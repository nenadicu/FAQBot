{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Lambda\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adadelta\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "TRAIN_CSV = '..../quora_duplicate_questions.csv'\n",
    "TEST_CSV = '..../testData.xlsx'\n",
    "EMBEDDING_FILE = 'GoogleNews-vectors-negative300.bin.gz'\n",
    "MODEL_SAVING_DIR = '/home/ecohen/HDD/HDD4/Models/Kaggle/Quora/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_df = pd.read_csv(\"quora_duplicate_questions.tsv\", sep=\"\\t\")\n",
    "quora_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(quora_df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "def text_to_word_list(text):\n",
    "    ''' Pre process and convert texts to a list of words '''\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = dict()\n",
    "inverse_vocabulary = ['<unk>']  # '<unk>' will never be used, it is only a placeholder for the [0, 0, ....0] embedding\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "questions_cols = ['question1', 'question2']\n",
    "\n",
    "# Iterate over the questions only of both training and test datasets\n",
    "for dataset in [train_df, test_df]:\n",
    "    for index, row in dataset.iterrows():\n",
    "\n",
    "        # Iterate through the text of both questions of the row\n",
    "        for question in questions_cols:\n",
    "\n",
    "            q2n = []  # q2n -> question numbers representation\n",
    "            for word in text_to_word_list(row[question]):\n",
    "\n",
    "                if word not in vocabulary:\n",
    "                    vocabulary[word] = len(inverse_vocabulary)\n",
    "                    q2n.append(len(inverse_vocabulary))\n",
    "                    inverse_vocabulary.append(word)\n",
    "                else:\n",
    "                    q2n.append(vocabulary[word])\n",
    "\n",
    "            # Replace questions as word to question as number representation\n",
    "            dataset.at[index, question]= q2n\n",
    "            \n",
    "embedding_dim = 300\n",
    "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # This will be the embedding matrix\n",
    "embeddings[0] = 0  # So that the padding will be ignored\n",
    "\n",
    "# Build the embedding matrix\n",
    "for word, index in vocabulary.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embeddings[index] = word2vec.word_vec(word)\n",
    "\n",
    "del word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = max(train_df.question1.map(lambda x: len(x)).max(),\n",
    "                     train_df.question2.map(lambda x: len(x)).max(),\n",
    "                     test_df.question1.map(lambda x: len(x)).max(),\n",
    "                     test_df.question2.map(lambda x: len(x)).max())\n",
    "\n",
    "# Split to train validation\n",
    "validation_size = 40000\n",
    "training_size = len(train_df) - validation_size\n",
    "\n",
    "X = train_df[questions_cols]\n",
    "Y = train_df['is_duplicate']\n",
    "\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Split to dicts\n",
    "X_train = {'left': X_train.question1, 'right': X_train.question2}\n",
    "X_validation = {'left': X_validation.question1, 'right': X_validation.question2}\n",
    "X_test = {'left': test_df.question1, 'right': test_df.question2}\n",
    "\n",
    "# Convert labels to their numpy representations\n",
    "Y_train = Y_train.values\n",
    "Y_validation = Y_validation.values\n",
    "\n",
    "# Zero padding\n",
    "for dataset, side in itertools.product([X_train, X_validation], ['left', 'right']):\n",
    "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)\n",
    "\n",
    "# Make sure everything is ok\n",
    "assert X_train['left'].shape == X_train['right'].shape\n",
    "assert len(X_train['left']) == len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2917 - accuracy: 0.6461\n",
      "Epoch 00001: val_loss improved from inf to 0.29231, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2917 - accuracy: 0.6461 - val_loss: 0.2923 - val_accuracy: 0.6460\n",
      "Epoch 2/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2915 - accuracy: 0.6462\n",
      "Epoch 00002: val_loss improved from 0.29231 to 0.29203, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2915 - accuracy: 0.6462 - val_loss: 0.2920 - val_accuracy: 0.6461\n",
      "Epoch 3/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.6462\n",
      "Epoch 00003: val_loss improved from 0.29203 to 0.29175, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2912 - accuracy: 0.6462 - val_loss: 0.2917 - val_accuracy: 0.6461\n",
      "Epoch 4/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2909 - accuracy: 0.6463\n",
      "Epoch 00004: val_loss improved from 0.29175 to 0.29146, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2909 - accuracy: 0.6463 - val_loss: 0.2915 - val_accuracy: 0.6462\n",
      "Epoch 5/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2906 - accuracy: 0.6464\n",
      "Epoch 00005: val_loss improved from 0.29146 to 0.29117, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2906 - accuracy: 0.6464 - val_loss: 0.2912 - val_accuracy: 0.6462\n",
      "Epoch 6/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2903 - accuracy: 0.6464\n",
      "Epoch 00006: val_loss improved from 0.29117 to 0.29087, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2903 - accuracy: 0.6464 - val_loss: 0.2909 - val_accuracy: 0.6463\n",
      "Epoch 7/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2901 - accuracy: 0.6465\n",
      "Epoch 00007: val_loss improved from 0.29087 to 0.29057, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2901 - accuracy: 0.6465 - val_loss: 0.2906 - val_accuracy: 0.6464\n",
      "Epoch 8/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.6465\n",
      "Epoch 00008: val_loss improved from 0.29057 to 0.29027, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2898 - accuracy: 0.6465 - val_loss: 0.2903 - val_accuracy: 0.6465\n",
      "Epoch 9/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.6466\n",
      "Epoch 00009: val_loss improved from 0.29027 to 0.28996, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2895 - accuracy: 0.6466 - val_loss: 0.2900 - val_accuracy: 0.6465\n",
      "Epoch 10/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2892 - accuracy: 0.6466\n",
      "Epoch 00010: val_loss improved from 0.28996 to 0.28966, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2892 - accuracy: 0.6466 - val_loss: 0.2897 - val_accuracy: 0.6465\n",
      "Epoch 11/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2889 - accuracy: 0.6467\n",
      "Epoch 00011: val_loss improved from 0.28966 to 0.28934, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2889 - accuracy: 0.6467 - val_loss: 0.2893 - val_accuracy: 0.6465\n",
      "Epoch 12/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2886 - accuracy: 0.6468\n",
      "Epoch 00012: val_loss improved from 0.28934 to 0.28903, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2886 - accuracy: 0.6468 - val_loss: 0.2890 - val_accuracy: 0.6465\n",
      "Epoch 13/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2883 - accuracy: 0.6469\n",
      "Epoch 00013: val_loss improved from 0.28903 to 0.28871, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2883 - accuracy: 0.6469 - val_loss: 0.2887 - val_accuracy: 0.6465\n",
      "Epoch 14/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2880 - accuracy: 0.6469\n",
      "Epoch 00014: val_loss improved from 0.28871 to 0.28839, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2880 - accuracy: 0.6469 - val_loss: 0.2884 - val_accuracy: 0.6467\n",
      "Epoch 15/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2876 - accuracy: 0.6470\n",
      "Epoch 00015: val_loss improved from 0.28839 to 0.28807, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2876 - accuracy: 0.6470 - val_loss: 0.2881 - val_accuracy: 0.6467\n",
      "Epoch 16/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2873 - accuracy: 0.6470\n",
      "Epoch 00016: val_loss improved from 0.28807 to 0.28774, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2873 - accuracy: 0.6470 - val_loss: 0.2877 - val_accuracy: 0.6470\n",
      "Epoch 17/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2870 - accuracy: 0.6470\n",
      "Epoch 00017: val_loss improved from 0.28774 to 0.28741, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2870 - accuracy: 0.6470 - val_loss: 0.2874 - val_accuracy: 0.6470\n",
      "Epoch 18/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2867 - accuracy: 0.6471\n",
      "Epoch 00018: val_loss improved from 0.28741 to 0.28708, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2867 - accuracy: 0.6471 - val_loss: 0.2871 - val_accuracy: 0.6470\n",
      "Epoch 19/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2864 - accuracy: 0.6471\n",
      "Epoch 00019: val_loss improved from 0.28708 to 0.28674, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2864 - accuracy: 0.6471 - val_loss: 0.2867 - val_accuracy: 0.6471\n",
      "Epoch 20/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.6472\n",
      "Epoch 00020: val_loss improved from 0.28674 to 0.28640, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2861 - accuracy: 0.6472 - val_loss: 0.2864 - val_accuracy: 0.6472\n",
      "Epoch 21/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.6472\n",
      "Epoch 00021: val_loss improved from 0.28640 to 0.28606, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2857 - accuracy: 0.6472 - val_loss: 0.2861 - val_accuracy: 0.6472\n",
      "Epoch 22/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2854 - accuracy: 0.6472\n",
      "Epoch 00022: val_loss improved from 0.28606 to 0.28572, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2854 - accuracy: 0.6472 - val_loss: 0.2857 - val_accuracy: 0.6472\n",
      "Epoch 23/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.6473\n",
      "Epoch 00023: val_loss improved from 0.28572 to 0.28537, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2851 - accuracy: 0.6473 - val_loss: 0.2854 - val_accuracy: 0.6473\n",
      "Epoch 24/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2847 - accuracy: 0.6474\n",
      "Epoch 00024: val_loss improved from 0.28537 to 0.28502, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2847 - accuracy: 0.6474 - val_loss: 0.2850 - val_accuracy: 0.6473\n",
      "Epoch 25/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2844 - accuracy: 0.6474\n",
      "Epoch 00025: val_loss improved from 0.28502 to 0.28467, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2844 - accuracy: 0.6474 - val_loss: 0.2847 - val_accuracy: 0.6473\n",
      "Epoch 26/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2840 - accuracy: 0.6475\n",
      "Epoch 00026: val_loss improved from 0.28467 to 0.28431, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2840 - accuracy: 0.6475 - val_loss: 0.2843 - val_accuracy: 0.6474\n",
      "Epoch 27/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 0.6476\n",
      "Epoch 00027: val_loss improved from 0.28431 to 0.28395, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2837 - accuracy: 0.6476 - val_loss: 0.2840 - val_accuracy: 0.6476\n",
      "Epoch 28/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2833 - accuracy: 0.6477\n",
      "Epoch 00028: val_loss improved from 0.28395 to 0.28359, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2833 - accuracy: 0.6477 - val_loss: 0.2836 - val_accuracy: 0.6475\n",
      "Epoch 29/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2830 - accuracy: 0.6478\n",
      "Epoch 00029: val_loss improved from 0.28359 to 0.28323, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2830 - accuracy: 0.6478 - val_loss: 0.2832 - val_accuracy: 0.6475\n",
      "Epoch 30/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2826 - accuracy: 0.6478\n",
      "Epoch 00030: val_loss improved from 0.28323 to 0.28286, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2826 - accuracy: 0.6478 - val_loss: 0.2829 - val_accuracy: 0.6476\n",
      "Epoch 31/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2823 - accuracy: 0.6479\n",
      "Epoch 00031: val_loss improved from 0.28286 to 0.28249, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2823 - accuracy: 0.6479 - val_loss: 0.2825 - val_accuracy: 0.6477\n",
      "Epoch 32/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.6480\n",
      "Epoch 00032: val_loss improved from 0.28249 to 0.28211, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2819 - accuracy: 0.6480 - val_loss: 0.2821 - val_accuracy: 0.6479\n",
      "Epoch 33/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2815 - accuracy: 0.6481\n",
      "Epoch 00033: val_loss improved from 0.28211 to 0.28173, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2815 - accuracy: 0.6481 - val_loss: 0.2817 - val_accuracy: 0.6480\n",
      "Epoch 34/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2812 - accuracy: 0.6482\n",
      "Epoch 00034: val_loss improved from 0.28173 to 0.28135, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2812 - accuracy: 0.6482 - val_loss: 0.2814 - val_accuracy: 0.6482\n",
      "Epoch 35/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2808 - accuracy: 0.6482\n",
      "Epoch 00035: val_loss improved from 0.28135 to 0.28096, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2808 - accuracy: 0.6482 - val_loss: 0.2810 - val_accuracy: 0.6483\n",
      "Epoch 36/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2804 - accuracy: 0.6483\n",
      "Epoch 00036: val_loss improved from 0.28096 to 0.28057, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2804 - accuracy: 0.6483 - val_loss: 0.2806 - val_accuracy: 0.6484\n",
      "Epoch 37/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2800 - accuracy: 0.6484\n",
      "Epoch 00037: val_loss improved from 0.28057 to 0.28018, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2800 - accuracy: 0.6484 - val_loss: 0.2802 - val_accuracy: 0.6486\n",
      "Epoch 38/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2797 - accuracy: 0.6485\n",
      "Epoch 00038: val_loss improved from 0.28018 to 0.27978, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2797 - accuracy: 0.6485 - val_loss: 0.2798 - val_accuracy: 0.6486\n",
      "Epoch 39/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2793 - accuracy: 0.6486\n",
      "Epoch 00039: val_loss improved from 0.27978 to 0.27937, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2793 - accuracy: 0.6486 - val_loss: 0.2794 - val_accuracy: 0.6488\n",
      "Epoch 40/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2789 - accuracy: 0.6486\n",
      "Epoch 00040: val_loss improved from 0.27937 to 0.27896, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2789 - accuracy: 0.6486 - val_loss: 0.2790 - val_accuracy: 0.6489\n",
      "Epoch 41/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2785 - accuracy: 0.6487\n",
      "Epoch 00041: val_loss improved from 0.27896 to 0.27854, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2785 - accuracy: 0.6487 - val_loss: 0.2785 - val_accuracy: 0.6489\n",
      "Epoch 42/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2781 - accuracy: 0.6488\n",
      "Epoch 00042: val_loss improved from 0.27854 to 0.27812, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2781 - accuracy: 0.6488 - val_loss: 0.2781 - val_accuracy: 0.6491\n",
      "Epoch 43/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2776 - accuracy: 0.6489\n",
      "Epoch 00043: val_loss improved from 0.27812 to 0.27770, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2776 - accuracy: 0.6489 - val_loss: 0.2777 - val_accuracy: 0.6493\n",
      "Epoch 44/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.6490\n",
      "Epoch 00044: val_loss improved from 0.27770 to 0.27726, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2772 - accuracy: 0.6490 - val_loss: 0.2773 - val_accuracy: 0.6494\n",
      "Epoch 45/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2768 - accuracy: 0.6491\n",
      "Epoch 00045: val_loss improved from 0.27726 to 0.27683, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2768 - accuracy: 0.6491 - val_loss: 0.2768 - val_accuracy: 0.6494\n",
      "Epoch 46/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.6492\n",
      "Epoch 00046: val_loss improved from 0.27683 to 0.27639, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2764 - accuracy: 0.6492 - val_loss: 0.2764 - val_accuracy: 0.6496\n",
      "Epoch 47/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.6492\n",
      "Epoch 00047: val_loss improved from 0.27639 to 0.27594, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2759 - accuracy: 0.6492 - val_loss: 0.2759 - val_accuracy: 0.6497\n",
      "Epoch 48/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.6493\n",
      "Epoch 00048: val_loss improved from 0.27594 to 0.27549, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2755 - accuracy: 0.6493 - val_loss: 0.2755 - val_accuracy: 0.6496\n",
      "Epoch 49/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.6494\n",
      "Epoch 00049: val_loss improved from 0.27549 to 0.27504, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2751 - accuracy: 0.6494 - val_loss: 0.2750 - val_accuracy: 0.6498\n",
      "Epoch 50/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2746 - accuracy: 0.6495\n",
      "Epoch 00050: val_loss improved from 0.27504 to 0.27459, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2746 - accuracy: 0.6495 - val_loss: 0.2746 - val_accuracy: 0.6498\n",
      "Epoch 51/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2742 - accuracy: 0.6496\n",
      "Epoch 00051: val_loss improved from 0.27459 to 0.27414, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2742 - accuracy: 0.6496 - val_loss: 0.2741 - val_accuracy: 0.6499\n",
      "Epoch 52/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2738 - accuracy: 0.6497\n",
      "Epoch 00052: val_loss improved from 0.27414 to 0.27369, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2738 - accuracy: 0.6497 - val_loss: 0.2737 - val_accuracy: 0.6500\n",
      "Epoch 53/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2733 - accuracy: 0.6498\n",
      "Epoch 00053: val_loss improved from 0.27369 to 0.27325, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2733 - accuracy: 0.6498 - val_loss: 0.2732 - val_accuracy: 0.6501\n",
      "Epoch 54/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.6499\n",
      "Epoch 00054: val_loss improved from 0.27325 to 0.27281, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2729 - accuracy: 0.6499 - val_loss: 0.2728 - val_accuracy: 0.6503\n",
      "Epoch 55/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2725 - accuracy: 0.6501\n",
      "Epoch 00055: val_loss improved from 0.27281 to 0.27238, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2725 - accuracy: 0.6501 - val_loss: 0.2724 - val_accuracy: 0.6504\n",
      "Epoch 56/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2721 - accuracy: 0.6502\n",
      "Epoch 00056: val_loss improved from 0.27238 to 0.27196, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2721 - accuracy: 0.6502 - val_loss: 0.2720 - val_accuracy: 0.6504\n",
      "Epoch 57/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2717 - accuracy: 0.6503\n",
      "Epoch 00057: val_loss improved from 0.27196 to 0.27155, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2717 - accuracy: 0.6503 - val_loss: 0.2715 - val_accuracy: 0.6504\n",
      "Epoch 58/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2713 - accuracy: 0.6504\n",
      "Epoch 00058: val_loss improved from 0.27155 to 0.27114, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2713 - accuracy: 0.6504 - val_loss: 0.2711 - val_accuracy: 0.6505\n",
      "Epoch 59/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2709 - accuracy: 0.6505\n",
      "Epoch 00059: val_loss improved from 0.27114 to 0.27074, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2709 - accuracy: 0.6505 - val_loss: 0.2707 - val_accuracy: 0.6508\n",
      "Epoch 60/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2705 - accuracy: 0.6507\n",
      "Epoch 00060: val_loss improved from 0.27074 to 0.27034, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2705 - accuracy: 0.6507 - val_loss: 0.2703 - val_accuracy: 0.6508\n",
      "Epoch 61/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2701 - accuracy: 0.6508\n",
      "Epoch 00061: val_loss improved from 0.27034 to 0.26995, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2701 - accuracy: 0.6508 - val_loss: 0.2699 - val_accuracy: 0.6511\n",
      "Epoch 62/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2697 - accuracy: 0.6509\n",
      "Epoch 00062: val_loss improved from 0.26995 to 0.26956, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2697 - accuracy: 0.6509 - val_loss: 0.2696 - val_accuracy: 0.6512\n",
      "Epoch 63/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.6510\n",
      "Epoch 00063: val_loss improved from 0.26956 to 0.26917, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2694 - accuracy: 0.6510 - val_loss: 0.2692 - val_accuracy: 0.6512\n",
      "Epoch 64/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2690 - accuracy: 0.6512\n",
      "Epoch 00064: val_loss improved from 0.26917 to 0.26879, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2690 - accuracy: 0.6512 - val_loss: 0.2688 - val_accuracy: 0.6514\n",
      "Epoch 65/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.6513\n",
      "Epoch 00065: val_loss improved from 0.26879 to 0.26841, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2686 - accuracy: 0.6513 - val_loss: 0.2684 - val_accuracy: 0.6516\n",
      "Epoch 66/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2682 - accuracy: 0.6514\n",
      "Epoch 00066: val_loss improved from 0.26841 to 0.26803, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2682 - accuracy: 0.6514 - val_loss: 0.2680 - val_accuracy: 0.6517\n",
      "Epoch 67/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2679 - accuracy: 0.6515\n",
      "Epoch 00067: val_loss improved from 0.26803 to 0.26765, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2679 - accuracy: 0.6515 - val_loss: 0.2677 - val_accuracy: 0.6518\n",
      "Epoch 68/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2675 - accuracy: 0.6517\n",
      "Epoch 00068: val_loss improved from 0.26765 to 0.26728, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2675 - accuracy: 0.6517 - val_loss: 0.2673 - val_accuracy: 0.6520\n",
      "Epoch 69/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.6518\n",
      "Epoch 00069: val_loss improved from 0.26728 to 0.26691, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2671 - accuracy: 0.6518 - val_loss: 0.2669 - val_accuracy: 0.6521\n",
      "Epoch 70/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2668 - accuracy: 0.6519\n",
      "Epoch 00070: val_loss improved from 0.26691 to 0.26654, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2668 - accuracy: 0.6519 - val_loss: 0.2665 - val_accuracy: 0.6522\n",
      "Epoch 71/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2664 - accuracy: 0.6521\n",
      "Epoch 00071: val_loss improved from 0.26654 to 0.26617, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2664 - accuracy: 0.6521 - val_loss: 0.2662 - val_accuracy: 0.6524\n",
      "Epoch 72/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2660 - accuracy: 0.6522\n",
      "Epoch 00072: val_loss improved from 0.26617 to 0.26580, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2660 - accuracy: 0.6522 - val_loss: 0.2658 - val_accuracy: 0.6526\n",
      "Epoch 73/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2657 - accuracy: 0.6523\n",
      "Epoch 00073: val_loss improved from 0.26580 to 0.26543, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2657 - accuracy: 0.6523 - val_loss: 0.2654 - val_accuracy: 0.6528\n",
      "Epoch 74/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2653 - accuracy: 0.6524\n",
      "Epoch 00074: val_loss improved from 0.26543 to 0.26507, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2653 - accuracy: 0.6524 - val_loss: 0.2651 - val_accuracy: 0.6531\n",
      "Epoch 75/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2650 - accuracy: 0.6526\n",
      "Epoch 00075: val_loss improved from 0.26507 to 0.26470, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2650 - accuracy: 0.6526 - val_loss: 0.2647 - val_accuracy: 0.6533\n",
      "Epoch 76/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2646 - accuracy: 0.6527\n",
      "Epoch 00076: val_loss improved from 0.26470 to 0.26434, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2646 - accuracy: 0.6527 - val_loss: 0.2643 - val_accuracy: 0.6534\n",
      "Epoch 77/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2642 - accuracy: 0.6529\n",
      "Epoch 00077: val_loss improved from 0.26434 to 0.26398, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2642 - accuracy: 0.6529 - val_loss: 0.2640 - val_accuracy: 0.6536\n",
      "Epoch 78/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2639 - accuracy: 0.6530\n",
      "Epoch 00078: val_loss improved from 0.26398 to 0.26362, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2639 - accuracy: 0.6530 - val_loss: 0.2636 - val_accuracy: 0.6537\n",
      "Epoch 79/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2635 - accuracy: 0.6531\n",
      "Epoch 00079: val_loss improved from 0.26362 to 0.26326, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2635 - accuracy: 0.6531 - val_loss: 0.2633 - val_accuracy: 0.6538\n",
      "Epoch 80/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2632 - accuracy: 0.6532\n",
      "Epoch 00080: val_loss improved from 0.26326 to 0.26291, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2632 - accuracy: 0.6532 - val_loss: 0.2629 - val_accuracy: 0.6539\n",
      "Epoch 81/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2628 - accuracy: 0.6534\n",
      "Epoch 00081: val_loss improved from 0.26291 to 0.26255, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2628 - accuracy: 0.6534 - val_loss: 0.2625 - val_accuracy: 0.6539\n",
      "Epoch 82/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2625 - accuracy: 0.6534\n",
      "Epoch 00082: val_loss improved from 0.26255 to 0.26219, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2625 - accuracy: 0.6534 - val_loss: 0.2622 - val_accuracy: 0.6540\n",
      "Epoch 83/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2621 - accuracy: 0.6536\n",
      "Epoch 00083: val_loss improved from 0.26219 to 0.26184, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2621 - accuracy: 0.6536 - val_loss: 0.2618 - val_accuracy: 0.6542\n",
      "Epoch 84/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2618 - accuracy: 0.6537\n",
      "Epoch 00084: val_loss improved from 0.26184 to 0.26149, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2618 - accuracy: 0.6537 - val_loss: 0.2615 - val_accuracy: 0.6542\n",
      "Epoch 85/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2614 - accuracy: 0.6537\n",
      "Epoch 00085: val_loss improved from 0.26149 to 0.26113, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2614 - accuracy: 0.6537 - val_loss: 0.2611 - val_accuracy: 0.6543\n",
      "Epoch 86/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.6539\n",
      "Epoch 00086: val_loss improved from 0.26113 to 0.26078, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2611 - accuracy: 0.6539 - val_loss: 0.2608 - val_accuracy: 0.6543\n",
      "Epoch 87/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.6539\n",
      "Epoch 00087: val_loss improved from 0.26078 to 0.26043, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2607 - accuracy: 0.6539 - val_loss: 0.2604 - val_accuracy: 0.6543\n",
      "Epoch 88/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2604 - accuracy: 0.6540\n",
      "Epoch 00088: val_loss improved from 0.26043 to 0.26008, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2604 - accuracy: 0.6540 - val_loss: 0.2601 - val_accuracy: 0.6544\n",
      "Epoch 89/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2600 - accuracy: 0.6542\n",
      "Epoch 00089: val_loss improved from 0.26008 to 0.25973, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2600 - accuracy: 0.6542 - val_loss: 0.2597 - val_accuracy: 0.6544\n",
      "Epoch 90/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2597 - accuracy: 0.6543\n",
      "Epoch 00090: val_loss improved from 0.25973 to 0.25938, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2597 - accuracy: 0.6543 - val_loss: 0.2594 - val_accuracy: 0.6547\n",
      "Epoch 91/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2593 - accuracy: 0.6544\n",
      "Epoch 00091: val_loss improved from 0.25938 to 0.25903, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2593 - accuracy: 0.6544 - val_loss: 0.2590 - val_accuracy: 0.6548\n",
      "Epoch 92/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2590 - accuracy: 0.6544\n",
      "Epoch 00092: val_loss improved from 0.25903 to 0.25868, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2590 - accuracy: 0.6544 - val_loss: 0.2587 - val_accuracy: 0.6550\n",
      "Epoch 93/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2586 - accuracy: 0.6545\n",
      "Epoch 00093: val_loss improved from 0.25868 to 0.25833, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2586 - accuracy: 0.6545 - val_loss: 0.2583 - val_accuracy: 0.6551\n",
      "Epoch 94/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2583 - accuracy: 0.6547\n",
      "Epoch 00094: val_loss improved from 0.25833 to 0.25798, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2583 - accuracy: 0.6547 - val_loss: 0.2580 - val_accuracy: 0.6554\n",
      "Epoch 95/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2579 - accuracy: 0.6548\n",
      "Epoch 00095: val_loss improved from 0.25798 to 0.25763, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2579 - accuracy: 0.6548 - val_loss: 0.2576 - val_accuracy: 0.6556\n",
      "Epoch 96/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.6550\n",
      "Epoch 00096: val_loss improved from 0.25763 to 0.25729, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2576 - accuracy: 0.6550 - val_loss: 0.2573 - val_accuracy: 0.6557\n",
      "Epoch 97/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 0.6551\n",
      "Epoch 00097: val_loss improved from 0.25729 to 0.25694, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2573 - accuracy: 0.6551 - val_loss: 0.2569 - val_accuracy: 0.6559\n",
      "Epoch 98/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2569 - accuracy: 0.6553\n",
      "Epoch 00098: val_loss improved from 0.25694 to 0.25660, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2569 - accuracy: 0.6553 - val_loss: 0.2566 - val_accuracy: 0.6560\n",
      "Epoch 99/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2566 - accuracy: 0.6554\n",
      "Epoch 00099: val_loss improved from 0.25660 to 0.25626, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2566 - accuracy: 0.6554 - val_loss: 0.2563 - val_accuracy: 0.6563\n",
      "Epoch 100/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2562 - accuracy: 0.6555\n",
      "Epoch 00100: val_loss improved from 0.25626 to 0.25592, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2562 - accuracy: 0.6555 - val_loss: 0.2559 - val_accuracy: 0.6565\n",
      "Epoch 101/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2559 - accuracy: 0.6557\n",
      "Epoch 00101: val_loss improved from 0.25592 to 0.25558, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2559 - accuracy: 0.6557 - val_loss: 0.2556 - val_accuracy: 0.6567\n",
      "Epoch 102/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2556 - accuracy: 0.6560\n",
      "Epoch 00102: val_loss improved from 0.25558 to 0.25524, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2556 - accuracy: 0.6560 - val_loss: 0.2552 - val_accuracy: 0.6569\n",
      "Epoch 103/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2552 - accuracy: 0.6561\n",
      "Epoch 00103: val_loss improved from 0.25524 to 0.25491, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2552 - accuracy: 0.6561 - val_loss: 0.2549 - val_accuracy: 0.6570\n",
      "Epoch 104/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2549 - accuracy: 0.6563\n",
      "Epoch 00104: val_loss improved from 0.25491 to 0.25457, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2549 - accuracy: 0.6563 - val_loss: 0.2546 - val_accuracy: 0.6571\n",
      "Epoch 105/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2546 - accuracy: 0.6565\n",
      "Epoch 00105: val_loss improved from 0.25457 to 0.25424, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2546 - accuracy: 0.6565 - val_loss: 0.2542 - val_accuracy: 0.6574\n",
      "Epoch 106/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2542 - accuracy: 0.6566\n",
      "Epoch 00106: val_loss improved from 0.25424 to 0.25391, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2542 - accuracy: 0.6566 - val_loss: 0.2539 - val_accuracy: 0.6577\n",
      "Epoch 107/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2539 - accuracy: 0.6567\n",
      "Epoch 00107: val_loss improved from 0.25391 to 0.25358, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2539 - accuracy: 0.6567 - val_loss: 0.2536 - val_accuracy: 0.6578\n",
      "Epoch 108/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.6569\n",
      "Epoch 00108: val_loss improved from 0.25358 to 0.25326, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2536 - accuracy: 0.6569 - val_loss: 0.2533 - val_accuracy: 0.6580\n",
      "Epoch 109/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2533 - accuracy: 0.6570\n",
      "Epoch 00109: val_loss improved from 0.25326 to 0.25293, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2533 - accuracy: 0.6570 - val_loss: 0.2529 - val_accuracy: 0.6581\n",
      "Epoch 110/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2529 - accuracy: 0.6572\n",
      "Epoch 00110: val_loss improved from 0.25293 to 0.25261, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2529 - accuracy: 0.6572 - val_loss: 0.2526 - val_accuracy: 0.6584\n",
      "Epoch 111/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2526 - accuracy: 0.6573\n",
      "Epoch 00111: val_loss improved from 0.25261 to 0.25228, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2526 - accuracy: 0.6573 - val_loss: 0.2523 - val_accuracy: 0.6588\n",
      "Epoch 112/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2523 - accuracy: 0.6574\n",
      "Epoch 00112: val_loss improved from 0.25228 to 0.25196, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2523 - accuracy: 0.6574 - val_loss: 0.2520 - val_accuracy: 0.6590\n",
      "Epoch 113/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2520 - accuracy: 0.6576\n",
      "Epoch 00113: val_loss improved from 0.25196 to 0.25164, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2520 - accuracy: 0.6576 - val_loss: 0.2516 - val_accuracy: 0.6592\n",
      "Epoch 114/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2517 - accuracy: 0.6577\n",
      "Epoch 00114: val_loss improved from 0.25164 to 0.25132, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2517 - accuracy: 0.6577 - val_loss: 0.2513 - val_accuracy: 0.6592\n",
      "Epoch 115/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2514 - accuracy: 0.6578\n",
      "Epoch 00115: val_loss improved from 0.25132 to 0.25100, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2514 - accuracy: 0.6578 - val_loss: 0.2510 - val_accuracy: 0.6592\n",
      "Epoch 116/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2510 - accuracy: 0.6579\n",
      "Epoch 00116: val_loss improved from 0.25100 to 0.25068, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2510 - accuracy: 0.6579 - val_loss: 0.2507 - val_accuracy: 0.6594\n",
      "Epoch 117/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2507 - accuracy: 0.6581\n",
      "Epoch 00117: val_loss improved from 0.25068 to 0.25036, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2507 - accuracy: 0.6581 - val_loss: 0.2504 - val_accuracy: 0.6596\n",
      "Epoch 118/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2504 - accuracy: 0.6582\n",
      "Epoch 00118: val_loss improved from 0.25036 to 0.25004, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2504 - accuracy: 0.6582 - val_loss: 0.2500 - val_accuracy: 0.6597\n",
      "Epoch 119/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2501 - accuracy: 0.6583\n",
      "Epoch 00119: val_loss improved from 0.25004 to 0.24972, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2501 - accuracy: 0.6583 - val_loss: 0.2497 - val_accuracy: 0.6599\n",
      "Epoch 120/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.6585\n",
      "Epoch 00120: val_loss improved from 0.24972 to 0.24939, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2498 - accuracy: 0.6585 - val_loss: 0.2494 - val_accuracy: 0.6600\n",
      "Epoch 121/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.6587\n",
      "Epoch 00121: val_loss improved from 0.24939 to 0.24907, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2495 - accuracy: 0.6587 - val_loss: 0.2491 - val_accuracy: 0.6602\n",
      "Epoch 122/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2491 - accuracy: 0.6588\n",
      "Epoch 00122: val_loss improved from 0.24907 to 0.24875, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2491 - accuracy: 0.6588 - val_loss: 0.2488 - val_accuracy: 0.6602\n",
      "Epoch 123/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2488 - accuracy: 0.6590\n",
      "Epoch 00123: val_loss improved from 0.24875 to 0.24843, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2488 - accuracy: 0.6590 - val_loss: 0.2484 - val_accuracy: 0.6605\n",
      "Epoch 124/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2485 - accuracy: 0.6591\n",
      "Epoch 00124: val_loss improved from 0.24843 to 0.24811, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2485 - accuracy: 0.6591 - val_loss: 0.2481 - val_accuracy: 0.6606\n",
      "Epoch 125/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2482 - accuracy: 0.6592\n",
      "Epoch 00125: val_loss improved from 0.24811 to 0.24779, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2482 - accuracy: 0.6592 - val_loss: 0.2478 - val_accuracy: 0.6606\n",
      "Epoch 126/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2479 - accuracy: 0.6594\n",
      "Epoch 00126: val_loss improved from 0.24779 to 0.24748, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2479 - accuracy: 0.6594 - val_loss: 0.2475 - val_accuracy: 0.6608\n",
      "Epoch 127/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2476 - accuracy: 0.6595\n",
      "Epoch 00127: val_loss improved from 0.24748 to 0.24717, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2476 - accuracy: 0.6595 - val_loss: 0.2472 - val_accuracy: 0.6610\n",
      "Epoch 128/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2473 - accuracy: 0.6597\n",
      "Epoch 00128: val_loss improved from 0.24717 to 0.24687, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2473 - accuracy: 0.6597 - val_loss: 0.2469 - val_accuracy: 0.6611\n",
      "Epoch 129/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2470 - accuracy: 0.6599\n",
      "Epoch 00129: val_loss improved from 0.24687 to 0.24658, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2470 - accuracy: 0.6599 - val_loss: 0.2466 - val_accuracy: 0.6611\n",
      "Epoch 130/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2467 - accuracy: 0.6600\n",
      "Epoch 00130: val_loss improved from 0.24658 to 0.24629, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2467 - accuracy: 0.6600 - val_loss: 0.2463 - val_accuracy: 0.6613\n",
      "Epoch 131/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2464 - accuracy: 0.6602\n",
      "Epoch 00131: val_loss improved from 0.24629 to 0.24602, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2464 - accuracy: 0.6602 - val_loss: 0.2460 - val_accuracy: 0.6614\n",
      "Epoch 132/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2462 - accuracy: 0.6603\n",
      "Epoch 00132: val_loss improved from 0.24602 to 0.24575, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2462 - accuracy: 0.6603 - val_loss: 0.2458 - val_accuracy: 0.6615\n",
      "Epoch 133/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2459 - accuracy: 0.6604\n",
      "Epoch 00133: val_loss improved from 0.24575 to 0.24549, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2459 - accuracy: 0.6604 - val_loss: 0.2455 - val_accuracy: 0.6616\n",
      "Epoch 134/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2456 - accuracy: 0.6606\n",
      "Epoch 00134: val_loss improved from 0.24549 to 0.24523, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2456 - accuracy: 0.6606 - val_loss: 0.2452 - val_accuracy: 0.6617\n",
      "Epoch 135/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2454 - accuracy: 0.6608\n",
      "Epoch 00135: val_loss improved from 0.24523 to 0.24498, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2454 - accuracy: 0.6608 - val_loss: 0.2450 - val_accuracy: 0.6619\n",
      "Epoch 136/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2451 - accuracy: 0.6608\n",
      "Epoch 00136: val_loss improved from 0.24498 to 0.24473, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2451 - accuracy: 0.6608 - val_loss: 0.2447 - val_accuracy: 0.6622\n",
      "Epoch 137/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2449 - accuracy: 0.6610\n",
      "Epoch 00137: val_loss improved from 0.24473 to 0.24449, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2449 - accuracy: 0.6610 - val_loss: 0.2445 - val_accuracy: 0.6622\n",
      "Epoch 138/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2446 - accuracy: 0.6612\n",
      "Epoch 00138: val_loss improved from 0.24449 to 0.24424, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2446 - accuracy: 0.6612 - val_loss: 0.2442 - val_accuracy: 0.6625\n",
      "Epoch 139/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2444 - accuracy: 0.6613\n",
      "Epoch 00139: val_loss improved from 0.24424 to 0.24400, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2444 - accuracy: 0.6613 - val_loss: 0.2440 - val_accuracy: 0.6628\n",
      "Epoch 140/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2442 - accuracy: 0.6615\n",
      "Epoch 00140: val_loss improved from 0.24400 to 0.24376, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2442 - accuracy: 0.6615 - val_loss: 0.2438 - val_accuracy: 0.6631\n",
      "Epoch 141/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2439 - accuracy: 0.6617\n",
      "Epoch 00141: val_loss improved from 0.24376 to 0.24353, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2439 - accuracy: 0.6617 - val_loss: 0.2435 - val_accuracy: 0.6632\n",
      "Epoch 142/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2437 - accuracy: 0.6618\n",
      "Epoch 00142: val_loss improved from 0.24353 to 0.24329, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2437 - accuracy: 0.6618 - val_loss: 0.2433 - val_accuracy: 0.6635\n",
      "Epoch 143/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.6620\n",
      "Epoch 00143: val_loss improved from 0.24329 to 0.24306, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2435 - accuracy: 0.6620 - val_loss: 0.2431 - val_accuracy: 0.6635\n",
      "Epoch 144/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2432 - accuracy: 0.6621\n",
      "Epoch 00144: val_loss improved from 0.24306 to 0.24282, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2432 - accuracy: 0.6621 - val_loss: 0.2428 - val_accuracy: 0.6637\n",
      "Epoch 145/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2430 - accuracy: 0.6623\n",
      "Epoch 00145: val_loss improved from 0.24282 to 0.24259, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2430 - accuracy: 0.6623 - val_loss: 0.2426 - val_accuracy: 0.6637\n",
      "Epoch 146/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2428 - accuracy: 0.6625\n",
      "Epoch 00146: val_loss improved from 0.24259 to 0.24236, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2428 - accuracy: 0.6625 - val_loss: 0.2424 - val_accuracy: 0.6638\n",
      "Epoch 147/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2425 - accuracy: 0.6626\n",
      "Epoch 00147: val_loss improved from 0.24236 to 0.24213, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2425 - accuracy: 0.6626 - val_loss: 0.2421 - val_accuracy: 0.6639\n",
      "Epoch 148/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.6627\n",
      "Epoch 00148: val_loss improved from 0.24213 to 0.24190, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2423 - accuracy: 0.6627 - val_loss: 0.2419 - val_accuracy: 0.6642\n",
      "Epoch 149/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.6629\n",
      "Epoch 00149: val_loss improved from 0.24190 to 0.24167, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2421 - accuracy: 0.6629 - val_loss: 0.2417 - val_accuracy: 0.6644\n",
      "Epoch 150/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2418 - accuracy: 0.6631\n",
      "Epoch 00150: val_loss improved from 0.24167 to 0.24145, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2418 - accuracy: 0.6631 - val_loss: 0.2414 - val_accuracy: 0.6644\n",
      "Epoch 151/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2416 - accuracy: 0.6633\n",
      "Epoch 00151: val_loss improved from 0.24145 to 0.24122, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2416 - accuracy: 0.6633 - val_loss: 0.2412 - val_accuracy: 0.6646\n",
      "Epoch 152/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2414 - accuracy: 0.6635\n",
      "Epoch 00152: val_loss improved from 0.24122 to 0.24100, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2414 - accuracy: 0.6635 - val_loss: 0.2410 - val_accuracy: 0.6647\n",
      "Epoch 153/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2412 - accuracy: 0.6636\n",
      "Epoch 00153: val_loss improved from 0.24100 to 0.24077, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2412 - accuracy: 0.6636 - val_loss: 0.2408 - val_accuracy: 0.6649\n",
      "Epoch 154/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2409 - accuracy: 0.6637\n",
      "Epoch 00154: val_loss improved from 0.24077 to 0.24055, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2409 - accuracy: 0.6637 - val_loss: 0.2405 - val_accuracy: 0.6652\n",
      "Epoch 155/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2407 - accuracy: 0.6639\n",
      "Epoch 00155: val_loss improved from 0.24055 to 0.24032, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2407 - accuracy: 0.6639 - val_loss: 0.2403 - val_accuracy: 0.6653\n",
      "Epoch 156/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.6641\n",
      "Epoch 00156: val_loss improved from 0.24032 to 0.24010, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2405 - accuracy: 0.6641 - val_loss: 0.2401 - val_accuracy: 0.6656\n",
      "Epoch 157/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2403 - accuracy: 0.6643\n",
      "Epoch 00157: val_loss improved from 0.24010 to 0.23988, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2403 - accuracy: 0.6643 - val_loss: 0.2399 - val_accuracy: 0.6657\n",
      "Epoch 158/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.6645\n",
      "Epoch 00158: val_loss improved from 0.23988 to 0.23966, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2401 - accuracy: 0.6645 - val_loss: 0.2397 - val_accuracy: 0.6658\n",
      "Epoch 159/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2398 - accuracy: 0.6647\n",
      "Epoch 00159: val_loss improved from 0.23966 to 0.23944, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2398 - accuracy: 0.6647 - val_loss: 0.2394 - val_accuracy: 0.6661\n",
      "Epoch 160/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2396 - accuracy: 0.6649\n",
      "Epoch 00160: val_loss improved from 0.23944 to 0.23923, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2396 - accuracy: 0.6649 - val_loss: 0.2392 - val_accuracy: 0.6662\n",
      "Epoch 161/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2394 - accuracy: 0.6651\n",
      "Epoch 00161: val_loss improved from 0.23923 to 0.23902, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2394 - accuracy: 0.6651 - val_loss: 0.2390 - val_accuracy: 0.6664\n",
      "Epoch 162/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2392 - accuracy: 0.6653\n",
      "Epoch 00162: val_loss improved from 0.23902 to 0.23881, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2392 - accuracy: 0.6653 - val_loss: 0.2388 - val_accuracy: 0.6666\n",
      "Epoch 163/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2390 - accuracy: 0.6655\n",
      "Epoch 00163: val_loss improved from 0.23881 to 0.23860, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2390 - accuracy: 0.6655 - val_loss: 0.2386 - val_accuracy: 0.6666\n",
      "Epoch 164/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2388 - accuracy: 0.6656\n",
      "Epoch 00164: val_loss improved from 0.23860 to 0.23841, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2388 - accuracy: 0.6656 - val_loss: 0.2384 - val_accuracy: 0.6668\n",
      "Epoch 165/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2386 - accuracy: 0.6657\n",
      "Epoch 00165: val_loss improved from 0.23841 to 0.23821, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2386 - accuracy: 0.6657 - val_loss: 0.2382 - val_accuracy: 0.6669\n",
      "Epoch 166/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2384 - accuracy: 0.6658\n",
      "Epoch 00166: val_loss improved from 0.23821 to 0.23802, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2384 - accuracy: 0.6658 - val_loss: 0.2380 - val_accuracy: 0.6669\n",
      "Epoch 167/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.6660\n",
      "Epoch 00167: val_loss improved from 0.23802 to 0.23784, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2382 - accuracy: 0.6660 - val_loss: 0.2378 - val_accuracy: 0.6671\n",
      "Epoch 168/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2380 - accuracy: 0.6662\n",
      "Epoch 00168: val_loss improved from 0.23784 to 0.23766, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2380 - accuracy: 0.6662 - val_loss: 0.2377 - val_accuracy: 0.6673\n",
      "Epoch 169/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2378 - accuracy: 0.6664\n",
      "Epoch 00169: val_loss improved from 0.23766 to 0.23748, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2378 - accuracy: 0.6664 - val_loss: 0.2375 - val_accuracy: 0.6675\n",
      "Epoch 170/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.6665\n",
      "Epoch 00170: val_loss improved from 0.23748 to 0.23731, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2377 - accuracy: 0.6665 - val_loss: 0.2373 - val_accuracy: 0.6675\n",
      "Epoch 171/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.6666\n",
      "Epoch 00171: val_loss improved from 0.23731 to 0.23713, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2375 - accuracy: 0.6666 - val_loss: 0.2371 - val_accuracy: 0.6676\n",
      "Epoch 172/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.6667\n",
      "Epoch 00172: val_loss improved from 0.23713 to 0.23697, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2373 - accuracy: 0.6667 - val_loss: 0.2370 - val_accuracy: 0.6678\n",
      "Epoch 173/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2372 - accuracy: 0.6669\n",
      "Epoch 00173: val_loss improved from 0.23697 to 0.23680, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2372 - accuracy: 0.6669 - val_loss: 0.2368 - val_accuracy: 0.6679\n",
      "Epoch 174/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2370 - accuracy: 0.6670\n",
      "Epoch 00174: val_loss improved from 0.23680 to 0.23664, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2370 - accuracy: 0.6670 - val_loss: 0.2366 - val_accuracy: 0.6679\n",
      "Epoch 175/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2368 - accuracy: 0.6672\n",
      "Epoch 00175: val_loss improved from 0.23664 to 0.23648, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2368 - accuracy: 0.6672 - val_loss: 0.2365 - val_accuracy: 0.6682\n",
      "Epoch 176/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2367 - accuracy: 0.6673\n",
      "Epoch 00176: val_loss improved from 0.23648 to 0.23632, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2367 - accuracy: 0.6673 - val_loss: 0.2363 - val_accuracy: 0.6683\n",
      "Epoch 177/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2365 - accuracy: 0.6675\n",
      "Epoch 00177: val_loss improved from 0.23632 to 0.23616, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2365 - accuracy: 0.6675 - val_loss: 0.2362 - val_accuracy: 0.6685\n",
      "Epoch 178/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2364 - accuracy: 0.6677\n",
      "Epoch 00178: val_loss improved from 0.23616 to 0.23600, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2364 - accuracy: 0.6677 - val_loss: 0.2360 - val_accuracy: 0.6688\n",
      "Epoch 179/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 0.6679\n",
      "Epoch 00179: val_loss improved from 0.23600 to 0.23585, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2362 - accuracy: 0.6679 - val_loss: 0.2358 - val_accuracy: 0.6690\n",
      "Epoch 180/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2360 - accuracy: 0.6681\n",
      "Epoch 00180: val_loss improved from 0.23585 to 0.23569, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2360 - accuracy: 0.6681 - val_loss: 0.2357 - val_accuracy: 0.6692\n",
      "Epoch 181/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.6682\n",
      "Epoch 00181: val_loss improved from 0.23569 to 0.23554, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2359 - accuracy: 0.6682 - val_loss: 0.2355 - val_accuracy: 0.6695\n",
      "Epoch 182/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2357 - accuracy: 0.6685\n",
      "Epoch 00182: val_loss improved from 0.23554 to 0.23539, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2357 - accuracy: 0.6685 - val_loss: 0.2354 - val_accuracy: 0.6697\n",
      "Epoch 183/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2356 - accuracy: 0.6687\n",
      "Epoch 00183: val_loss improved from 0.23539 to 0.23524, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2356 - accuracy: 0.6687 - val_loss: 0.2352 - val_accuracy: 0.6696\n",
      "Epoch 184/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2354 - accuracy: 0.6688\n",
      "Epoch 00184: val_loss improved from 0.23524 to 0.23509, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2354 - accuracy: 0.6688 - val_loss: 0.2351 - val_accuracy: 0.6697\n",
      "Epoch 185/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2353 - accuracy: 0.6690\n",
      "Epoch 00185: val_loss improved from 0.23509 to 0.23495, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2353 - accuracy: 0.6690 - val_loss: 0.2349 - val_accuracy: 0.6699\n",
      "Epoch 186/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2352 - accuracy: 0.6691\n",
      "Epoch 00186: val_loss improved from 0.23495 to 0.23480, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2352 - accuracy: 0.6691 - val_loss: 0.2348 - val_accuracy: 0.6702\n",
      "Epoch 187/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2350 - accuracy: 0.6693\n",
      "Epoch 00187: val_loss improved from 0.23480 to 0.23466, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2350 - accuracy: 0.6693 - val_loss: 0.2347 - val_accuracy: 0.6703\n",
      "Epoch 188/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2349 - accuracy: 0.6695\n",
      "Epoch 00188: val_loss improved from 0.23466 to 0.23452, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2349 - accuracy: 0.6695 - val_loss: 0.2345 - val_accuracy: 0.6707\n",
      "Epoch 189/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2347 - accuracy: 0.6696\n",
      "Epoch 00189: val_loss improved from 0.23452 to 0.23438, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2347 - accuracy: 0.6696 - val_loss: 0.2344 - val_accuracy: 0.6708\n",
      "Epoch 190/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2346 - accuracy: 0.6698\n",
      "Epoch 00190: val_loss improved from 0.23438 to 0.23424, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2346 - accuracy: 0.6698 - val_loss: 0.2342 - val_accuracy: 0.6710\n",
      "Epoch 191/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2344 - accuracy: 0.6699\n",
      "Epoch 00191: val_loss improved from 0.23424 to 0.23410, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2344 - accuracy: 0.6699 - val_loss: 0.2341 - val_accuracy: 0.6710\n",
      "Epoch 192/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2343 - accuracy: 0.6701\n",
      "Epoch 00192: val_loss improved from 0.23410 to 0.23396, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2343 - accuracy: 0.6701 - val_loss: 0.2340 - val_accuracy: 0.6711\n",
      "Epoch 193/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.6703\n",
      "Epoch 00193: val_loss improved from 0.23396 to 0.23382, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2342 - accuracy: 0.6703 - val_loss: 0.2338 - val_accuracy: 0.6713\n",
      "Epoch 194/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2340 - accuracy: 0.6705\n",
      "Epoch 00194: val_loss improved from 0.23382 to 0.23369, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2340 - accuracy: 0.6705 - val_loss: 0.2337 - val_accuracy: 0.6713\n",
      "Epoch 195/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2339 - accuracy: 0.6705\n",
      "Epoch 00195: val_loss improved from 0.23369 to 0.23355, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2339 - accuracy: 0.6705 - val_loss: 0.2336 - val_accuracy: 0.6714\n",
      "Epoch 196/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2338 - accuracy: 0.6707\n",
      "Epoch 00196: val_loss improved from 0.23355 to 0.23342, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2338 - accuracy: 0.6707 - val_loss: 0.2334 - val_accuracy: 0.6716\n",
      "Epoch 197/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.6709\n",
      "Epoch 00197: val_loss improved from 0.23342 to 0.23329, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2336 - accuracy: 0.6709 - val_loss: 0.2333 - val_accuracy: 0.6718\n",
      "Epoch 198/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2335 - accuracy: 0.6710\n",
      "Epoch 00198: val_loss improved from 0.23329 to 0.23315, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2335 - accuracy: 0.6710 - val_loss: 0.2332 - val_accuracy: 0.6719\n",
      "Epoch 199/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.6711\n",
      "Epoch 00199: val_loss improved from 0.23315 to 0.23302, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2334 - accuracy: 0.6711 - val_loss: 0.2330 - val_accuracy: 0.6720\n",
      "Epoch 200/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2332 - accuracy: 0.6713\n",
      "Epoch 00200: val_loss improved from 0.23302 to 0.23289, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2332 - accuracy: 0.6713 - val_loss: 0.2329 - val_accuracy: 0.6722\n",
      "Epoch 201/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2331 - accuracy: 0.6715\n",
      "Epoch 00201: val_loss improved from 0.23289 to 0.23277, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2331 - accuracy: 0.6715 - val_loss: 0.2328 - val_accuracy: 0.6722\n",
      "Epoch 202/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.6716\n",
      "Epoch 00202: val_loss improved from 0.23277 to 0.23264, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2330 - accuracy: 0.6716 - val_loss: 0.2326 - val_accuracy: 0.6722\n",
      "Epoch 203/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2328 - accuracy: 0.6718\n",
      "Epoch 00203: val_loss improved from 0.23264 to 0.23251, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2328 - accuracy: 0.6718 - val_loss: 0.2325 - val_accuracy: 0.6723\n",
      "Epoch 204/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2327 - accuracy: 0.6719\n",
      "Epoch 00204: val_loss improved from 0.23251 to 0.23239, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2327 - accuracy: 0.6719 - val_loss: 0.2324 - val_accuracy: 0.6723\n",
      "Epoch 205/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2326 - accuracy: 0.6720\n",
      "Epoch 00205: val_loss improved from 0.23239 to 0.23226, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2326 - accuracy: 0.6720 - val_loss: 0.2323 - val_accuracy: 0.6724\n",
      "Epoch 206/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2325 - accuracy: 0.6721\n",
      "Epoch 00206: val_loss improved from 0.23226 to 0.23214, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2325 - accuracy: 0.6721 - val_loss: 0.2321 - val_accuracy: 0.6727\n",
      "Epoch 207/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2323 - accuracy: 0.6722\n",
      "Epoch 00207: val_loss improved from 0.23214 to 0.23202, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2323 - accuracy: 0.6722 - val_loss: 0.2320 - val_accuracy: 0.6728\n",
      "Epoch 208/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2322 - accuracy: 0.6724\n",
      "Epoch 00208: val_loss improved from 0.23202 to 0.23190, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2322 - accuracy: 0.6724 - val_loss: 0.2319 - val_accuracy: 0.6729\n",
      "Epoch 209/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.6725\n",
      "Epoch 00209: val_loss improved from 0.23190 to 0.23177, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2321 - accuracy: 0.6725 - val_loss: 0.2318 - val_accuracy: 0.6730\n",
      "Epoch 210/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.6726\n",
      "Epoch 00210: val_loss improved from 0.23177 to 0.23165, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2320 - accuracy: 0.6726 - val_loss: 0.2317 - val_accuracy: 0.6730\n",
      "Epoch 211/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2319 - accuracy: 0.6727\n",
      "Epoch 00211: val_loss improved from 0.23165 to 0.23153, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2319 - accuracy: 0.6727 - val_loss: 0.2315 - val_accuracy: 0.6732\n",
      "Epoch 212/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2317 - accuracy: 0.6729\n",
      "Epoch 00212: val_loss improved from 0.23153 to 0.23142, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2317 - accuracy: 0.6729 - val_loss: 0.2314 - val_accuracy: 0.6733\n",
      "Epoch 213/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2316 - accuracy: 0.6729\n",
      "Epoch 00213: val_loss improved from 0.23142 to 0.23130, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2316 - accuracy: 0.6729 - val_loss: 0.2313 - val_accuracy: 0.6736\n",
      "Epoch 214/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2315 - accuracy: 0.6731\n",
      "Epoch 00214: val_loss improved from 0.23130 to 0.23118, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2315 - accuracy: 0.6731 - val_loss: 0.2312 - val_accuracy: 0.6736\n",
      "Epoch 215/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2314 - accuracy: 0.6732\n",
      "Epoch 00215: val_loss improved from 0.23118 to 0.23107, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2314 - accuracy: 0.6732 - val_loss: 0.2311 - val_accuracy: 0.6737\n",
      "Epoch 216/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2313 - accuracy: 0.6733\n",
      "Epoch 00216: val_loss improved from 0.23107 to 0.23095, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2313 - accuracy: 0.6733 - val_loss: 0.2310 - val_accuracy: 0.6738\n",
      "Epoch 217/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2311 - accuracy: 0.6734\n",
      "Epoch 00217: val_loss improved from 0.23095 to 0.23084, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2311 - accuracy: 0.6734 - val_loss: 0.2308 - val_accuracy: 0.6738\n",
      "Epoch 218/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2310 - accuracy: 0.6735\n",
      "Epoch 00218: val_loss improved from 0.23084 to 0.23072, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2310 - accuracy: 0.6735 - val_loss: 0.2307 - val_accuracy: 0.6738\n",
      "Epoch 219/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2309 - accuracy: 0.6736\n",
      "Epoch 00219: val_loss improved from 0.23072 to 0.23061, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2309 - accuracy: 0.6736 - val_loss: 0.2306 - val_accuracy: 0.6736\n",
      "Epoch 220/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.6737\n",
      "Epoch 00220: val_loss improved from 0.23061 to 0.23050, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2308 - accuracy: 0.6737 - val_loss: 0.2305 - val_accuracy: 0.6738\n",
      "Epoch 221/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.6738\n",
      "Epoch 00221: val_loss improved from 0.23050 to 0.23039, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2307 - accuracy: 0.6738 - val_loss: 0.2304 - val_accuracy: 0.6738\n",
      "Epoch 222/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2306 - accuracy: 0.6740\n",
      "Epoch 00222: val_loss improved from 0.23039 to 0.23028, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2306 - accuracy: 0.6740 - val_loss: 0.2303 - val_accuracy: 0.6740\n",
      "Epoch 223/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2305 - accuracy: 0.6741\n",
      "Epoch 00223: val_loss improved from 0.23028 to 0.23017, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2305 - accuracy: 0.6741 - val_loss: 0.2302 - val_accuracy: 0.6742\n",
      "Epoch 224/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2304 - accuracy: 0.6742\n",
      "Epoch 00224: val_loss improved from 0.23017 to 0.23006, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2304 - accuracy: 0.6742 - val_loss: 0.2301 - val_accuracy: 0.6742\n",
      "Epoch 225/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.6743\n",
      "Epoch 00225: val_loss improved from 0.23006 to 0.22995, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2302 - accuracy: 0.6743 - val_loss: 0.2299 - val_accuracy: 0.6744\n",
      "Epoch 226/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2301 - accuracy: 0.6743\n",
      "Epoch 00226: val_loss improved from 0.22995 to 0.22984, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2301 - accuracy: 0.6743 - val_loss: 0.2298 - val_accuracy: 0.6746\n",
      "Epoch 227/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2300 - accuracy: 0.6745\n",
      "Epoch 00227: val_loss improved from 0.22984 to 0.22974, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2300 - accuracy: 0.6745 - val_loss: 0.2297 - val_accuracy: 0.6746\n",
      "Epoch 228/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2299 - accuracy: 0.6746\n",
      "Epoch 00228: val_loss improved from 0.22974 to 0.22963, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2299 - accuracy: 0.6746 - val_loss: 0.2296 - val_accuracy: 0.6746\n",
      "Epoch 229/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2298 - accuracy: 0.6747\n",
      "Epoch 00229: val_loss improved from 0.22963 to 0.22953, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2298 - accuracy: 0.6747 - val_loss: 0.2295 - val_accuracy: 0.6745\n",
      "Epoch 230/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2297 - accuracy: 0.6747\n",
      "Epoch 00230: val_loss improved from 0.22953 to 0.22942, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2297 - accuracy: 0.6747 - val_loss: 0.2294 - val_accuracy: 0.6746\n",
      "Epoch 231/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2296 - accuracy: 0.6748\n",
      "Epoch 00231: val_loss improved from 0.22942 to 0.22932, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2296 - accuracy: 0.6748 - val_loss: 0.2293 - val_accuracy: 0.6746\n",
      "Epoch 232/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2295 - accuracy: 0.6749\n",
      "Epoch 00232: val_loss improved from 0.22932 to 0.22921, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2295 - accuracy: 0.6749 - val_loss: 0.2292 - val_accuracy: 0.6749\n",
      "Epoch 233/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2294 - accuracy: 0.6750\n",
      "Epoch 00233: val_loss improved from 0.22921 to 0.22911, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2294 - accuracy: 0.6750 - val_loss: 0.2291 - val_accuracy: 0.6750\n",
      "Epoch 234/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.6751\n",
      "Epoch 00234: val_loss improved from 0.22911 to 0.22901, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2293 - accuracy: 0.6751 - val_loss: 0.2290 - val_accuracy: 0.6750\n",
      "Epoch 235/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2292 - accuracy: 0.6752\n",
      "Epoch 00235: val_loss improved from 0.22901 to 0.22891, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2292 - accuracy: 0.6752 - val_loss: 0.2289 - val_accuracy: 0.6751\n",
      "Epoch 236/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2291 - accuracy: 0.6752\n",
      "Epoch 00236: val_loss improved from 0.22891 to 0.22881, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2291 - accuracy: 0.6752 - val_loss: 0.2288 - val_accuracy: 0.6752\n",
      "Epoch 237/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2290 - accuracy: 0.6753\n",
      "Epoch 00237: val_loss improved from 0.22881 to 0.22871, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2290 - accuracy: 0.6753 - val_loss: 0.2287 - val_accuracy: 0.6754\n",
      "Epoch 238/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2289 - accuracy: 0.6754\n",
      "Epoch 00238: val_loss improved from 0.22871 to 0.22861, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2289 - accuracy: 0.6754 - val_loss: 0.2286 - val_accuracy: 0.6754\n",
      "Epoch 239/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2288 - accuracy: 0.6755\n",
      "Epoch 00239: val_loss improved from 0.22861 to 0.22852, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2288 - accuracy: 0.6755 - val_loss: 0.2285 - val_accuracy: 0.6755\n",
      "Epoch 240/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2287 - accuracy: 0.6756\n",
      "Epoch 00240: val_loss improved from 0.22852 to 0.22842, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2287 - accuracy: 0.6756 - val_loss: 0.2284 - val_accuracy: 0.6757\n",
      "Epoch 241/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.6757\n",
      "Epoch 00241: val_loss improved from 0.22842 to 0.22832, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2286 - accuracy: 0.6757 - val_loss: 0.2283 - val_accuracy: 0.6758\n",
      "Epoch 242/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.6758\n",
      "Epoch 00242: val_loss improved from 0.22832 to 0.22823, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2285 - accuracy: 0.6758 - val_loss: 0.2282 - val_accuracy: 0.6762\n",
      "Epoch 243/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2284 - accuracy: 0.6758\n",
      "Epoch 00243: val_loss improved from 0.22823 to 0.22813, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2284 - accuracy: 0.6758 - val_loss: 0.2281 - val_accuracy: 0.6763\n",
      "Epoch 244/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2283 - accuracy: 0.6759\n",
      "Epoch 00244: val_loss improved from 0.22813 to 0.22804, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2283 - accuracy: 0.6759 - val_loss: 0.2280 - val_accuracy: 0.6763\n",
      "Epoch 245/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.6760\n",
      "Epoch 00245: val_loss improved from 0.22804 to 0.22794, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2282 - accuracy: 0.6760 - val_loss: 0.2279 - val_accuracy: 0.6766\n",
      "Epoch 246/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2281 - accuracy: 0.6762\n",
      "Epoch 00246: val_loss improved from 0.22794 to 0.22785, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2281 - accuracy: 0.6762 - val_loss: 0.2279 - val_accuracy: 0.6765\n",
      "Epoch 247/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2280 - accuracy: 0.6762\n",
      "Epoch 00247: val_loss improved from 0.22785 to 0.22776, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2280 - accuracy: 0.6762 - val_loss: 0.2278 - val_accuracy: 0.6766\n",
      "Epoch 248/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2279 - accuracy: 0.6763\n",
      "Epoch 00248: val_loss improved from 0.22776 to 0.22767, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2279 - accuracy: 0.6763 - val_loss: 0.2277 - val_accuracy: 0.6767\n",
      "Epoch 249/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.6764\n",
      "Epoch 00249: val_loss improved from 0.22767 to 0.22758, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2278 - accuracy: 0.6764 - val_loss: 0.2276 - val_accuracy: 0.6768\n",
      "Epoch 250/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.6765\n",
      "Epoch 00250: val_loss improved from 0.22758 to 0.22748, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2278 - accuracy: 0.6765 - val_loss: 0.2275 - val_accuracy: 0.6769\n",
      "Epoch 251/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2277 - accuracy: 0.6766\n",
      "Epoch 00251: val_loss improved from 0.22748 to 0.22739, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2277 - accuracy: 0.6766 - val_loss: 0.2274 - val_accuracy: 0.6771\n",
      "Epoch 252/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2276 - accuracy: 0.6767\n",
      "Epoch 00252: val_loss improved from 0.22739 to 0.22730, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2276 - accuracy: 0.6767 - val_loss: 0.2273 - val_accuracy: 0.6774\n",
      "Epoch 253/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2275 - accuracy: 0.6767\n",
      "Epoch 00253: val_loss improved from 0.22730 to 0.22722, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2275 - accuracy: 0.6767 - val_loss: 0.2272 - val_accuracy: 0.6775\n",
      "Epoch 254/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.6768\n",
      "Epoch 00254: val_loss improved from 0.22722 to 0.22713, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2274 - accuracy: 0.6768 - val_loss: 0.2271 - val_accuracy: 0.6776\n",
      "Epoch 255/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.6769\n",
      "Epoch 00255: val_loss improved from 0.22713 to 0.22704, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2273 - accuracy: 0.6769 - val_loss: 0.2270 - val_accuracy: 0.6778\n",
      "Epoch 256/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2272 - accuracy: 0.6770\n",
      "Epoch 00256: val_loss improved from 0.22704 to 0.22695, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2272 - accuracy: 0.6770 - val_loss: 0.2270 - val_accuracy: 0.6779\n",
      "Epoch 257/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2271 - accuracy: 0.6771\n",
      "Epoch 00257: val_loss improved from 0.22695 to 0.22686, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2271 - accuracy: 0.6771 - val_loss: 0.2269 - val_accuracy: 0.6780\n",
      "Epoch 258/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.6772\n",
      "Epoch 00258: val_loss improved from 0.22686 to 0.22678, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2270 - accuracy: 0.6772 - val_loss: 0.2268 - val_accuracy: 0.6782\n",
      "Epoch 259/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.6773\n",
      "Epoch 00259: val_loss improved from 0.22678 to 0.22669, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2270 - accuracy: 0.6773 - val_loss: 0.2267 - val_accuracy: 0.6781\n",
      "Epoch 260/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2269 - accuracy: 0.6774\n",
      "Epoch 00260: val_loss improved from 0.22669 to 0.22661, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2269 - accuracy: 0.6774 - val_loss: 0.2266 - val_accuracy: 0.6782\n",
      "Epoch 261/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2268 - accuracy: 0.6774\n",
      "Epoch 00261: val_loss improved from 0.22661 to 0.22652, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2268 - accuracy: 0.6774 - val_loss: 0.2265 - val_accuracy: 0.6784\n",
      "Epoch 262/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2267 - accuracy: 0.6775\n",
      "Epoch 00262: val_loss improved from 0.22652 to 0.22643, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2267 - accuracy: 0.6775 - val_loss: 0.2264 - val_accuracy: 0.6785\n",
      "Epoch 263/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2266 - accuracy: 0.6776\n",
      "Epoch 00263: val_loss improved from 0.22643 to 0.22635, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2266 - accuracy: 0.6776 - val_loss: 0.2264 - val_accuracy: 0.6785\n",
      "Epoch 264/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2265 - accuracy: 0.6776\n",
      "Epoch 00264: val_loss improved from 0.22635 to 0.22627, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2265 - accuracy: 0.6776 - val_loss: 0.2263 - val_accuracy: 0.6786\n",
      "Epoch 265/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.6777\n",
      "Epoch 00265: val_loss improved from 0.22627 to 0.22618, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2264 - accuracy: 0.6777 - val_loss: 0.2262 - val_accuracy: 0.6785\n",
      "Epoch 266/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.6778\n",
      "Epoch 00266: val_loss improved from 0.22618 to 0.22610, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2264 - accuracy: 0.6778 - val_loss: 0.2261 - val_accuracy: 0.6788\n",
      "Epoch 267/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2263 - accuracy: 0.6779\n",
      "Epoch 00267: val_loss improved from 0.22610 to 0.22602, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2263 - accuracy: 0.6779 - val_loss: 0.2260 - val_accuracy: 0.6790\n",
      "Epoch 268/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2262 - accuracy: 0.6780\n",
      "Epoch 00268: val_loss improved from 0.22602 to 0.22593, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2262 - accuracy: 0.6780 - val_loss: 0.2259 - val_accuracy: 0.6791\n",
      "Epoch 269/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2261 - accuracy: 0.6781\n",
      "Epoch 00269: val_loss improved from 0.22593 to 0.22585, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2261 - accuracy: 0.6781 - val_loss: 0.2259 - val_accuracy: 0.6790\n",
      "Epoch 270/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2260 - accuracy: 0.6782\n",
      "Epoch 00270: val_loss improved from 0.22585 to 0.22577, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2260 - accuracy: 0.6782 - val_loss: 0.2258 - val_accuracy: 0.6791\n",
      "Epoch 271/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.6783\n",
      "Epoch 00271: val_loss improved from 0.22577 to 0.22569, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2259 - accuracy: 0.6783 - val_loss: 0.2257 - val_accuracy: 0.6792\n",
      "Epoch 272/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2259 - accuracy: 0.6784\n",
      "Epoch 00272: val_loss improved from 0.22569 to 0.22561, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2259 - accuracy: 0.6784 - val_loss: 0.2256 - val_accuracy: 0.6793\n",
      "Epoch 273/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2258 - accuracy: 0.6785\n",
      "Epoch 00273: val_loss improved from 0.22561 to 0.22553, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2258 - accuracy: 0.6785 - val_loss: 0.2255 - val_accuracy: 0.6792\n",
      "Epoch 274/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2257 - accuracy: 0.6785\n",
      "Epoch 00274: val_loss improved from 0.22553 to 0.22545, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2257 - accuracy: 0.6785 - val_loss: 0.2254 - val_accuracy: 0.6793\n",
      "Epoch 275/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 0.6786\n",
      "Epoch 00275: val_loss improved from 0.22545 to 0.22537, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2256 - accuracy: 0.6786 - val_loss: 0.2254 - val_accuracy: 0.6793\n",
      "Epoch 276/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2255 - accuracy: 0.6787\n",
      "Epoch 00276: val_loss improved from 0.22537 to 0.22529, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2255 - accuracy: 0.6787 - val_loss: 0.2253 - val_accuracy: 0.6794\n",
      "Epoch 277/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2255 - accuracy: 0.6789\n",
      "Epoch 00277: val_loss improved from 0.22529 to 0.22521, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2255 - accuracy: 0.6789 - val_loss: 0.2252 - val_accuracy: 0.6795\n",
      "Epoch 278/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2254 - accuracy: 0.6789\n",
      "Epoch 00278: val_loss improved from 0.22521 to 0.22513, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2254 - accuracy: 0.6789 - val_loss: 0.2251 - val_accuracy: 0.6796\n",
      "Epoch 279/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2253 - accuracy: 0.6790\n",
      "Epoch 00279: val_loss improved from 0.22513 to 0.22505, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2253 - accuracy: 0.6790 - val_loss: 0.2251 - val_accuracy: 0.6797\n",
      "Epoch 280/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2252 - accuracy: 0.6791\n",
      "Epoch 00280: val_loss improved from 0.22505 to 0.22498, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2252 - accuracy: 0.6791 - val_loss: 0.2250 - val_accuracy: 0.6797\n",
      "Epoch 281/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2251 - accuracy: 0.6792\n",
      "Epoch 00281: val_loss improved from 0.22498 to 0.22490, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2251 - accuracy: 0.6792 - val_loss: 0.2249 - val_accuracy: 0.6796\n",
      "Epoch 282/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2251 - accuracy: 0.6793\n",
      "Epoch 00282: val_loss improved from 0.22490 to 0.22482, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2251 - accuracy: 0.6793 - val_loss: 0.2248 - val_accuracy: 0.6799\n",
      "Epoch 283/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2250 - accuracy: 0.6794\n",
      "Epoch 00283: val_loss improved from 0.22482 to 0.22474, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2250 - accuracy: 0.6794 - val_loss: 0.2247 - val_accuracy: 0.6800\n",
      "Epoch 284/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2249 - accuracy: 0.6795\n",
      "Epoch 00284: val_loss improved from 0.22474 to 0.22467, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2249 - accuracy: 0.6795 - val_loss: 0.2247 - val_accuracy: 0.6800\n",
      "Epoch 285/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.6796\n",
      "Epoch 00285: val_loss improved from 0.22467 to 0.22459, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2248 - accuracy: 0.6796 - val_loss: 0.2246 - val_accuracy: 0.6801\n",
      "Epoch 286/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2248 - accuracy: 0.6797\n",
      "Epoch 00286: val_loss improved from 0.22459 to 0.22452, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2248 - accuracy: 0.6797 - val_loss: 0.2245 - val_accuracy: 0.6802\n",
      "Epoch 287/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2247 - accuracy: 0.6797\n",
      "Epoch 00287: val_loss improved from 0.22452 to 0.22444, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2247 - accuracy: 0.6797 - val_loss: 0.2244 - val_accuracy: 0.6802\n",
      "Epoch 288/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.6798\n",
      "Epoch 00288: val_loss improved from 0.22444 to 0.22437, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2246 - accuracy: 0.6798 - val_loss: 0.2244 - val_accuracy: 0.6801\n",
      "Epoch 289/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.6799\n",
      "Epoch 00289: val_loss improved from 0.22437 to 0.22429, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2245 - accuracy: 0.6799 - val_loss: 0.2243 - val_accuracy: 0.6802\n",
      "Epoch 290/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2245 - accuracy: 0.6800\n",
      "Epoch 00290: val_loss improved from 0.22429 to 0.22422, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2245 - accuracy: 0.6800 - val_loss: 0.2242 - val_accuracy: 0.6803\n",
      "Epoch 291/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.6800\n",
      "Epoch 00291: val_loss improved from 0.22422 to 0.22414, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2244 - accuracy: 0.6800 - val_loss: 0.2241 - val_accuracy: 0.6805\n",
      "Epoch 292/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2243 - accuracy: 0.6801\n",
      "Epoch 00292: val_loss improved from 0.22414 to 0.22407, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2243 - accuracy: 0.6801 - val_loss: 0.2241 - val_accuracy: 0.6806\n",
      "Epoch 293/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.6801\n",
      "Epoch 00293: val_loss improved from 0.22407 to 0.22400, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2242 - accuracy: 0.6801 - val_loss: 0.2240 - val_accuracy: 0.6805\n",
      "Epoch 294/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2242 - accuracy: 0.6802\n",
      "Epoch 00294: val_loss improved from 0.22400 to 0.22392, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2242 - accuracy: 0.6802 - val_loss: 0.2239 - val_accuracy: 0.6807\n",
      "Epoch 295/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2241 - accuracy: 0.6803\n",
      "Epoch 00295: val_loss improved from 0.22392 to 0.22385, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2241 - accuracy: 0.6803 - val_loss: 0.2239 - val_accuracy: 0.6809\n",
      "Epoch 296/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2240 - accuracy: 0.6803\n",
      "Epoch 00296: val_loss improved from 0.22385 to 0.22378, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2240 - accuracy: 0.6803 - val_loss: 0.2238 - val_accuracy: 0.6810\n",
      "Epoch 297/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.6804\n",
      "Epoch 00297: val_loss improved from 0.22378 to 0.22371, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2239 - accuracy: 0.6804 - val_loss: 0.2237 - val_accuracy: 0.6811\n",
      "Epoch 298/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.6805\n",
      "Epoch 00298: val_loss improved from 0.22371 to 0.22364, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2239 - accuracy: 0.6805 - val_loss: 0.2236 - val_accuracy: 0.6812\n",
      "Epoch 299/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2238 - accuracy: 0.6806\n",
      "Epoch 00299: val_loss improved from 0.22364 to 0.22357, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2238 - accuracy: 0.6806 - val_loss: 0.2236 - val_accuracy: 0.6814\n",
      "Epoch 300/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.6807\n",
      "Epoch 00300: val_loss improved from 0.22357 to 0.22349, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2237 - accuracy: 0.6807 - val_loss: 0.2235 - val_accuracy: 0.6814\n",
      "Epoch 301/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2237 - accuracy: 0.6807\n",
      "Epoch 00301: val_loss improved from 0.22349 to 0.22342, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2237 - accuracy: 0.6807 - val_loss: 0.2234 - val_accuracy: 0.6813\n",
      "Epoch 302/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2236 - accuracy: 0.6808\n",
      "Epoch 00302: val_loss improved from 0.22342 to 0.22335, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2236 - accuracy: 0.6808 - val_loss: 0.2234 - val_accuracy: 0.6815\n",
      "Epoch 303/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.6809\n",
      "Epoch 00303: val_loss improved from 0.22335 to 0.22328, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2235 - accuracy: 0.6809 - val_loss: 0.2233 - val_accuracy: 0.6814\n",
      "Epoch 304/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.6809\n",
      "Epoch 00304: val_loss improved from 0.22328 to 0.22321, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2234 - accuracy: 0.6809 - val_loss: 0.2232 - val_accuracy: 0.6814\n",
      "Epoch 305/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2234 - accuracy: 0.6811\n",
      "Epoch 00305: val_loss improved from 0.22321 to 0.22315, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2234 - accuracy: 0.6811 - val_loss: 0.2231 - val_accuracy: 0.6813\n",
      "Epoch 306/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2233 - accuracy: 0.6811\n",
      "Epoch 00306: val_loss improved from 0.22315 to 0.22308, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2233 - accuracy: 0.6811 - val_loss: 0.2231 - val_accuracy: 0.6814\n",
      "Epoch 307/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.6813\n",
      "Epoch 00307: val_loss improved from 0.22308 to 0.22301, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2232 - accuracy: 0.6813 - val_loss: 0.2230 - val_accuracy: 0.6815\n",
      "Epoch 308/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2232 - accuracy: 0.6814\n",
      "Epoch 00308: val_loss improved from 0.22301 to 0.22294, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2232 - accuracy: 0.6814 - val_loss: 0.2229 - val_accuracy: 0.6815\n",
      "Epoch 309/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2231 - accuracy: 0.6815\n",
      "Epoch 00309: val_loss improved from 0.22294 to 0.22287, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2231 - accuracy: 0.6815 - val_loss: 0.2229 - val_accuracy: 0.6817\n",
      "Epoch 310/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.6815\n",
      "Epoch 00310: val_loss improved from 0.22287 to 0.22280, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2230 - accuracy: 0.6815 - val_loss: 0.2228 - val_accuracy: 0.6817\n",
      "Epoch 311/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2230 - accuracy: 0.6816\n",
      "Epoch 00311: val_loss improved from 0.22280 to 0.22274, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2230 - accuracy: 0.6816 - val_loss: 0.2227 - val_accuracy: 0.6818\n",
      "Epoch 312/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2229 - accuracy: 0.6817\n",
      "Epoch 00312: val_loss improved from 0.22274 to 0.22267, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2229 - accuracy: 0.6817 - val_loss: 0.2227 - val_accuracy: 0.6819\n",
      "Epoch 313/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.6817\n",
      "Epoch 00313: val_loss improved from 0.22267 to 0.22260, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2228 - accuracy: 0.6817 - val_loss: 0.2226 - val_accuracy: 0.6823\n",
      "Epoch 314/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.6818\n",
      "Epoch 00314: val_loss improved from 0.22260 to 0.22254, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2228 - accuracy: 0.6818 - val_loss: 0.2225 - val_accuracy: 0.6824\n",
      "Epoch 315/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.6819\n",
      "Epoch 00315: val_loss improved from 0.22254 to 0.22247, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2227 - accuracy: 0.6819 - val_loss: 0.2225 - val_accuracy: 0.6824\n",
      "Epoch 316/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.6819\n",
      "Epoch 00316: val_loss improved from 0.22247 to 0.22240, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2226 - accuracy: 0.6819 - val_loss: 0.2224 - val_accuracy: 0.6824\n",
      "Epoch 317/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.6820\n",
      "Epoch 00317: val_loss improved from 0.22240 to 0.22234, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2226 - accuracy: 0.6820 - val_loss: 0.2223 - val_accuracy: 0.6826\n",
      "Epoch 318/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.6821\n",
      "Epoch 00318: val_loss improved from 0.22234 to 0.22227, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2225 - accuracy: 0.6821 - val_loss: 0.2223 - val_accuracy: 0.6827\n",
      "Epoch 319/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.6822\n",
      "Epoch 00319: val_loss improved from 0.22227 to 0.22221, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2224 - accuracy: 0.6822 - val_loss: 0.2222 - val_accuracy: 0.6829\n",
      "Epoch 320/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2224 - accuracy: 0.6823\n",
      "Epoch 00320: val_loss improved from 0.22221 to 0.22214, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2224 - accuracy: 0.6823 - val_loss: 0.2221 - val_accuracy: 0.6828\n",
      "Epoch 321/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2223 - accuracy: 0.6823\n",
      "Epoch 00321: val_loss improved from 0.22214 to 0.22208, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2223 - accuracy: 0.6823 - val_loss: 0.2221 - val_accuracy: 0.6829\n",
      "Epoch 322/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.6824\n",
      "Epoch 00322: val_loss improved from 0.22208 to 0.22202, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2222 - accuracy: 0.6824 - val_loss: 0.2220 - val_accuracy: 0.6832\n",
      "Epoch 323/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2222 - accuracy: 0.6824\n",
      "Epoch 00323: val_loss improved from 0.22202 to 0.22195, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2222 - accuracy: 0.6824 - val_loss: 0.2220 - val_accuracy: 0.6832\n",
      "Epoch 324/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.6825\n",
      "Epoch 00324: val_loss improved from 0.22195 to 0.22189, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2221 - accuracy: 0.6825 - val_loss: 0.2219 - val_accuracy: 0.6833\n",
      "Epoch 325/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.6827\n",
      "Epoch 00325: val_loss improved from 0.22189 to 0.22183, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2220 - accuracy: 0.6827 - val_loss: 0.2218 - val_accuracy: 0.6834\n",
      "Epoch 326/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2220 - accuracy: 0.6828\n",
      "Epoch 00326: val_loss improved from 0.22183 to 0.22176, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2220 - accuracy: 0.6828 - val_loss: 0.2218 - val_accuracy: 0.6834\n",
      "Epoch 327/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.6828\n",
      "Epoch 00327: val_loss improved from 0.22176 to 0.22170, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2219 - accuracy: 0.6828 - val_loss: 0.2217 - val_accuracy: 0.6834\n",
      "Epoch 328/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.6829\n",
      "Epoch 00328: val_loss improved from 0.22170 to 0.22164, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2219 - accuracy: 0.6829 - val_loss: 0.2216 - val_accuracy: 0.6835\n",
      "Epoch 329/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2218 - accuracy: 0.6829\n",
      "Epoch 00329: val_loss improved from 0.22164 to 0.22157, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2218 - accuracy: 0.6829 - val_loss: 0.2216 - val_accuracy: 0.6838\n",
      "Epoch 330/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.6830\n",
      "Epoch 00330: val_loss improved from 0.22157 to 0.22151, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2217 - accuracy: 0.6830 - val_loss: 0.2215 - val_accuracy: 0.6838\n",
      "Epoch 331/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.6831\n",
      "Epoch 00331: val_loss improved from 0.22151 to 0.22145, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2217 - accuracy: 0.6831 - val_loss: 0.2215 - val_accuracy: 0.6838\n",
      "Epoch 332/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.6831\n",
      "Epoch 00332: val_loss improved from 0.22145 to 0.22139, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2216 - accuracy: 0.6831 - val_loss: 0.2214 - val_accuracy: 0.6838\n",
      "Epoch 333/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.6832\n",
      "Epoch 00333: val_loss improved from 0.22139 to 0.22133, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2215 - accuracy: 0.6832 - val_loss: 0.2213 - val_accuracy: 0.6839\n",
      "Epoch 334/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2215 - accuracy: 0.6832\n",
      "Epoch 00334: val_loss improved from 0.22133 to 0.22127, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2215 - accuracy: 0.6832 - val_loss: 0.2213 - val_accuracy: 0.6839\n",
      "Epoch 335/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.6833\n",
      "Epoch 00335: val_loss improved from 0.22127 to 0.22121, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2214 - accuracy: 0.6833 - val_loss: 0.2212 - val_accuracy: 0.6840\n",
      "Epoch 336/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2214 - accuracy: 0.6834\n",
      "Epoch 00336: val_loss improved from 0.22121 to 0.22115, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2214 - accuracy: 0.6834 - val_loss: 0.2211 - val_accuracy: 0.6840\n",
      "Epoch 337/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2213 - accuracy: 0.6835\n",
      "Epoch 00337: val_loss improved from 0.22115 to 0.22109, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2213 - accuracy: 0.6835 - val_loss: 0.2211 - val_accuracy: 0.6841\n",
      "Epoch 338/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.6836\n",
      "Epoch 00338: val_loss improved from 0.22109 to 0.22103, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2212 - accuracy: 0.6836 - val_loss: 0.2210 - val_accuracy: 0.6840\n",
      "Epoch 339/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2212 - accuracy: 0.6837\n",
      "Epoch 00339: val_loss improved from 0.22103 to 0.22097, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2212 - accuracy: 0.6837 - val_loss: 0.2210 - val_accuracy: 0.6841\n",
      "Epoch 340/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.6837\n",
      "Epoch 00340: val_loss improved from 0.22097 to 0.22091, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2211 - accuracy: 0.6837 - val_loss: 0.2209 - val_accuracy: 0.6841\n",
      "Epoch 341/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2211 - accuracy: 0.6838\n",
      "Epoch 00341: val_loss improved from 0.22091 to 0.22085, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2211 - accuracy: 0.6838 - val_loss: 0.2209 - val_accuracy: 0.6844\n",
      "Epoch 342/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2210 - accuracy: 0.6839\n",
      "Epoch 00342: val_loss improved from 0.22085 to 0.22079, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2210 - accuracy: 0.6839 - val_loss: 0.2208 - val_accuracy: 0.6844\n",
      "Epoch 343/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.6840\n",
      "Epoch 00343: val_loss improved from 0.22079 to 0.22074, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2209 - accuracy: 0.6840 - val_loss: 0.2207 - val_accuracy: 0.6845\n",
      "Epoch 344/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2209 - accuracy: 0.6841\n",
      "Epoch 00344: val_loss improved from 0.22074 to 0.22068, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2209 - accuracy: 0.6841 - val_loss: 0.2207 - val_accuracy: 0.6846\n",
      "Epoch 345/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2208 - accuracy: 0.6841\n",
      "Epoch 00345: val_loss improved from 0.22068 to 0.22062, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2208 - accuracy: 0.6841 - val_loss: 0.2206 - val_accuracy: 0.6848\n",
      "Epoch 346/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2208 - accuracy: 0.6842\n",
      "Epoch 00346: val_loss improved from 0.22062 to 0.22056, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2208 - accuracy: 0.6842 - val_loss: 0.2206 - val_accuracy: 0.6848\n",
      "Epoch 347/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2207 - accuracy: 0.6843\n",
      "Epoch 00347: val_loss improved from 0.22056 to 0.22050, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2207 - accuracy: 0.6843 - val_loss: 0.2205 - val_accuracy: 0.6848\n",
      "Epoch 348/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2207 - accuracy: 0.6844\n",
      "Epoch 00348: val_loss improved from 0.22050 to 0.22045, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2207 - accuracy: 0.6844 - val_loss: 0.2204 - val_accuracy: 0.6848\n",
      "Epoch 349/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2206 - accuracy: 0.6844\n",
      "Epoch 00349: val_loss improved from 0.22045 to 0.22039, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2206 - accuracy: 0.6844 - val_loss: 0.2204 - val_accuracy: 0.6848\n",
      "Epoch 350/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2205 - accuracy: 0.6845\n",
      "Epoch 00350: val_loss improved from 0.22039 to 0.22033, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2205 - accuracy: 0.6845 - val_loss: 0.2203 - val_accuracy: 0.6850\n",
      "Epoch 351/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2205 - accuracy: 0.6847\n",
      "Epoch 00351: val_loss improved from 0.22033 to 0.22028, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2205 - accuracy: 0.6847 - val_loss: 0.2203 - val_accuracy: 0.6850\n",
      "Epoch 352/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2204 - accuracy: 0.6847\n",
      "Epoch 00352: val_loss improved from 0.22028 to 0.22022, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2204 - accuracy: 0.6847 - val_loss: 0.2202 - val_accuracy: 0.6850\n",
      "Epoch 353/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2204 - accuracy: 0.6848\n",
      "Epoch 00353: val_loss improved from 0.22022 to 0.22017, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2204 - accuracy: 0.6848 - val_loss: 0.2202 - val_accuracy: 0.6850\n",
      "Epoch 354/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.6848\n",
      "Epoch 00354: val_loss improved from 0.22017 to 0.22011, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2203 - accuracy: 0.6848 - val_loss: 0.2201 - val_accuracy: 0.6851\n",
      "Epoch 355/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2203 - accuracy: 0.6849\n",
      "Epoch 00355: val_loss improved from 0.22011 to 0.22006, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2203 - accuracy: 0.6849 - val_loss: 0.2201 - val_accuracy: 0.6854\n",
      "Epoch 356/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.6850\n",
      "Epoch 00356: val_loss improved from 0.22006 to 0.22000, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2202 - accuracy: 0.6850 - val_loss: 0.2200 - val_accuracy: 0.6856\n",
      "Epoch 357/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2202 - accuracy: 0.6850\n",
      "Epoch 00357: val_loss improved from 0.22000 to 0.21995, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2202 - accuracy: 0.6850 - val_loss: 0.2199 - val_accuracy: 0.6856\n",
      "Epoch 358/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2201 - accuracy: 0.6850\n",
      "Epoch 00358: val_loss improved from 0.21995 to 0.21989, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2201 - accuracy: 0.6850 - val_loss: 0.2199 - val_accuracy: 0.6858\n",
      "Epoch 359/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.6851\n",
      "Epoch 00359: val_loss improved from 0.21989 to 0.21984, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2200 - accuracy: 0.6851 - val_loss: 0.2198 - val_accuracy: 0.6858\n",
      "Epoch 360/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2200 - accuracy: 0.6851\n",
      "Epoch 00360: val_loss improved from 0.21984 to 0.21978, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2200 - accuracy: 0.6851 - val_loss: 0.2198 - val_accuracy: 0.6859\n",
      "Epoch 361/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.6853\n",
      "Epoch 00361: val_loss improved from 0.21978 to 0.21973, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2199 - accuracy: 0.6853 - val_loss: 0.2197 - val_accuracy: 0.6861\n",
      "Epoch 362/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2199 - accuracy: 0.6853\n",
      "Epoch 00362: val_loss improved from 0.21973 to 0.21968, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2199 - accuracy: 0.6853 - val_loss: 0.2197 - val_accuracy: 0.6863\n",
      "Epoch 363/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2198 - accuracy: 0.6854\n",
      "Epoch 00363: val_loss improved from 0.21968 to 0.21962, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2198 - accuracy: 0.6854 - val_loss: 0.2196 - val_accuracy: 0.6863\n",
      "Epoch 364/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2198 - accuracy: 0.6855\n",
      "Epoch 00364: val_loss improved from 0.21962 to 0.21957, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2198 - accuracy: 0.6855 - val_loss: 0.2196 - val_accuracy: 0.6864\n",
      "Epoch 365/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.6855\n",
      "Epoch 00365: val_loss improved from 0.21957 to 0.21952, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2197 - accuracy: 0.6855 - val_loss: 0.2195 - val_accuracy: 0.6864\n",
      "Epoch 366/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2197 - accuracy: 0.6857\n",
      "Epoch 00366: val_loss improved from 0.21952 to 0.21947, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2197 - accuracy: 0.6857 - val_loss: 0.2195 - val_accuracy: 0.6866\n",
      "Epoch 367/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.6857\n",
      "Epoch 00367: val_loss improved from 0.21947 to 0.21941, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2196 - accuracy: 0.6857 - val_loss: 0.2194 - val_accuracy: 0.6868\n",
      "Epoch 368/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2196 - accuracy: 0.6857\n",
      "Epoch 00368: val_loss improved from 0.21941 to 0.21936, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2196 - accuracy: 0.6857 - val_loss: 0.2194 - val_accuracy: 0.6867\n",
      "Epoch 369/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.6858\n",
      "Epoch 00369: val_loss improved from 0.21936 to 0.21931, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2195 - accuracy: 0.6858 - val_loss: 0.2193 - val_accuracy: 0.6869\n",
      "Epoch 370/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.6858\n",
      "Epoch 00370: val_loss improved from 0.21931 to 0.21926, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2195 - accuracy: 0.6858 - val_loss: 0.2193 - val_accuracy: 0.6869\n",
      "Epoch 371/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.6859\n",
      "Epoch 00371: val_loss improved from 0.21926 to 0.21921, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2194 - accuracy: 0.6859 - val_loss: 0.2192 - val_accuracy: 0.6869\n",
      "Epoch 372/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2194 - accuracy: 0.6860\n",
      "Epoch 00372: val_loss improved from 0.21921 to 0.21916, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2194 - accuracy: 0.6860 - val_loss: 0.2192 - val_accuracy: 0.6869\n",
      "Epoch 373/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2193 - accuracy: 0.6861\n",
      "Epoch 00373: val_loss improved from 0.21916 to 0.21911, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2193 - accuracy: 0.6861 - val_loss: 0.2191 - val_accuracy: 0.6869\n",
      "Epoch 374/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.6861\n",
      "Epoch 00374: val_loss improved from 0.21911 to 0.21906, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2192 - accuracy: 0.6861 - val_loss: 0.2191 - val_accuracy: 0.6871\n",
      "Epoch 375/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2192 - accuracy: 0.6862\n",
      "Epoch 00375: val_loss improved from 0.21906 to 0.21901, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2192 - accuracy: 0.6862 - val_loss: 0.2190 - val_accuracy: 0.6872\n",
      "Epoch 376/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.6862\n",
      "Epoch 00376: val_loss improved from 0.21901 to 0.21896, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2191 - accuracy: 0.6862 - val_loss: 0.2190 - val_accuracy: 0.6872\n",
      "Epoch 377/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2191 - accuracy: 0.6863\n",
      "Epoch 00377: val_loss improved from 0.21896 to 0.21891, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2191 - accuracy: 0.6863 - val_loss: 0.2189 - val_accuracy: 0.6873\n",
      "Epoch 378/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.6863\n",
      "Epoch 00378: val_loss improved from 0.21891 to 0.21886, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2190 - accuracy: 0.6863 - val_loss: 0.2189 - val_accuracy: 0.6873\n",
      "Epoch 379/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2190 - accuracy: 0.6864\n",
      "Epoch 00379: val_loss improved from 0.21886 to 0.21881, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2190 - accuracy: 0.6864 - val_loss: 0.2188 - val_accuracy: 0.6874\n",
      "Epoch 380/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.6865\n",
      "Epoch 00380: val_loss improved from 0.21881 to 0.21876, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2189 - accuracy: 0.6865 - val_loss: 0.2188 - val_accuracy: 0.6875\n",
      "Epoch 381/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2189 - accuracy: 0.6865\n",
      "Epoch 00381: val_loss improved from 0.21876 to 0.21871, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2189 - accuracy: 0.6865 - val_loss: 0.2187 - val_accuracy: 0.6876\n",
      "Epoch 382/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.6866\n",
      "Epoch 00382: val_loss improved from 0.21871 to 0.21866, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2188 - accuracy: 0.6866 - val_loss: 0.2187 - val_accuracy: 0.6877\n",
      "Epoch 383/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.6866\n",
      "Epoch 00383: val_loss improved from 0.21866 to 0.21861, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2188 - accuracy: 0.6866 - val_loss: 0.2186 - val_accuracy: 0.6878\n",
      "Epoch 384/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2188 - accuracy: 0.6867\n",
      "Epoch 00384: val_loss improved from 0.21861 to 0.21857, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2188 - accuracy: 0.6867 - val_loss: 0.2186 - val_accuracy: 0.6879\n",
      "Epoch 385/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.6868\n",
      "Epoch 00385: val_loss improved from 0.21857 to 0.21852, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2187 - accuracy: 0.6868 - val_loss: 0.2185 - val_accuracy: 0.6880\n",
      "Epoch 386/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.6869\n",
      "Epoch 00386: val_loss improved from 0.21852 to 0.21847, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2187 - accuracy: 0.6869 - val_loss: 0.2185 - val_accuracy: 0.6880\n",
      "Epoch 387/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.6870\n",
      "Epoch 00387: val_loss improved from 0.21847 to 0.21842, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2186 - accuracy: 0.6870 - val_loss: 0.2184 - val_accuracy: 0.6880\n",
      "Epoch 388/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2186 - accuracy: 0.6870\n",
      "Epoch 00388: val_loss improved from 0.21842 to 0.21837, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2186 - accuracy: 0.6870 - val_loss: 0.2184 - val_accuracy: 0.6882\n",
      "Epoch 389/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.6871\n",
      "Epoch 00389: val_loss improved from 0.21837 to 0.21833, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2185 - accuracy: 0.6871 - val_loss: 0.2183 - val_accuracy: 0.6883\n",
      "Epoch 390/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.6872\n",
      "Epoch 00390: val_loss improved from 0.21833 to 0.21828, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2185 - accuracy: 0.6872 - val_loss: 0.2183 - val_accuracy: 0.6885\n",
      "Epoch 391/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.6872\n",
      "Epoch 00391: val_loss improved from 0.21828 to 0.21823, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2184 - accuracy: 0.6872 - val_loss: 0.2182 - val_accuracy: 0.6885\n",
      "Epoch 392/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.6873\n",
      "Epoch 00392: val_loss improved from 0.21823 to 0.21819, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2184 - accuracy: 0.6873 - val_loss: 0.2182 - val_accuracy: 0.6887\n",
      "Epoch 393/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.6874\n",
      "Epoch 00393: val_loss improved from 0.21819 to 0.21814, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2183 - accuracy: 0.6874 - val_loss: 0.2181 - val_accuracy: 0.6887\n",
      "Epoch 394/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2183 - accuracy: 0.6874\n",
      "Epoch 00394: val_loss improved from 0.21814 to 0.21809, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2183 - accuracy: 0.6874 - val_loss: 0.2181 - val_accuracy: 0.6887\n",
      "Epoch 395/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.6875\n",
      "Epoch 00395: val_loss improved from 0.21809 to 0.21805, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2182 - accuracy: 0.6875 - val_loss: 0.2180 - val_accuracy: 0.6888\n",
      "Epoch 396/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2182 - accuracy: 0.6876\n",
      "Epoch 00396: val_loss improved from 0.21805 to 0.21800, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2182 - accuracy: 0.6876 - val_loss: 0.2180 - val_accuracy: 0.6888\n",
      "Epoch 397/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.6877\n",
      "Epoch 00397: val_loss improved from 0.21800 to 0.21796, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2181 - accuracy: 0.6877 - val_loss: 0.2180 - val_accuracy: 0.6888\n",
      "Epoch 398/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.6877\n",
      "Epoch 00398: val_loss improved from 0.21796 to 0.21791, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2181 - accuracy: 0.6877 - val_loss: 0.2179 - val_accuracy: 0.6889\n",
      "Epoch 399/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.6878\n",
      "Epoch 00399: val_loss improved from 0.21791 to 0.21787, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2180 - accuracy: 0.6878 - val_loss: 0.2179 - val_accuracy: 0.6889\n",
      "Epoch 400/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.6878\n",
      "Epoch 00400: val_loss improved from 0.21787 to 0.21782, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2180 - accuracy: 0.6878 - val_loss: 0.2178 - val_accuracy: 0.6889\n",
      "Epoch 401/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.6879\n",
      "Epoch 00401: val_loss improved from 0.21782 to 0.21778, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2180 - accuracy: 0.6879 - val_loss: 0.2178 - val_accuracy: 0.6890\n",
      "Epoch 402/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2179 - accuracy: 0.6879\n",
      "Epoch 00402: val_loss improved from 0.21778 to 0.21773, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2179 - accuracy: 0.6879 - val_loss: 0.2177 - val_accuracy: 0.6892\n",
      "Epoch 403/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2179 - accuracy: 0.6880\n",
      "Epoch 00403: val_loss improved from 0.21773 to 0.21769, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2179 - accuracy: 0.6880 - val_loss: 0.2177 - val_accuracy: 0.6893\n",
      "Epoch 404/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.6880\n",
      "Epoch 00404: val_loss improved from 0.21769 to 0.21764, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2178 - accuracy: 0.6880 - val_loss: 0.2176 - val_accuracy: 0.6893\n",
      "Epoch 405/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2178 - accuracy: 0.6881\n",
      "Epoch 00405: val_loss improved from 0.21764 to 0.21760, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2178 - accuracy: 0.6881 - val_loss: 0.2176 - val_accuracy: 0.6893\n",
      "Epoch 406/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.6881\n",
      "Epoch 00406: val_loss improved from 0.21760 to 0.21756, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2177 - accuracy: 0.6881 - val_loss: 0.2176 - val_accuracy: 0.6893\n",
      "Epoch 407/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2177 - accuracy: 0.6882\n",
      "Epoch 00407: val_loss improved from 0.21756 to 0.21751, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2177 - accuracy: 0.6882 - val_loss: 0.2175 - val_accuracy: 0.6893\n",
      "Epoch 408/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.6882\n",
      "Epoch 00408: val_loss improved from 0.21751 to 0.21747, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2176 - accuracy: 0.6882 - val_loss: 0.2175 - val_accuracy: 0.6894\n",
      "Epoch 409/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.6883\n",
      "Epoch 00409: val_loss improved from 0.21747 to 0.21743, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2176 - accuracy: 0.6883 - val_loss: 0.2174 - val_accuracy: 0.6894\n",
      "Epoch 410/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.6883\n",
      "Epoch 00410: val_loss improved from 0.21743 to 0.21738, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2176 - accuracy: 0.6883 - val_loss: 0.2174 - val_accuracy: 0.6894\n",
      "Epoch 411/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.6884\n",
      "Epoch 00411: val_loss improved from 0.21738 to 0.21734, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2175 - accuracy: 0.6884 - val_loss: 0.2173 - val_accuracy: 0.6896\n",
      "Epoch 412/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2175 - accuracy: 0.6884\n",
      "Epoch 00412: val_loss improved from 0.21734 to 0.21730, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2175 - accuracy: 0.6884 - val_loss: 0.2173 - val_accuracy: 0.6897\n",
      "Epoch 413/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.6885\n",
      "Epoch 00413: val_loss improved from 0.21730 to 0.21725, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2174 - accuracy: 0.6885 - val_loss: 0.2173 - val_accuracy: 0.6899\n",
      "Epoch 414/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2174 - accuracy: 0.6886\n",
      "Epoch 00414: val_loss improved from 0.21725 to 0.21721, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2174 - accuracy: 0.6886 - val_loss: 0.2172 - val_accuracy: 0.6899\n",
      "Epoch 415/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2173 - accuracy: 0.6886\n",
      "Epoch 00415: val_loss improved from 0.21721 to 0.21717, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2173 - accuracy: 0.6886 - val_loss: 0.2172 - val_accuracy: 0.6899\n",
      "Epoch 416/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2173 - accuracy: 0.6887\n",
      "Epoch 00416: val_loss improved from 0.21717 to 0.21713, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2173 - accuracy: 0.6887 - val_loss: 0.2171 - val_accuracy: 0.6899\n",
      "Epoch 417/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2173 - accuracy: 0.6888\n",
      "Epoch 00417: val_loss improved from 0.21713 to 0.21709, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2173 - accuracy: 0.6888 - val_loss: 0.2171 - val_accuracy: 0.6900\n",
      "Epoch 418/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2172 - accuracy: 0.6888\n",
      "Epoch 00418: val_loss improved from 0.21709 to 0.21705, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2172 - accuracy: 0.6888 - val_loss: 0.2170 - val_accuracy: 0.6900\n",
      "Epoch 419/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2172 - accuracy: 0.6889\n",
      "Epoch 00419: val_loss improved from 0.21705 to 0.21700, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2172 - accuracy: 0.6889 - val_loss: 0.2170 - val_accuracy: 0.6900\n",
      "Epoch 420/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.6890\n",
      "Epoch 00420: val_loss improved from 0.21700 to 0.21696, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2171 - accuracy: 0.6890 - val_loss: 0.2170 - val_accuracy: 0.6900\n",
      "Epoch 421/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.6890\n",
      "Epoch 00421: val_loss improved from 0.21696 to 0.21692, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2171 - accuracy: 0.6890 - val_loss: 0.2169 - val_accuracy: 0.6901\n",
      "Epoch 422/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2170 - accuracy: 0.6890\n",
      "Epoch 00422: val_loss improved from 0.21692 to 0.21688, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2170 - accuracy: 0.6890 - val_loss: 0.2169 - val_accuracy: 0.6901\n",
      "Epoch 423/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2170 - accuracy: 0.6891\n",
      "Epoch 00423: val_loss improved from 0.21688 to 0.21684, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2170 - accuracy: 0.6891 - val_loss: 0.2168 - val_accuracy: 0.6902\n",
      "Epoch 424/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2170 - accuracy: 0.6892\n",
      "Epoch 00424: val_loss improved from 0.21684 to 0.21680, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2170 - accuracy: 0.6892 - val_loss: 0.2168 - val_accuracy: 0.6904\n",
      "Epoch 425/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.6892\n",
      "Epoch 00425: val_loss improved from 0.21680 to 0.21676, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2169 - accuracy: 0.6892 - val_loss: 0.2168 - val_accuracy: 0.6904\n",
      "Epoch 426/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2169 - accuracy: 0.6893\n",
      "Epoch 00426: val_loss improved from 0.21676 to 0.21672, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2169 - accuracy: 0.6893 - val_loss: 0.2167 - val_accuracy: 0.6905\n",
      "Epoch 427/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.6894\n",
      "Epoch 00427: val_loss improved from 0.21672 to 0.21668, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2168 - accuracy: 0.6894 - val_loss: 0.2167 - val_accuracy: 0.6905\n",
      "Epoch 428/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.6894\n",
      "Epoch 00428: val_loss improved from 0.21668 to 0.21664, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2168 - accuracy: 0.6894 - val_loss: 0.2166 - val_accuracy: 0.6905\n",
      "Epoch 429/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2168 - accuracy: 0.6895\n",
      "Epoch 00429: val_loss improved from 0.21664 to 0.21660, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2168 - accuracy: 0.6895 - val_loss: 0.2166 - val_accuracy: 0.6906\n",
      "Epoch 430/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.6896\n",
      "Epoch 00430: val_loss improved from 0.21660 to 0.21656, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2167 - accuracy: 0.6896 - val_loss: 0.2166 - val_accuracy: 0.6907\n",
      "Epoch 431/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2167 - accuracy: 0.6896\n",
      "Epoch 00431: val_loss improved from 0.21656 to 0.21652, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2167 - accuracy: 0.6896 - val_loss: 0.2165 - val_accuracy: 0.6906\n",
      "Epoch 432/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.6896\n",
      "Epoch 00432: val_loss improved from 0.21652 to 0.21648, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2166 - accuracy: 0.6896 - val_loss: 0.2165 - val_accuracy: 0.6907\n",
      "Epoch 433/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.6897\n",
      "Epoch 00433: val_loss improved from 0.21648 to 0.21644, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 630ms/step - loss: 0.2166 - accuracy: 0.6897 - val_loss: 0.2164 - val_accuracy: 0.6908\n",
      "Epoch 434/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2166 - accuracy: 0.6898\n",
      "Epoch 00434: val_loss improved from 0.21644 to 0.21640, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2166 - accuracy: 0.6898 - val_loss: 0.2164 - val_accuracy: 0.6907\n",
      "Epoch 435/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.6899\n",
      "Epoch 00435: val_loss improved from 0.21640 to 0.21636, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2165 - accuracy: 0.6899 - val_loss: 0.2164 - val_accuracy: 0.6907\n",
      "Epoch 436/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2165 - accuracy: 0.6899\n",
      "Epoch 00436: val_loss improved from 0.21636 to 0.21633, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2165 - accuracy: 0.6899 - val_loss: 0.2163 - val_accuracy: 0.6907\n",
      "Epoch 437/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.6899\n",
      "Epoch 00437: val_loss improved from 0.21633 to 0.21629, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 630ms/step - loss: 0.2164 - accuracy: 0.6899 - val_loss: 0.2163 - val_accuracy: 0.6907\n",
      "Epoch 438/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.6900\n",
      "Epoch 00438: val_loss improved from 0.21629 to 0.21625, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2164 - accuracy: 0.6900 - val_loss: 0.2162 - val_accuracy: 0.6907\n",
      "Epoch 439/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2164 - accuracy: 0.6900\n",
      "Epoch 00439: val_loss improved from 0.21625 to 0.21621, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2164 - accuracy: 0.6900 - val_loss: 0.2162 - val_accuracy: 0.6907\n",
      "Epoch 440/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2163 - accuracy: 0.6901\n",
      "Epoch 00440: val_loss improved from 0.21621 to 0.21617, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2163 - accuracy: 0.6901 - val_loss: 0.2162 - val_accuracy: 0.6908\n",
      "Epoch 441/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2163 - accuracy: 0.6902\n",
      "Epoch 00441: val_loss improved from 0.21617 to 0.21613, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2163 - accuracy: 0.6902 - val_loss: 0.2161 - val_accuracy: 0.6908\n",
      "Epoch 442/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.6902\n",
      "Epoch 00442: val_loss improved from 0.21613 to 0.21610, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2162 - accuracy: 0.6902 - val_loss: 0.2161 - val_accuracy: 0.6909\n",
      "Epoch 443/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.6903\n",
      "Epoch 00443: val_loss improved from 0.21610 to 0.21606, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2162 - accuracy: 0.6903 - val_loss: 0.2161 - val_accuracy: 0.6909\n",
      "Epoch 444/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.6903\n",
      "Epoch 00444: val_loss improved from 0.21606 to 0.21602, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2162 - accuracy: 0.6903 - val_loss: 0.2160 - val_accuracy: 0.6910\n",
      "Epoch 445/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.6904\n",
      "Epoch 00445: val_loss improved from 0.21602 to 0.21599, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2161 - accuracy: 0.6904 - val_loss: 0.2160 - val_accuracy: 0.6911\n",
      "Epoch 446/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.6904\n",
      "Epoch 00446: val_loss improved from 0.21599 to 0.21595, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2161 - accuracy: 0.6904 - val_loss: 0.2159 - val_accuracy: 0.6911\n",
      "Epoch 447/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2161 - accuracy: 0.6905\n",
      "Epoch 00447: val_loss improved from 0.21595 to 0.21591, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2161 - accuracy: 0.6905 - val_loss: 0.2159 - val_accuracy: 0.6910\n",
      "Epoch 448/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.6906\n",
      "Epoch 00448: val_loss improved from 0.21591 to 0.21587, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2160 - accuracy: 0.6906 - val_loss: 0.2159 - val_accuracy: 0.6910\n",
      "Epoch 449/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2160 - accuracy: 0.6906\n",
      "Epoch 00449: val_loss improved from 0.21587 to 0.21584, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2160 - accuracy: 0.6906 - val_loss: 0.2158 - val_accuracy: 0.6911\n",
      "Epoch 450/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.6907\n",
      "Epoch 00450: val_loss improved from 0.21584 to 0.21580, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2159 - accuracy: 0.6907 - val_loss: 0.2158 - val_accuracy: 0.6912\n",
      "Epoch 451/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.6908\n",
      "Epoch 00451: val_loss improved from 0.21580 to 0.21576, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2159 - accuracy: 0.6908 - val_loss: 0.2158 - val_accuracy: 0.6913\n",
      "Epoch 452/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2159 - accuracy: 0.6909\n",
      "Epoch 00452: val_loss improved from 0.21576 to 0.21573, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2159 - accuracy: 0.6909 - val_loss: 0.2157 - val_accuracy: 0.6914\n",
      "Epoch 453/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.6909\n",
      "Epoch 00453: val_loss improved from 0.21573 to 0.21569, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2158 - accuracy: 0.6909 - val_loss: 0.2157 - val_accuracy: 0.6914\n",
      "Epoch 454/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.6910\n",
      "Epoch 00454: val_loss improved from 0.21569 to 0.21566, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2158 - accuracy: 0.6910 - val_loss: 0.2157 - val_accuracy: 0.6916\n",
      "Epoch 455/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2158 - accuracy: 0.6910\n",
      "Epoch 00455: val_loss improved from 0.21566 to 0.21562, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2158 - accuracy: 0.6910 - val_loss: 0.2156 - val_accuracy: 0.6916\n",
      "Epoch 456/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 0.6911\n",
      "Epoch 00456: val_loss improved from 0.21562 to 0.21558, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2157 - accuracy: 0.6911 - val_loss: 0.2156 - val_accuracy: 0.6916\n",
      "Epoch 457/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 0.6911\n",
      "Epoch 00457: val_loss improved from 0.21558 to 0.21555, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2157 - accuracy: 0.6911 - val_loss: 0.2155 - val_accuracy: 0.6917\n",
      "Epoch 458/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.6911\n",
      "Epoch 00458: val_loss improved from 0.21555 to 0.21551, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2156 - accuracy: 0.6911 - val_loss: 0.2155 - val_accuracy: 0.6918\n",
      "Epoch 459/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.6912\n",
      "Epoch 00459: val_loss improved from 0.21551 to 0.21548, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2156 - accuracy: 0.6912 - val_loss: 0.2155 - val_accuracy: 0.6920\n",
      "Epoch 460/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2156 - accuracy: 0.6912\n",
      "Epoch 00460: val_loss improved from 0.21548 to 0.21544, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2156 - accuracy: 0.6912 - val_loss: 0.2154 - val_accuracy: 0.6920\n",
      "Epoch 461/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.6913\n",
      "Epoch 00461: val_loss improved from 0.21544 to 0.21541, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2155 - accuracy: 0.6913 - val_loss: 0.2154 - val_accuracy: 0.6921\n",
      "Epoch 462/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.6914\n",
      "Epoch 00462: val_loss improved from 0.21541 to 0.21537, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2155 - accuracy: 0.6914 - val_loss: 0.2154 - val_accuracy: 0.6921\n",
      "Epoch 463/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2155 - accuracy: 0.6914\n",
      "Epoch 00463: val_loss improved from 0.21537 to 0.21534, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2155 - accuracy: 0.6914 - val_loss: 0.2153 - val_accuracy: 0.6921\n",
      "Epoch 464/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.6914\n",
      "Epoch 00464: val_loss improved from 0.21534 to 0.21530, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2154 - accuracy: 0.6914 - val_loss: 0.2153 - val_accuracy: 0.6921\n",
      "Epoch 465/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.6915\n",
      "Epoch 00465: val_loss improved from 0.21530 to 0.21527, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2154 - accuracy: 0.6915 - val_loss: 0.2153 - val_accuracy: 0.6921\n",
      "Epoch 466/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2154 - accuracy: 0.6915\n",
      "Epoch 00466: val_loss improved from 0.21527 to 0.21523, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2154 - accuracy: 0.6915 - val_loss: 0.2152 - val_accuracy: 0.6922\n",
      "Epoch 467/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2153 - accuracy: 0.6915\n",
      "Epoch 00467: val_loss improved from 0.21523 to 0.21520, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2153 - accuracy: 0.6915 - val_loss: 0.2152 - val_accuracy: 0.6922\n",
      "Epoch 468/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2153 - accuracy: 0.6915\n",
      "Epoch 00468: val_loss improved from 0.21520 to 0.21516, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2153 - accuracy: 0.6915 - val_loss: 0.2152 - val_accuracy: 0.6923\n",
      "Epoch 469/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2153 - accuracy: 0.6916\n",
      "Epoch 00469: val_loss improved from 0.21516 to 0.21513, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2153 - accuracy: 0.6916 - val_loss: 0.2151 - val_accuracy: 0.6922\n",
      "Epoch 470/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.6916\n",
      "Epoch 00470: val_loss improved from 0.21513 to 0.21510, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2152 - accuracy: 0.6916 - val_loss: 0.2151 - val_accuracy: 0.6922\n",
      "Epoch 471/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.6917\n",
      "Epoch 00471: val_loss improved from 0.21510 to 0.21506, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2152 - accuracy: 0.6917 - val_loss: 0.2151 - val_accuracy: 0.6923\n",
      "Epoch 472/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.6917\n",
      "Epoch 00472: val_loss improved from 0.21506 to 0.21503, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2152 - accuracy: 0.6917 - val_loss: 0.2150 - val_accuracy: 0.6923\n",
      "Epoch 473/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.6917\n",
      "Epoch 00473: val_loss improved from 0.21503 to 0.21499, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2151 - accuracy: 0.6917 - val_loss: 0.2150 - val_accuracy: 0.6923\n",
      "Epoch 474/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.6917\n",
      "Epoch 00474: val_loss improved from 0.21499 to 0.21496, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2151 - accuracy: 0.6917 - val_loss: 0.2150 - val_accuracy: 0.6926\n",
      "Epoch 475/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.6918\n",
      "Epoch 00475: val_loss improved from 0.21496 to 0.21493, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2151 - accuracy: 0.6918 - val_loss: 0.2149 - val_accuracy: 0.6927\n",
      "Epoch 476/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2150 - accuracy: 0.6918\n",
      "Epoch 00476: val_loss improved from 0.21493 to 0.21489, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2150 - accuracy: 0.6918 - val_loss: 0.2149 - val_accuracy: 0.6926\n",
      "Epoch 477/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2150 - accuracy: 0.6919\n",
      "Epoch 00477: val_loss improved from 0.21489 to 0.21486, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2150 - accuracy: 0.6919 - val_loss: 0.2149 - val_accuracy: 0.6926\n",
      "Epoch 478/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2150 - accuracy: 0.6919\n",
      "Epoch 00478: val_loss improved from 0.21486 to 0.21483, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 630ms/step - loss: 0.2150 - accuracy: 0.6919 - val_loss: 0.2148 - val_accuracy: 0.6926\n",
      "Epoch 479/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.6920\n",
      "Epoch 00479: val_loss improved from 0.21483 to 0.21480, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2149 - accuracy: 0.6920 - val_loss: 0.2148 - val_accuracy: 0.6928\n",
      "Epoch 480/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.6921\n",
      "Epoch 00480: val_loss improved from 0.21480 to 0.21476, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2149 - accuracy: 0.6921 - val_loss: 0.2148 - val_accuracy: 0.6929\n",
      "Epoch 481/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.6921\n",
      "Epoch 00481: val_loss improved from 0.21476 to 0.21473, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2149 - accuracy: 0.6921 - val_loss: 0.2147 - val_accuracy: 0.6929\n",
      "Epoch 482/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.6921\n",
      "Epoch 00482: val_loss improved from 0.21473 to 0.21470, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2148 - accuracy: 0.6921 - val_loss: 0.2147 - val_accuracy: 0.6929\n",
      "Epoch 483/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.6922\n",
      "Epoch 00483: val_loss improved from 0.21470 to 0.21466, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2148 - accuracy: 0.6922 - val_loss: 0.2147 - val_accuracy: 0.6930\n",
      "Epoch 484/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.6922\n",
      "Epoch 00484: val_loss improved from 0.21466 to 0.21463, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2148 - accuracy: 0.6922 - val_loss: 0.2146 - val_accuracy: 0.6930\n",
      "Epoch 485/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.6922\n",
      "Epoch 00485: val_loss improved from 0.21463 to 0.21460, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2147 - accuracy: 0.6922 - val_loss: 0.2146 - val_accuracy: 0.6930\n",
      "Epoch 486/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.6922\n",
      "Epoch 00486: val_loss improved from 0.21460 to 0.21457, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2147 - accuracy: 0.6922 - val_loss: 0.2146 - val_accuracy: 0.6930\n",
      "Epoch 487/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.6923\n",
      "Epoch 00487: val_loss improved from 0.21457 to 0.21454, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2147 - accuracy: 0.6923 - val_loss: 0.2145 - val_accuracy: 0.6930\n",
      "Epoch 488/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.6923\n",
      "Epoch 00488: val_loss improved from 0.21454 to 0.21450, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2146 - accuracy: 0.6923 - val_loss: 0.2145 - val_accuracy: 0.6930\n",
      "Epoch 489/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.6923\n",
      "Epoch 00489: val_loss improved from 0.21450 to 0.21447, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2146 - accuracy: 0.6923 - val_loss: 0.2145 - val_accuracy: 0.6930\n",
      "Epoch 490/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2146 - accuracy: 0.6923\n",
      "Epoch 00490: val_loss improved from 0.21447 to 0.21444, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2146 - accuracy: 0.6923 - val_loss: 0.2144 - val_accuracy: 0.6930\n",
      "Epoch 491/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.6924\n",
      "Epoch 00491: val_loss improved from 0.21444 to 0.21441, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2145 - accuracy: 0.6924 - val_loss: 0.2144 - val_accuracy: 0.6929\n",
      "Epoch 492/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.6924\n",
      "Epoch 00492: val_loss improved from 0.21441 to 0.21438, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2145 - accuracy: 0.6924 - val_loss: 0.2144 - val_accuracy: 0.6930\n",
      "Epoch 493/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.6924\n",
      "Epoch 00493: val_loss improved from 0.21438 to 0.21434, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2145 - accuracy: 0.6924 - val_loss: 0.2143 - val_accuracy: 0.6929\n",
      "Epoch 494/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 0.6925\n",
      "Epoch 00494: val_loss improved from 0.21434 to 0.21431, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 630ms/step - loss: 0.2144 - accuracy: 0.6925 - val_loss: 0.2143 - val_accuracy: 0.6930\n",
      "Epoch 495/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 0.6926\n",
      "Epoch 00495: val_loss improved from 0.21431 to 0.21428, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2144 - accuracy: 0.6926 - val_loss: 0.2143 - val_accuracy: 0.6930\n",
      "Epoch 496/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2144 - accuracy: 0.6926\n",
      "Epoch 00496: val_loss improved from 0.21428 to 0.21425, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2144 - accuracy: 0.6926 - val_loss: 0.2143 - val_accuracy: 0.6931\n",
      "Epoch 497/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.6927\n",
      "Epoch 00497: val_loss improved from 0.21425 to 0.21422, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2143 - accuracy: 0.6927 - val_loss: 0.2142 - val_accuracy: 0.6930\n",
      "Epoch 498/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.6927\n",
      "Epoch 00498: val_loss improved from 0.21422 to 0.21419, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2143 - accuracy: 0.6927 - val_loss: 0.2142 - val_accuracy: 0.6930\n",
      "Epoch 499/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2143 - accuracy: 0.6928\n",
      "Epoch 00499: val_loss improved from 0.21419 to 0.21416, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2143 - accuracy: 0.6928 - val_loss: 0.2142 - val_accuracy: 0.6930\n",
      "Epoch 500/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.6928\n",
      "Epoch 00500: val_loss improved from 0.21416 to 0.21413, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2142 - accuracy: 0.6928 - val_loss: 0.2141 - val_accuracy: 0.6930\n",
      "Epoch 501/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.6929\n",
      "Epoch 00501: val_loss improved from 0.21413 to 0.21410, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2142 - accuracy: 0.6929 - val_loss: 0.2141 - val_accuracy: 0.6930\n",
      "Epoch 502/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2142 - accuracy: 0.6929\n",
      "Epoch 00502: val_loss improved from 0.21410 to 0.21407, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2142 - accuracy: 0.6929 - val_loss: 0.2141 - val_accuracy: 0.6930\n",
      "Epoch 503/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.6929\n",
      "Epoch 00503: val_loss improved from 0.21407 to 0.21403, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2141 - accuracy: 0.6929 - val_loss: 0.2140 - val_accuracy: 0.6929\n",
      "Epoch 504/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.6930\n",
      "Epoch 00504: val_loss improved from 0.21403 to 0.21400, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2141 - accuracy: 0.6930 - val_loss: 0.2140 - val_accuracy: 0.6929\n",
      "Epoch 505/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.6930\n",
      "Epoch 00505: val_loss improved from 0.21400 to 0.21397, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2141 - accuracy: 0.6930 - val_loss: 0.2140 - val_accuracy: 0.6928\n",
      "Epoch 506/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.6930\n",
      "Epoch 00506: val_loss improved from 0.21397 to 0.21394, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2140 - accuracy: 0.6930 - val_loss: 0.2139 - val_accuracy: 0.6928\n",
      "Epoch 507/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.6931\n",
      "Epoch 00507: val_loss improved from 0.21394 to 0.21391, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2140 - accuracy: 0.6931 - val_loss: 0.2139 - val_accuracy: 0.6928\n",
      "Epoch 508/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.6931\n",
      "Epoch 00508: val_loss improved from 0.21391 to 0.21388, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2140 - accuracy: 0.6931 - val_loss: 0.2139 - val_accuracy: 0.6929\n",
      "Epoch 509/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.6931\n",
      "Epoch 00509: val_loss improved from 0.21388 to 0.21385, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2140 - accuracy: 0.6931 - val_loss: 0.2139 - val_accuracy: 0.6930\n",
      "Epoch 510/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.6932\n",
      "Epoch 00510: val_loss improved from 0.21385 to 0.21382, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2139 - accuracy: 0.6932 - val_loss: 0.2138 - val_accuracy: 0.6930\n",
      "Epoch 511/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.6932\n",
      "Epoch 00511: val_loss improved from 0.21382 to 0.21379, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2139 - accuracy: 0.6932 - val_loss: 0.2138 - val_accuracy: 0.6931\n",
      "Epoch 512/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2139 - accuracy: 0.6932\n",
      "Epoch 00512: val_loss improved from 0.21379 to 0.21376, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2139 - accuracy: 0.6932 - val_loss: 0.2138 - val_accuracy: 0.6932\n",
      "Epoch 513/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2138 - accuracy: 0.6933\n",
      "Epoch 00513: val_loss improved from 0.21376 to 0.21373, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2138 - accuracy: 0.6933 - val_loss: 0.2137 - val_accuracy: 0.6932\n",
      "Epoch 514/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2138 - accuracy: 0.6933\n",
      "Epoch 00514: val_loss improved from 0.21373 to 0.21371, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2138 - accuracy: 0.6933 - val_loss: 0.2137 - val_accuracy: 0.6933\n",
      "Epoch 515/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2138 - accuracy: 0.6933\n",
      "Epoch 00515: val_loss improved from 0.21371 to 0.21368, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2138 - accuracy: 0.6933 - val_loss: 0.2137 - val_accuracy: 0.6934\n",
      "Epoch 516/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.6934\n",
      "Epoch 00516: val_loss improved from 0.21368 to 0.21365, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2137 - accuracy: 0.6934 - val_loss: 0.2136 - val_accuracy: 0.6935\n",
      "Epoch 517/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.6934\n",
      "Epoch 00517: val_loss improved from 0.21365 to 0.21362, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2137 - accuracy: 0.6934 - val_loss: 0.2136 - val_accuracy: 0.6935\n",
      "Epoch 518/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2137 - accuracy: 0.6935\n",
      "Epoch 00518: val_loss improved from 0.21362 to 0.21359, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2137 - accuracy: 0.6935 - val_loss: 0.2136 - val_accuracy: 0.6936\n",
      "Epoch 519/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.6935\n",
      "Epoch 00519: val_loss improved from 0.21359 to 0.21356, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2136 - accuracy: 0.6935 - val_loss: 0.2136 - val_accuracy: 0.6938\n",
      "Epoch 520/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.6936\n",
      "Epoch 00520: val_loss improved from 0.21356 to 0.21353, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2136 - accuracy: 0.6936 - val_loss: 0.2135 - val_accuracy: 0.6938\n",
      "Epoch 521/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.6936\n",
      "Epoch 00521: val_loss improved from 0.21353 to 0.21350, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2136 - accuracy: 0.6936 - val_loss: 0.2135 - val_accuracy: 0.6939\n",
      "Epoch 522/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.6936\n",
      "Epoch 00522: val_loss improved from 0.21350 to 0.21347, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2136 - accuracy: 0.6936 - val_loss: 0.2135 - val_accuracy: 0.6939\n",
      "Epoch 523/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.6936\n",
      "Epoch 00523: val_loss improved from 0.21347 to 0.21344, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2135 - accuracy: 0.6936 - val_loss: 0.2134 - val_accuracy: 0.6940\n",
      "Epoch 524/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.6937\n",
      "Epoch 00524: val_loss improved from 0.21344 to 0.21341, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2135 - accuracy: 0.6937 - val_loss: 0.2134 - val_accuracy: 0.6940\n",
      "Epoch 525/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.6937\n",
      "Epoch 00525: val_loss improved from 0.21341 to 0.21338, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2135 - accuracy: 0.6937 - val_loss: 0.2134 - val_accuracy: 0.6940\n",
      "Epoch 526/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.6937\n",
      "Epoch 00526: val_loss improved from 0.21338 to 0.21336, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2134 - accuracy: 0.6937 - val_loss: 0.2134 - val_accuracy: 0.6940\n",
      "Epoch 527/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.6938\n",
      "Epoch 00527: val_loss improved from 0.21336 to 0.21333, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2134 - accuracy: 0.6938 - val_loss: 0.2133 - val_accuracy: 0.6940\n",
      "Epoch 528/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.6938\n",
      "Epoch 00528: val_loss improved from 0.21333 to 0.21330, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2134 - accuracy: 0.6938 - val_loss: 0.2133 - val_accuracy: 0.6940\n",
      "Epoch 529/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2134 - accuracy: 0.6938\n",
      "Epoch 00529: val_loss improved from 0.21330 to 0.21327, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2134 - accuracy: 0.6938 - val_loss: 0.2133 - val_accuracy: 0.6942\n",
      "Epoch 530/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.6938\n",
      "Epoch 00530: val_loss improved from 0.21327 to 0.21324, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2133 - accuracy: 0.6938 - val_loss: 0.2132 - val_accuracy: 0.6943\n",
      "Epoch 531/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.6939\n",
      "Epoch 00531: val_loss improved from 0.21324 to 0.21321, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2133 - accuracy: 0.6939 - val_loss: 0.2132 - val_accuracy: 0.6943\n",
      "Epoch 532/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2133 - accuracy: 0.6939\n",
      "Epoch 00532: val_loss improved from 0.21321 to 0.21319, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2133 - accuracy: 0.6939 - val_loss: 0.2132 - val_accuracy: 0.6943\n",
      "Epoch 533/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.6940\n",
      "Epoch 00533: val_loss improved from 0.21319 to 0.21316, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2132 - accuracy: 0.6940 - val_loss: 0.2132 - val_accuracy: 0.6943\n",
      "Epoch 534/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.6940\n",
      "Epoch 00534: val_loss improved from 0.21316 to 0.21313, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 625ms/step - loss: 0.2132 - accuracy: 0.6940 - val_loss: 0.2131 - val_accuracy: 0.6943\n",
      "Epoch 535/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.6940\n",
      "Epoch 00535: val_loss improved from 0.21313 to 0.21310, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2132 - accuracy: 0.6940 - val_loss: 0.2131 - val_accuracy: 0.6943\n",
      "Epoch 536/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.6941\n",
      "Epoch 00536: val_loss improved from 0.21310 to 0.21307, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2132 - accuracy: 0.6941 - val_loss: 0.2131 - val_accuracy: 0.6944\n",
      "Epoch 537/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2131 - accuracy: 0.6941\n",
      "Epoch 00537: val_loss improved from 0.21307 to 0.21305, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2131 - accuracy: 0.6941 - val_loss: 0.2130 - val_accuracy: 0.6944\n",
      "Epoch 538/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2131 - accuracy: 0.6942\n",
      "Epoch 00538: val_loss improved from 0.21305 to 0.21302, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2131 - accuracy: 0.6942 - val_loss: 0.2130 - val_accuracy: 0.6944\n",
      "Epoch 539/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2131 - accuracy: 0.6942\n",
      "Epoch 00539: val_loss improved from 0.21302 to 0.21299, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2131 - accuracy: 0.6942 - val_loss: 0.2130 - val_accuracy: 0.6943\n",
      "Epoch 540/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2130 - accuracy: 0.6943\n",
      "Epoch 00540: val_loss improved from 0.21299 to 0.21296, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 630ms/step - loss: 0.2130 - accuracy: 0.6943 - val_loss: 0.2130 - val_accuracy: 0.6944\n",
      "Epoch 541/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2130 - accuracy: 0.6943\n",
      "Epoch 00541: val_loss improved from 0.21296 to 0.21293, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2130 - accuracy: 0.6943 - val_loss: 0.2129 - val_accuracy: 0.6945\n",
      "Epoch 542/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2130 - accuracy: 0.6943\n",
      "Epoch 00542: val_loss improved from 0.21293 to 0.21291, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2130 - accuracy: 0.6943 - val_loss: 0.2129 - val_accuracy: 0.6946\n",
      "Epoch 543/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2130 - accuracy: 0.6944\n",
      "Epoch 00543: val_loss improved from 0.21291 to 0.21288, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2130 - accuracy: 0.6944 - val_loss: 0.2129 - val_accuracy: 0.6946\n",
      "Epoch 544/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.6944\n",
      "Epoch 00544: val_loss improved from 0.21288 to 0.21285, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2129 - accuracy: 0.6944 - val_loss: 0.2129 - val_accuracy: 0.6945\n",
      "Epoch 545/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.6944\n",
      "Epoch 00545: val_loss improved from 0.21285 to 0.21282, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2129 - accuracy: 0.6944 - val_loss: 0.2128 - val_accuracy: 0.6945\n",
      "Epoch 546/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2129 - accuracy: 0.6945\n",
      "Epoch 00546: val_loss improved from 0.21282 to 0.21280, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2129 - accuracy: 0.6945 - val_loss: 0.2128 - val_accuracy: 0.6946\n",
      "Epoch 547/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.6945\n",
      "Epoch 00547: val_loss improved from 0.21280 to 0.21277, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2128 - accuracy: 0.6945 - val_loss: 0.2128 - val_accuracy: 0.6946\n",
      "Epoch 548/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.6945\n",
      "Epoch 00548: val_loss improved from 0.21277 to 0.21274, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2128 - accuracy: 0.6945 - val_loss: 0.2127 - val_accuracy: 0.6948\n",
      "Epoch 549/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.6945\n",
      "Epoch 00549: val_loss improved from 0.21274 to 0.21272, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2128 - accuracy: 0.6945 - val_loss: 0.2127 - val_accuracy: 0.6948\n",
      "Epoch 550/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2128 - accuracy: 0.6946\n",
      "Epoch 00550: val_loss improved from 0.21272 to 0.21269, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2128 - accuracy: 0.6946 - val_loss: 0.2127 - val_accuracy: 0.6949\n",
      "Epoch 551/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2127 - accuracy: 0.6946\n",
      "Epoch 00551: val_loss improved from 0.21269 to 0.21266, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2127 - accuracy: 0.6946 - val_loss: 0.2127 - val_accuracy: 0.6949\n",
      "Epoch 552/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2127 - accuracy: 0.6946\n",
      "Epoch 00552: val_loss improved from 0.21266 to 0.21264, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2127 - accuracy: 0.6946 - val_loss: 0.2126 - val_accuracy: 0.6950\n",
      "Epoch 553/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2127 - accuracy: 0.6946\n",
      "Epoch 00553: val_loss improved from 0.21264 to 0.21261, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2127 - accuracy: 0.6946 - val_loss: 0.2126 - val_accuracy: 0.6951\n",
      "Epoch 554/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2126 - accuracy: 0.6946\n",
      "Epoch 00554: val_loss improved from 0.21261 to 0.21258, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2126 - accuracy: 0.6946 - val_loss: 0.2126 - val_accuracy: 0.6951\n",
      "Epoch 555/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2126 - accuracy: 0.6946\n",
      "Epoch 00555: val_loss improved from 0.21258 to 0.21256, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2126 - accuracy: 0.6946 - val_loss: 0.2126 - val_accuracy: 0.6950\n",
      "Epoch 556/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2126 - accuracy: 0.6946\n",
      "Epoch 00556: val_loss improved from 0.21256 to 0.21253, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2126 - accuracy: 0.6946 - val_loss: 0.2125 - val_accuracy: 0.6950\n",
      "Epoch 557/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2126 - accuracy: 0.6946\n",
      "Epoch 00557: val_loss improved from 0.21253 to 0.21250, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2126 - accuracy: 0.6946 - val_loss: 0.2125 - val_accuracy: 0.6950\n",
      "Epoch 558/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.6947\n",
      "Epoch 00558: val_loss improved from 0.21250 to 0.21248, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2125 - accuracy: 0.6947 - val_loss: 0.2125 - val_accuracy: 0.6950\n",
      "Epoch 559/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.6947\n",
      "Epoch 00559: val_loss improved from 0.21248 to 0.21245, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2125 - accuracy: 0.6947 - val_loss: 0.2124 - val_accuracy: 0.6950\n",
      "Epoch 560/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.6947\n",
      "Epoch 00560: val_loss improved from 0.21245 to 0.21242, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 630ms/step - loss: 0.2125 - accuracy: 0.6947 - val_loss: 0.2124 - val_accuracy: 0.6950\n",
      "Epoch 561/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.6947\n",
      "Epoch 00561: val_loss improved from 0.21242 to 0.21240, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2125 - accuracy: 0.6947 - val_loss: 0.2124 - val_accuracy: 0.6950\n",
      "Epoch 562/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.6947\n",
      "Epoch 00562: val_loss improved from 0.21240 to 0.21237, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2124 - accuracy: 0.6947 - val_loss: 0.2124 - val_accuracy: 0.6950\n",
      "Epoch 563/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.6948\n",
      "Epoch 00563: val_loss improved from 0.21237 to 0.21234, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2124 - accuracy: 0.6948 - val_loss: 0.2123 - val_accuracy: 0.6950\n",
      "Epoch 564/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2124 - accuracy: 0.6948\n",
      "Epoch 00564: val_loss improved from 0.21234 to 0.21232, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2124 - accuracy: 0.6948 - val_loss: 0.2123 - val_accuracy: 0.6951\n",
      "Epoch 565/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2123 - accuracy: 0.6948\n",
      "Epoch 00565: val_loss improved from 0.21232 to 0.21229, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2123 - accuracy: 0.6948 - val_loss: 0.2123 - val_accuracy: 0.6951\n",
      "Epoch 566/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2123 - accuracy: 0.6949\n",
      "Epoch 00566: val_loss improved from 0.21229 to 0.21227, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2123 - accuracy: 0.6949 - val_loss: 0.2123 - val_accuracy: 0.6951\n",
      "Epoch 567/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2123 - accuracy: 0.6949\n",
      "Epoch 00567: val_loss improved from 0.21227 to 0.21224, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2123 - accuracy: 0.6949 - val_loss: 0.2122 - val_accuracy: 0.6953\n",
      "Epoch 568/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2123 - accuracy: 0.6950\n",
      "Epoch 00568: val_loss improved from 0.21224 to 0.21221, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2123 - accuracy: 0.6950 - val_loss: 0.2122 - val_accuracy: 0.6953\n",
      "Epoch 569/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.6950\n",
      "Epoch 00569: val_loss improved from 0.21221 to 0.21219, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2122 - accuracy: 0.6950 - val_loss: 0.2122 - val_accuracy: 0.6953\n",
      "Epoch 570/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.6950\n",
      "Epoch 00570: val_loss improved from 0.21219 to 0.21216, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2122 - accuracy: 0.6950 - val_loss: 0.2122 - val_accuracy: 0.6954\n",
      "Epoch 571/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.6950\n",
      "Epoch 00571: val_loss improved from 0.21216 to 0.21214, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2122 - accuracy: 0.6950 - val_loss: 0.2121 - val_accuracy: 0.6954\n",
      "Epoch 572/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2122 - accuracy: 0.6950\n",
      "Epoch 00572: val_loss improved from 0.21214 to 0.21211, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2122 - accuracy: 0.6950 - val_loss: 0.2121 - val_accuracy: 0.6955\n",
      "Epoch 573/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.6950\n",
      "Epoch 00573: val_loss improved from 0.21211 to 0.21209, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2121 - accuracy: 0.6950 - val_loss: 0.2121 - val_accuracy: 0.6954\n",
      "Epoch 574/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.6951\n",
      "Epoch 00574: val_loss improved from 0.21209 to 0.21206, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2121 - accuracy: 0.6951 - val_loss: 0.2121 - val_accuracy: 0.6955\n",
      "Epoch 575/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.6951\n",
      "Epoch 00575: val_loss improved from 0.21206 to 0.21203, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2121 - accuracy: 0.6951 - val_loss: 0.2120 - val_accuracy: 0.6956\n",
      "Epoch 576/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2121 - accuracy: 0.6951\n",
      "Epoch 00576: val_loss improved from 0.21203 to 0.21201, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2121 - accuracy: 0.6951 - val_loss: 0.2120 - val_accuracy: 0.6956\n",
      "Epoch 577/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.6951\n",
      "Epoch 00577: val_loss improved from 0.21201 to 0.21198, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2120 - accuracy: 0.6951 - val_loss: 0.2120 - val_accuracy: 0.6957\n",
      "Epoch 578/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.6952\n",
      "Epoch 00578: val_loss improved from 0.21198 to 0.21196, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2120 - accuracy: 0.6952 - val_loss: 0.2120 - val_accuracy: 0.6958\n",
      "Epoch 579/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2120 - accuracy: 0.6952\n",
      "Epoch 00579: val_loss improved from 0.21196 to 0.21193, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2120 - accuracy: 0.6952 - val_loss: 0.2119 - val_accuracy: 0.6958\n",
      "Epoch 580/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.6952\n",
      "Epoch 00580: val_loss improved from 0.21193 to 0.21191, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2119 - accuracy: 0.6952 - val_loss: 0.2119 - val_accuracy: 0.6959\n",
      "Epoch 581/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.6952\n",
      "Epoch 00581: val_loss improved from 0.21191 to 0.21188, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 631ms/step - loss: 0.2119 - accuracy: 0.6952 - val_loss: 0.2119 - val_accuracy: 0.6959\n",
      "Epoch 582/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.6953\n",
      "Epoch 00582: val_loss improved from 0.21188 to 0.21186, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2119 - accuracy: 0.6953 - val_loss: 0.2119 - val_accuracy: 0.6959\n",
      "Epoch 583/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.6953\n",
      "Epoch 00583: val_loss improved from 0.21186 to 0.21183, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2119 - accuracy: 0.6953 - val_loss: 0.2118 - val_accuracy: 0.6958\n",
      "Epoch 584/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.6953\n",
      "Epoch 00584: val_loss improved from 0.21183 to 0.21181, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2118 - accuracy: 0.6953 - val_loss: 0.2118 - val_accuracy: 0.6957\n",
      "Epoch 585/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.6953\n",
      "Epoch 00585: val_loss improved from 0.21181 to 0.21178, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2118 - accuracy: 0.6953 - val_loss: 0.2118 - val_accuracy: 0.6958\n",
      "Epoch 586/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.6953\n",
      "Epoch 00586: val_loss improved from 0.21178 to 0.21176, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2118 - accuracy: 0.6953 - val_loss: 0.2118 - val_accuracy: 0.6958\n",
      "Epoch 587/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.6954\n",
      "Epoch 00587: val_loss improved from 0.21176 to 0.21173, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2118 - accuracy: 0.6954 - val_loss: 0.2117 - val_accuracy: 0.6958\n",
      "Epoch 588/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.6954\n",
      "Epoch 00588: val_loss improved from 0.21173 to 0.21171, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2117 - accuracy: 0.6954 - val_loss: 0.2117 - val_accuracy: 0.6959\n",
      "Epoch 589/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.6954\n",
      "Epoch 00589: val_loss improved from 0.21171 to 0.21168, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2117 - accuracy: 0.6954 - val_loss: 0.2117 - val_accuracy: 0.6959\n",
      "Epoch 590/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.6955\n",
      "Epoch 00590: val_loss improved from 0.21168 to 0.21166, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2117 - accuracy: 0.6955 - val_loss: 0.2117 - val_accuracy: 0.6960\n",
      "Epoch 591/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2117 - accuracy: 0.6955\n",
      "Epoch 00591: val_loss improved from 0.21166 to 0.21163, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2117 - accuracy: 0.6955 - val_loss: 0.2116 - val_accuracy: 0.6960\n",
      "Epoch 592/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2116 - accuracy: 0.6956\n",
      "Epoch 00592: val_loss improved from 0.21163 to 0.21161, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2116 - accuracy: 0.6956 - val_loss: 0.2116 - val_accuracy: 0.6960\n",
      "Epoch 593/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2116 - accuracy: 0.6956\n",
      "Epoch 00593: val_loss improved from 0.21161 to 0.21158, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2116 - accuracy: 0.6956 - val_loss: 0.2116 - val_accuracy: 0.6961\n",
      "Epoch 594/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2116 - accuracy: 0.6956\n",
      "Epoch 00594: val_loss improved from 0.21158 to 0.21156, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2116 - accuracy: 0.6956 - val_loss: 0.2116 - val_accuracy: 0.6961\n",
      "Epoch 595/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2116 - accuracy: 0.6956\n",
      "Epoch 00595: val_loss improved from 0.21156 to 0.21153, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2116 - accuracy: 0.6956 - val_loss: 0.2115 - val_accuracy: 0.6961\n",
      "Epoch 596/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.6957\n",
      "Epoch 00596: val_loss improved from 0.21153 to 0.21151, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2115 - accuracy: 0.6957 - val_loss: 0.2115 - val_accuracy: 0.6962\n",
      "Epoch 597/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.6957\n",
      "Epoch 00597: val_loss improved from 0.21151 to 0.21149, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2115 - accuracy: 0.6957 - val_loss: 0.2115 - val_accuracy: 0.6962\n",
      "Epoch 598/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.6957\n",
      "Epoch 00598: val_loss improved from 0.21149 to 0.21146, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2115 - accuracy: 0.6957 - val_loss: 0.2115 - val_accuracy: 0.6962\n",
      "Epoch 599/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.6957\n",
      "Epoch 00599: val_loss improved from 0.21146 to 0.21144, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2115 - accuracy: 0.6957 - val_loss: 0.2114 - val_accuracy: 0.6961\n",
      "Epoch 600/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.6957\n",
      "Epoch 00600: val_loss improved from 0.21144 to 0.21141, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2114 - accuracy: 0.6957 - val_loss: 0.2114 - val_accuracy: 0.6963\n",
      "Epoch 601/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.6958\n",
      "Epoch 00601: val_loss improved from 0.21141 to 0.21139, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2114 - accuracy: 0.6958 - val_loss: 0.2114 - val_accuracy: 0.6963\n",
      "Epoch 602/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.6958\n",
      "Epoch 00602: val_loss improved from 0.21139 to 0.21136, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 626ms/step - loss: 0.2114 - accuracy: 0.6958 - val_loss: 0.2114 - val_accuracy: 0.6963\n",
      "Epoch 603/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2114 - accuracy: 0.6958\n",
      "Epoch 00603: val_loss improved from 0.21136 to 0.21134, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2114 - accuracy: 0.6958 - val_loss: 0.2113 - val_accuracy: 0.6964\n",
      "Epoch 604/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.6959\n",
      "Epoch 00604: val_loss improved from 0.21134 to 0.21132, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2113 - accuracy: 0.6959 - val_loss: 0.2113 - val_accuracy: 0.6965\n",
      "Epoch 605/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.6959\n",
      "Epoch 00605: val_loss improved from 0.21132 to 0.21129, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2113 - accuracy: 0.6959 - val_loss: 0.2113 - val_accuracy: 0.6966\n",
      "Epoch 606/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.6959\n",
      "Epoch 00606: val_loss improved from 0.21129 to 0.21127, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2113 - accuracy: 0.6959 - val_loss: 0.2113 - val_accuracy: 0.6966\n",
      "Epoch 607/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2113 - accuracy: 0.6959\n",
      "Epoch 00607: val_loss improved from 0.21127 to 0.21124, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 630ms/step - loss: 0.2113 - accuracy: 0.6959 - val_loss: 0.2112 - val_accuracy: 0.6966\n",
      "Epoch 608/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.6959\n",
      "Epoch 00608: val_loss improved from 0.21124 to 0.21122, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 630ms/step - loss: 0.2112 - accuracy: 0.6959 - val_loss: 0.2112 - val_accuracy: 0.6966\n",
      "Epoch 609/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.6960\n",
      "Epoch 00609: val_loss improved from 0.21122 to 0.21120, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2112 - accuracy: 0.6960 - val_loss: 0.2112 - val_accuracy: 0.6967\n",
      "Epoch 610/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.6960\n",
      "Epoch 00610: val_loss improved from 0.21120 to 0.21117, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2112 - accuracy: 0.6960 - val_loss: 0.2112 - val_accuracy: 0.6968\n",
      "Epoch 611/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2112 - accuracy: 0.6960\n",
      "Epoch 00611: val_loss improved from 0.21117 to 0.21115, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 627ms/step - loss: 0.2112 - accuracy: 0.6960 - val_loss: 0.2111 - val_accuracy: 0.6969\n",
      "Epoch 612/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.6961\n",
      "Epoch 00612: val_loss improved from 0.21115 to 0.21112, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2111 - accuracy: 0.6961 - val_loss: 0.2111 - val_accuracy: 0.6969\n",
      "Epoch 613/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.6961\n",
      "Epoch 00613: val_loss improved from 0.21112 to 0.21110, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2111 - accuracy: 0.6961 - val_loss: 0.2111 - val_accuracy: 0.6969\n",
      "Epoch 614/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.6961\n",
      "Epoch 00614: val_loss improved from 0.21110 to 0.21108, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 630ms/step - loss: 0.2111 - accuracy: 0.6961 - val_loss: 0.2111 - val_accuracy: 0.6969\n",
      "Epoch 615/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2111 - accuracy: 0.6961\n",
      "Epoch 00615: val_loss improved from 0.21108 to 0.21105, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2111 - accuracy: 0.6961 - val_loss: 0.2111 - val_accuracy: 0.6970\n",
      "Epoch 616/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2110 - accuracy: 0.6962\n",
      "Epoch 00616: val_loss improved from 0.21105 to 0.21103, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 631ms/step - loss: 0.2110 - accuracy: 0.6962 - val_loss: 0.2110 - val_accuracy: 0.6970\n",
      "Epoch 617/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2110 - accuracy: 0.6962\n",
      "Epoch 00617: val_loss improved from 0.21103 to 0.21101, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2110 - accuracy: 0.6962 - val_loss: 0.2110 - val_accuracy: 0.6971\n",
      "Epoch 618/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2110 - accuracy: 0.6962\n",
      "Epoch 00618: val_loss improved from 0.21101 to 0.21098, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 628ms/step - loss: 0.2110 - accuracy: 0.6962 - val_loss: 0.2110 - val_accuracy: 0.6971\n",
      "Epoch 619/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2110 - accuracy: 0.6963\n",
      "Epoch 00619: val_loss improved from 0.21098 to 0.21096, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2110 - accuracy: 0.6963 - val_loss: 0.2110 - val_accuracy: 0.6972\n",
      "Epoch 620/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.6963\n",
      "Epoch 00620: val_loss improved from 0.21096 to 0.21094, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 101s 629ms/step - loss: 0.2109 - accuracy: 0.6963 - val_loss: 0.2109 - val_accuracy: 0.6972\n",
      "Epoch 621/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.6963\n",
      "Epoch 00621: val_loss improved from 0.21094 to 0.21091, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 628ms/step - loss: 0.2109 - accuracy: 0.6963 - val_loss: 0.2109 - val_accuracy: 0.6972\n",
      "Epoch 622/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.6963\n",
      "Epoch 00622: val_loss improved from 0.21091 to 0.21089, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2109 - accuracy: 0.6963 - val_loss: 0.2109 - val_accuracy: 0.6972\n",
      "Epoch 623/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2109 - accuracy: 0.6963\n",
      "Epoch 00623: val_loss improved from 0.21089 to 0.21087, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2109 - accuracy: 0.6963 - val_loss: 0.2109 - val_accuracy: 0.6973\n",
      "Epoch 624/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.6964\n",
      "Epoch 00624: val_loss improved from 0.21087 to 0.21084, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2108 - accuracy: 0.6964 - val_loss: 0.2108 - val_accuracy: 0.6973\n",
      "Epoch 625/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.6964\n",
      "Epoch 00625: val_loss improved from 0.21084 to 0.21082, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2108 - accuracy: 0.6964 - val_loss: 0.2108 - val_accuracy: 0.6973\n",
      "Epoch 626/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.6964\n",
      "Epoch 00626: val_loss improved from 0.21082 to 0.21080, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2108 - accuracy: 0.6964 - val_loss: 0.2108 - val_accuracy: 0.6973\n",
      "Epoch 627/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2108 - accuracy: 0.6965\n",
      "Epoch 00627: val_loss improved from 0.21080 to 0.21077, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2108 - accuracy: 0.6965 - val_loss: 0.2108 - val_accuracy: 0.6973\n",
      "Epoch 628/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.6965\n",
      "Epoch 00628: val_loss improved from 0.21077 to 0.21075, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2107 - accuracy: 0.6965 - val_loss: 0.2108 - val_accuracy: 0.6973\n",
      "Epoch 629/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.6965\n",
      "Epoch 00629: val_loss improved from 0.21075 to 0.21073, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2107 - accuracy: 0.6965 - val_loss: 0.2107 - val_accuracy: 0.6973\n",
      "Epoch 630/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.6965\n",
      "Epoch 00630: val_loss improved from 0.21073 to 0.21070, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2107 - accuracy: 0.6965 - val_loss: 0.2107 - val_accuracy: 0.6973\n",
      "Epoch 631/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.6966\n",
      "Epoch 00631: val_loss improved from 0.21070 to 0.21068, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2107 - accuracy: 0.6966 - val_loss: 0.2107 - val_accuracy: 0.6973\n",
      "Epoch 632/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2107 - accuracy: 0.6966\n",
      "Epoch 00632: val_loss improved from 0.21068 to 0.21066, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2107 - accuracy: 0.6966 - val_loss: 0.2107 - val_accuracy: 0.6973\n",
      "Epoch 633/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.6966\n",
      "Epoch 00633: val_loss improved from 0.21066 to 0.21064, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2106 - accuracy: 0.6966 - val_loss: 0.2106 - val_accuracy: 0.6973\n",
      "Epoch 634/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.6966\n",
      "Epoch 00634: val_loss improved from 0.21064 to 0.21061, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2106 - accuracy: 0.6966 - val_loss: 0.2106 - val_accuracy: 0.6973\n",
      "Epoch 635/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.6967\n",
      "Epoch 00635: val_loss improved from 0.21061 to 0.21059, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2106 - accuracy: 0.6967 - val_loss: 0.2106 - val_accuracy: 0.6973\n",
      "Epoch 636/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2106 - accuracy: 0.6967\n",
      "Epoch 00636: val_loss improved from 0.21059 to 0.21057, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2106 - accuracy: 0.6967 - val_loss: 0.2106 - val_accuracy: 0.6974\n",
      "Epoch 637/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2105 - accuracy: 0.6967\n",
      "Epoch 00637: val_loss improved from 0.21057 to 0.21054, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2105 - accuracy: 0.6967 - val_loss: 0.2105 - val_accuracy: 0.6973\n",
      "Epoch 638/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2105 - accuracy: 0.6967\n",
      "Epoch 00638: val_loss improved from 0.21054 to 0.21052, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2105 - accuracy: 0.6967 - val_loss: 0.2105 - val_accuracy: 0.6973\n",
      "Epoch 639/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2105 - accuracy: 0.6968\n",
      "Epoch 00639: val_loss improved from 0.21052 to 0.21050, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2105 - accuracy: 0.6968 - val_loss: 0.2105 - val_accuracy: 0.6973\n",
      "Epoch 640/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2105 - accuracy: 0.6968\n",
      "Epoch 00640: val_loss improved from 0.21050 to 0.21048, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2105 - accuracy: 0.6968 - val_loss: 0.2105 - val_accuracy: 0.6972\n",
      "Epoch 641/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2104 - accuracy: 0.6968\n",
      "Epoch 00641: val_loss improved from 0.21048 to 0.21045, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2104 - accuracy: 0.6968 - val_loss: 0.2105 - val_accuracy: 0.6973\n",
      "Epoch 642/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2104 - accuracy: 0.6968\n",
      "Epoch 00642: val_loss improved from 0.21045 to 0.21043, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2104 - accuracy: 0.6968 - val_loss: 0.2104 - val_accuracy: 0.6973\n",
      "Epoch 643/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2104 - accuracy: 0.6969\n",
      "Epoch 00643: val_loss improved from 0.21043 to 0.21041, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2104 - accuracy: 0.6969 - val_loss: 0.2104 - val_accuracy: 0.6974\n",
      "Epoch 644/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2104 - accuracy: 0.6969\n",
      "Epoch 00644: val_loss improved from 0.21041 to 0.21039, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 623ms/step - loss: 0.2104 - accuracy: 0.6969 - val_loss: 0.2104 - val_accuracy: 0.6974\n",
      "Epoch 645/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.6969\n",
      "Epoch 00645: val_loss improved from 0.21039 to 0.21036, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2103 - accuracy: 0.6969 - val_loss: 0.2104 - val_accuracy: 0.6975\n",
      "Epoch 646/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.6969\n",
      "Epoch 00646: val_loss improved from 0.21036 to 0.21034, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2103 - accuracy: 0.6969 - val_loss: 0.2103 - val_accuracy: 0.6975\n",
      "Epoch 647/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.6969\n",
      "Epoch 00647: val_loss improved from 0.21034 to 0.21032, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2103 - accuracy: 0.6969 - val_loss: 0.2103 - val_accuracy: 0.6975\n",
      "Epoch 648/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.6970\n",
      "Epoch 00648: val_loss improved from 0.21032 to 0.21030, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2103 - accuracy: 0.6970 - val_loss: 0.2103 - val_accuracy: 0.6975\n",
      "Epoch 649/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2103 - accuracy: 0.6970\n",
      "Epoch 00649: val_loss improved from 0.21030 to 0.21027, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2103 - accuracy: 0.6970 - val_loss: 0.2103 - val_accuracy: 0.6975\n",
      "Epoch 650/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.6970\n",
      "Epoch 00650: val_loss improved from 0.21027 to 0.21025, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2102 - accuracy: 0.6970 - val_loss: 0.2103 - val_accuracy: 0.6976\n",
      "Epoch 651/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.6970\n",
      "Epoch 00651: val_loss improved from 0.21025 to 0.21023, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2102 - accuracy: 0.6970 - val_loss: 0.2102 - val_accuracy: 0.6976\n",
      "Epoch 652/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.6970\n",
      "Epoch 00652: val_loss improved from 0.21023 to 0.21021, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2102 - accuracy: 0.6970 - val_loss: 0.2102 - val_accuracy: 0.6976\n",
      "Epoch 653/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.6970\n",
      "Epoch 00653: val_loss improved from 0.21021 to 0.21019, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2102 - accuracy: 0.6970 - val_loss: 0.2102 - val_accuracy: 0.6976\n",
      "Epoch 654/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2101 - accuracy: 0.6971\n",
      "Epoch 00654: val_loss improved from 0.21019 to 0.21016, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2101 - accuracy: 0.6971 - val_loss: 0.2102 - val_accuracy: 0.6976\n",
      "Epoch 655/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2101 - accuracy: 0.6971\n",
      "Epoch 00655: val_loss improved from 0.21016 to 0.21014, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2101 - accuracy: 0.6971 - val_loss: 0.2101 - val_accuracy: 0.6977\n",
      "Epoch 656/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2101 - accuracy: 0.6971\n",
      "Epoch 00656: val_loss improved from 0.21014 to 0.21012, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2101 - accuracy: 0.6971 - val_loss: 0.2101 - val_accuracy: 0.6978\n",
      "Epoch 657/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2101 - accuracy: 0.6971\n",
      "Epoch 00657: val_loss improved from 0.21012 to 0.21010, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2101 - accuracy: 0.6971 - val_loss: 0.2101 - val_accuracy: 0.6978\n",
      "Epoch 658/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.6971\n",
      "Epoch 00658: val_loss improved from 0.21010 to 0.21008, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2100 - accuracy: 0.6971 - val_loss: 0.2101 - val_accuracy: 0.6978\n",
      "Epoch 659/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.6972\n",
      "Epoch 00659: val_loss improved from 0.21008 to 0.21005, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2100 - accuracy: 0.6972 - val_loss: 0.2101 - val_accuracy: 0.6978\n",
      "Epoch 660/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.6972\n",
      "Epoch 00660: val_loss improved from 0.21005 to 0.21003, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2100 - accuracy: 0.6972 - val_loss: 0.2100 - val_accuracy: 0.6978\n",
      "Epoch 661/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.6972\n",
      "Epoch 00661: val_loss improved from 0.21003 to 0.21001, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2100 - accuracy: 0.6972 - val_loss: 0.2100 - val_accuracy: 0.6979\n",
      "Epoch 662/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.6972\n",
      "Epoch 00662: val_loss improved from 0.21001 to 0.20999, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2100 - accuracy: 0.6972 - val_loss: 0.2100 - val_accuracy: 0.6979\n",
      "Epoch 663/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.6973\n",
      "Epoch 00663: val_loss improved from 0.20999 to 0.20997, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2099 - accuracy: 0.6973 - val_loss: 0.2100 - val_accuracy: 0.6979\n",
      "Epoch 664/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.6973\n",
      "Epoch 00664: val_loss improved from 0.20997 to 0.20994, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2099 - accuracy: 0.6973 - val_loss: 0.2099 - val_accuracy: 0.6980\n",
      "Epoch 665/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.6973\n",
      "Epoch 00665: val_loss improved from 0.20994 to 0.20992, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2099 - accuracy: 0.6973 - val_loss: 0.2099 - val_accuracy: 0.6981\n",
      "Epoch 666/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2099 - accuracy: 0.6974\n",
      "Epoch 00666: val_loss improved from 0.20992 to 0.20990, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2099 - accuracy: 0.6974 - val_loss: 0.2099 - val_accuracy: 0.6981\n",
      "Epoch 667/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.6974\n",
      "Epoch 00667: val_loss improved from 0.20990 to 0.20988, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2098 - accuracy: 0.6974 - val_loss: 0.2099 - val_accuracy: 0.6982\n",
      "Epoch 668/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.6974\n",
      "Epoch 00668: val_loss improved from 0.20988 to 0.20986, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2098 - accuracy: 0.6974 - val_loss: 0.2099 - val_accuracy: 0.6983\n",
      "Epoch 669/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.6974\n",
      "Epoch 00669: val_loss improved from 0.20986 to 0.20983, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2098 - accuracy: 0.6974 - val_loss: 0.2098 - val_accuracy: 0.6983\n",
      "Epoch 670/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.6974\n",
      "Epoch 00670: val_loss improved from 0.20983 to 0.20981, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2098 - accuracy: 0.6974 - val_loss: 0.2098 - val_accuracy: 0.6982\n",
      "Epoch 671/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.6975\n",
      "Epoch 00671: val_loss improved from 0.20981 to 0.20979, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2097 - accuracy: 0.6975 - val_loss: 0.2098 - val_accuracy: 0.6982\n",
      "Epoch 672/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.6975\n",
      "Epoch 00672: val_loss improved from 0.20979 to 0.20977, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2097 - accuracy: 0.6975 - val_loss: 0.2098 - val_accuracy: 0.6982\n",
      "Epoch 673/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.6975\n",
      "Epoch 00673: val_loss improved from 0.20977 to 0.20975, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2097 - accuracy: 0.6975 - val_loss: 0.2097 - val_accuracy: 0.6984\n",
      "Epoch 674/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.6975\n",
      "Epoch 00674: val_loss improved from 0.20975 to 0.20973, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2097 - accuracy: 0.6975 - val_loss: 0.2097 - val_accuracy: 0.6984\n",
      "Epoch 675/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2097 - accuracy: 0.6976\n",
      "Epoch 00675: val_loss improved from 0.20973 to 0.20970, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2097 - accuracy: 0.6976 - val_loss: 0.2097 - val_accuracy: 0.6985\n",
      "Epoch 676/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.6976\n",
      "Epoch 00676: val_loss improved from 0.20970 to 0.20968, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2096 - accuracy: 0.6976 - val_loss: 0.2097 - val_accuracy: 0.6985\n",
      "Epoch 677/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.6976\n",
      "Epoch 00677: val_loss improved from 0.20968 to 0.20966, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 622ms/step - loss: 0.2096 - accuracy: 0.6976 - val_loss: 0.2097 - val_accuracy: 0.6985\n",
      "Epoch 678/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.6976\n",
      "Epoch 00678: val_loss improved from 0.20966 to 0.20964, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2096 - accuracy: 0.6976 - val_loss: 0.2096 - val_accuracy: 0.6985\n",
      "Epoch 679/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2096 - accuracy: 0.6976\n",
      "Epoch 00679: val_loss improved from 0.20964 to 0.20962, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2096 - accuracy: 0.6976 - val_loss: 0.2096 - val_accuracy: 0.6985\n",
      "Epoch 680/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.6977\n",
      "Epoch 00680: val_loss improved from 0.20962 to 0.20960, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 100s 624ms/step - loss: 0.2095 - accuracy: 0.6977 - val_loss: 0.2096 - val_accuracy: 0.6985\n",
      "Epoch 681/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.6977\n",
      "Epoch 00681: val_loss improved from 0.20960 to 0.20957, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2095 - accuracy: 0.6977 - val_loss: 0.2096 - val_accuracy: 0.6985\n",
      "Epoch 682/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.6977\n",
      "Epoch 00682: val_loss improved from 0.20957 to 0.20955, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2095 - accuracy: 0.6977 - val_loss: 0.2096 - val_accuracy: 0.6985\n",
      "Epoch 683/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.6978\n",
      "Epoch 00683: val_loss improved from 0.20955 to 0.20953, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2095 - accuracy: 0.6978 - val_loss: 0.2095 - val_accuracy: 0.6985\n",
      "Epoch 684/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.6978\n",
      "Epoch 00684: val_loss improved from 0.20953 to 0.20951, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2095 - accuracy: 0.6978 - val_loss: 0.2095 - val_accuracy: 0.6985\n",
      "Epoch 685/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.6978\n",
      "Epoch 00685: val_loss improved from 0.20951 to 0.20949, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2094 - accuracy: 0.6978 - val_loss: 0.2095 - val_accuracy: 0.6985\n",
      "Epoch 686/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.6979\n",
      "Epoch 00686: val_loss improved from 0.20949 to 0.20947, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 622ms/step - loss: 0.2094 - accuracy: 0.6979 - val_loss: 0.2095 - val_accuracy: 0.6985\n",
      "Epoch 687/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.6979\n",
      "Epoch 00687: val_loss improved from 0.20947 to 0.20945, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2094 - accuracy: 0.6979 - val_loss: 0.2094 - val_accuracy: 0.6985\n",
      "Epoch 688/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2094 - accuracy: 0.6979\n",
      "Epoch 00688: val_loss improved from 0.20945 to 0.20942, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2094 - accuracy: 0.6979 - val_loss: 0.2094 - val_accuracy: 0.6984\n",
      "Epoch 689/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.6979\n",
      "Epoch 00689: val_loss improved from 0.20942 to 0.20940, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2093 - accuracy: 0.6979 - val_loss: 0.2094 - val_accuracy: 0.6984\n",
      "Epoch 690/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.6980\n",
      "Epoch 00690: val_loss improved from 0.20940 to 0.20938, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2093 - accuracy: 0.6980 - val_loss: 0.2094 - val_accuracy: 0.6984\n",
      "Epoch 691/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.6980\n",
      "Epoch 00691: val_loss improved from 0.20938 to 0.20936, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2093 - accuracy: 0.6980 - val_loss: 0.2094 - val_accuracy: 0.6984\n",
      "Epoch 692/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.6980\n",
      "Epoch 00692: val_loss improved from 0.20936 to 0.20934, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2093 - accuracy: 0.6980 - val_loss: 0.2093 - val_accuracy: 0.6985\n",
      "Epoch 693/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2093 - accuracy: 0.6980\n",
      "Epoch 00693: val_loss improved from 0.20934 to 0.20932, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2093 - accuracy: 0.6980 - val_loss: 0.2093 - val_accuracy: 0.6984\n",
      "Epoch 694/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2092 - accuracy: 0.6980\n",
      "Epoch 00694: val_loss improved from 0.20932 to 0.20930, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2092 - accuracy: 0.6980 - val_loss: 0.2093 - val_accuracy: 0.6984\n",
      "Epoch 695/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2092 - accuracy: 0.6981\n",
      "Epoch 00695: val_loss improved from 0.20930 to 0.20927, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 619ms/step - loss: 0.2092 - accuracy: 0.6981 - val_loss: 0.2093 - val_accuracy: 0.6985\n",
      "Epoch 696/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2092 - accuracy: 0.6981\n",
      "Epoch 00696: val_loss improved from 0.20927 to 0.20925, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2092 - accuracy: 0.6981 - val_loss: 0.2093 - val_accuracy: 0.6985\n",
      "Epoch 697/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2092 - accuracy: 0.6981\n",
      "Epoch 00697: val_loss improved from 0.20925 to 0.20923, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2092 - accuracy: 0.6981 - val_loss: 0.2092 - val_accuracy: 0.6985\n",
      "Epoch 698/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2091 - accuracy: 0.6981\n",
      "Epoch 00698: val_loss improved from 0.20923 to 0.20921, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2091 - accuracy: 0.6981 - val_loss: 0.2092 - val_accuracy: 0.6986\n",
      "Epoch 699/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2091 - accuracy: 0.6982\n",
      "Epoch 00699: val_loss improved from 0.20921 to 0.20919, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 621ms/step - loss: 0.2091 - accuracy: 0.6982 - val_loss: 0.2092 - val_accuracy: 0.6986\n",
      "Epoch 700/700\n",
      "160/160 [==============================] - ETA: 0s - loss: 0.2091 - accuracy: 0.6982\n",
      "Epoch 00700: val_loss improved from 0.20919 to 0.20917, saving model to ./uros_my_best_model_lstm_50.hdf5\n",
      "160/160 [==============================] - 99s 620ms/step - loss: 0.2091 - accuracy: 0.6982 - val_loss: 0.2092 - val_accuracy: 0.6986\n",
      "Training time finished.\n",
      "700 epochs in 19:33:32.013273\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 50\n",
    "gradient_clipping_norm = 1.25\n",
    "batch_size = 2048\n",
    "n_epoch = 700\n",
    "\n",
    "def exponent_neg_manhattan_distance(left, right):\n",
    "    ''' Helper function for the similarity estimate of the LSTMs outputs'''account\n",
    "    return K.exp(-K.sum(K.abs(left-right), axis=1, keepdims=True))\n",
    "\n",
    "# The visible layer\n",
    "left_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "right_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(len(embeddings), embedding_dim, weights=[embeddings], input_length=max_seq_length, trainable=True)\n",
    "\n",
    "# Embedded version of the inputs\n",
    "encoded_left = embedding_layer(left_input)\n",
    "encoded_right = embedding_layer(right_input)\n",
    "\n",
    "# Since this is a siamese network, both sides share the same LSTM\n",
    "shared_lstm = LSTM(n_hidden)\n",
    "\n",
    "left_output = shared_lstm(encoded_left)\n",
    "right_output = shared_lstm(encoded_right)\n",
    "\n",
    "# Calculates the distance as defined by the MaLSTM model\n",
    "malstm_distance = Lambda(function=lambda x: exponent_neg_manhattan_distance(x[0], x[1]),output_shape=lambda x: (x[0][0], 1))([left_output, right_output])\n",
    "\n",
    "# Pack it all up into a model\n",
    "malstm = Model([left_input, right_input], [malstm_distance])\n",
    "\n",
    "# Adadelta optimizer, with gradient clipping by norm\n",
    "optimizer = Adadelta(clipnorm=gradient_clipping_norm)\n",
    "\n",
    "malstm.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "filepath = './uros_my_best_model_lstm_novi_test.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, \n",
    "                             monitor='val_loss',\n",
    "                             verbose=1, \n",
    "                             save_best_only=True,\n",
    "                             mode='min')\n",
    "# Start training\n",
    "training_start_time = time()\n",
    "\n",
    "malstm_trained = malstm.fit([X_train['left'], X_train['right']], Y_train, batch_size=batch_size, verbose=1, epochs=n_epoch,\n",
    "                            validation_data=([X_validation['left'], X_validation['right']], Y_validation), callbacks=[checkpoint])\n",
    "\n",
    "print(\"Training time finished.\\n{} epochs in {}\".format(n_epoch, datetime.timedelta(seconds=time()-training_start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA62klEQVR4nO3dd3gU5drH8e+dBBJKgECoCZ2E3kNRUIoNBUVAqSpYsB0LetQDvqjYTrEcK+JBEQ4qoKJyUEFUBEQRaSLSSwgQCDWQQCBlk/v9YwZcY5CgbHY3uT/XlcvZZ2Z2fxuX3DvPM/OMqCrGGGNMfiH+DmCMMSYwWYEwxhhTICsQxhhjCmQFwhhjTIGsQBhjjCmQFQhjjDEFsgJhSjwRqSciKiJhhdh2hIh8WxS5jPE3KxAmqIhIkohki0h0vvYf3T/y9fwUzTtLeRE5JiJz/Z3FmD/DCoQJRtuBIScfiEhLoKz/4vzGACALuEREahTlCxfmKMiYwrICYYLR28ANXo+HA1O9NxCRiiIyVUQOiMgOERkrIiHuulAReU5EDopIItC7gH0niUiKiOwWkadEJPQs8g0HXgfWANfle+6uIrJERI6IyC4RGeG2lxGR592saSLyrdvWXUSS8z1Hkohc7C6PE5GZIvKOiKQDI0Sko4h8775Gioi8KiKlvfZvLiJfikiqiOwTkYdFpIaIHBeRKl7btXN/f6XO4r2bYsQKhAlGS4EKItLU/cM9GHgn3zavABWBBkA3nIJyo7tuJNAHaAskANfk23cK4AEaudtcCtxSmGAiUhfoDrzr/tyQb91cN1tVoA2w2l39HNAeOB+oDDwE5BXmNYG+wEygkvuaucB9QDRwHnARcKebIRL4CvgcqOW+x/mquhdYCAz0et7rgRmqmlPIHKaYsQJhgtXJo4hLgA3A7pMrvIrGGFU9qqpJwPM4f/DA+SP4oqruUtVU4B9e+1YHrgBGqWqGqu4HXnCfrzCuB9ao6npgBtBcRNq664YCX6nqdFXNUdVDqrraPbK5CbhXVXeraq6qLlHVrEK+5veqOktV81T1hKquVNWlqupx3/t/cIokOIVxr6o+r6qZ7u/nB3fdf3GPeNzf4RCc37Mpoay/0gSrt4FvgPrk617C+eZcCtjh1bYDiHGXawG78q07qa67b4qInGwLybf977kBeANAVXeLyCKcLqcfgdrAtgL2iQYiTrOuMH6VTUTigX/jHB2Vxfl3vtJdfboMAP8DXheR+kBjIE1Vl/3BTKYYsCMIE5RUdQfOYPUVwEf5Vh8EcnD+2J9Uh1+OMlJw/lB6rztpF84Ac7SqVnJ/Kqhq8zNlEpHzgThgjIjsFZG9QCdgqDt4vAtoWMCuB4HM06zLwGsA3v1mXzXfNvmnZJ4AbATiVLUC8DBwstrtwul2+w1VzQTexzmKuB47eijxrECYYHYz0FNVM7wbVTUX5w/d0yIS6fb9388v4xTvA/eISKyIRAGjvfZNAb4AnheRCiISIiINRaQbZzYc+BJohjO+0AZoAZQBLscZH7hYRAaKSJiIVBGRNqqaB7wF/FtEarmD6OeJSDiwGYgQkd7uYPFYIPwMOSKBdOCYiDQB7vBa9ylQU0RGiUi4+/vp5LV+KjACuAorECWeFQgTtFR1m6quOM3qu3G+fScC3wLTcP4Ig9MFNA/4CVjFb49AbgBKA+uBwzgDwDV/L4uIROCMbbyiqnu9frbj/KEdrqo7cY54/gqk4gxQt3af4gHgZ2C5u+5fQIiqpuEMML+JcwSUAfzqrKYCPIAz3nHUfa/vnVyhqkdxxm2uBPYCW4AeXuu/wxkcX+UepZkSTOyGQcYYbyLyNTBNVd/0dxbjX1YgjDGniEgHnG6y2u7RhinBrIvJGAOAiPwX5xqJUVYcDNgRhDHGmNOwIwhjjDEFKjYXykVHR2u9evX8HcMYY4LKypUrD6pq/mtrgGJUIOrVq8eKFac749EYY0xBROS0pzP7tItJRHqJyCYR2SoiowtY/4KIrHZ/NovIEa91w0Vki/sz3Jc5jTHG/JbPjiDcKQHG41yUkwwsF5HZ7iRmAKjqfV7b340zcyYiUhl4DGcuGQVWuvse9lVeY4wxv+bLI4iOwFZVTVTVbJyZLfv+zvZDgOnu8mXAl6qa6haFL4FePsxqjDEmH1+OQcTw61kmk3EmLvsNd66c+sDXv7NvTAH73QrcClCnTp38q8nJySE5OZnMzMw/EN8UJCIigtjYWEqVsnvIGFPcBcog9WBgpjvJWqGp6kRgIkBCQsJvLuhITk4mMjKSevXq4TV1s/mDVJVDhw6RnJxM/fr1/R3HGONjvuxi2s2vp1SOxeumLvkM5pfupbPd97QyMzOpUqWKFYdzRESoUqWKHZEZU0L4skAsB+JEpL57P9zBwOz8G7nTEUcB33s1zwMuFZEodzrmS922s2bF4dyy36cxJYfPuphU1SMid+H8YQ8F3lLVdSLyBLBCVU8Wi8E4971Vr31TReRJnCID8IR7a0hjjCn+VCE1EUJCoXwNyM2C9BSIrAFlKjnb5GRC2i7YNBfCIyHhxt99yj/Cp2MQqjoHmJOv7dF8j8edZt+3+GX+/qB06NAhLrroIgD27t1LaGgoVas6FywuW7aM0qVLn3bfFStWMHXqVF5++eUiyWqM8bPdq+DwdihfHeY/CbuW/nYbCYHKDSHjAGQdBXfYVmM7IsFWIEq6KlWqsHr1agDGjRtH+fLleeCBB06t93g8hIUV/L8gISGBhISEoohpjPGnrGOw4O+wbCLk5Tht5avDpU87RwtHUyAvF6LqwYGNeDbMIaNyS3aF1mbrifLMPtGa3JB4/uuDaFYgitiIESOIiIjgxx9/pEuXLgwePJh7772XzMxMypQpw+TJk2ncuDELFy7kueee49NPP2XcuHHs3LmTxMREdu7cyahRo7jnnnv8/VaMMX+EKqz7CPZvgD0/QuIiyPNAi/7QYgAcT4X4XlDe6W04cDSLhZv288PmVJYnVWfHoQ6nnqpO5bI0rhFJ53pRPolaYgrE45+sY/2e9HP6nM1qVeCxK894L/vfSE5OZsmSJYSGhpKens7ixYsJCwvjq6++4uGHH+bDDz/8zT4bN25kwYIFHD16lMaNG3PHHXfYtQjGBIOk75xCkOdxisLeNbB/PSAQFgFthkDb66F2R9Izc1izK43Vyw7z484kkg5lkHgwA1WIKluK9nUrc33nusRXj6R+dDlqVy7r0+glpkAEkmuvvZbQ0FAA0tLSGD58OFu2bEFEyMnJKXCf3r17Ex4eTnh4ONWqVWPfvn3ExsYWZWxjzEkZB2H3SueP/bEDziCyJwsy0yAzHUSgUl04uBmSl/2yX7lqULUxXPQYeeffy5o9R1my7SDLvkpl+fbPycj+5VKwRtXKE1ctkqvbxHBR0+o0qRFJSEjRnkVYYgrEH/mm7yvlypU7tfzII4/Qo0cPPv74Y5KSkujevXuB+4SHh59aDg0NxePx+DqmMcabKiQvh6WvwfrZpwaICa8IpSIgNBxKlXF+PJmwcylE1iSrxziSql3MrgNprMmMZl96Nht/Smf7/K9Iz3T+HTeILsfVbWOIjSpL81oVaF27EhXL+L+HoMQUiECVlpZGTIwzi8iUKVP8G8YY81v7N8CSV+GnaaB5TkHofAc06Q3VW0BEhVObZnvyWLsnjVU7DrN62x5W7s4gZa4H2OlukUblcqVpXD2SK1vXIqFeFN3iq1G53OnPaPQnKxB+9tBDDzF8+HCeeuopevfu7e84xpiTklfAjGFwbC9IKDS9Chr2dAaSw8sDkJ6Zw6pN+1mRdJjlSams3nWELE8eADUqRNAlrgYNqpajQXQ56lctR70q5QgPCwmaC06LzT2pExISNP8NgzZs2EDTpk39lKj4st+rKZY8WbBtARw/CCvecsYYQkpB1/ug7TCIqseeIydYnpR6qiBs2ncUVQgNEZrXqkBC3cp0qBdF+7pRVKsQ4e93VCgislJVCzyn3o4gjDEly9G9cOIIRMeD5wQseQU2fw4pa34ZVyhVluwe41hXqx9rDwkr5qWyIimR3UdOAFCudCjt6kZxeYuadKgXRevalSgXXvz+nBa/d2SMMQXZvxE+GA4HNjqPI2tBxn7I85BXJZ5djW/kx6xY0qQcq1MjmD0vmty8dQBUiwynQ/3KjLygPgn1KtOkRiRhoT69IWdAsAJhjCmeTs5ntOIt2PWDcwZSeEXoMZbcsAiObVrEvpp9+DyzORO21+DE7lzCw0IIDwshvnokt3erTLs6UcRXjyQ2qkzQjBucS1YgjDHBLeMgpO+GKo2gVFnnGoS9P8O8/4PtiwDIKxvN7sY38nn4ZXyztTLLtqeS5WkAQMUypbi6bU2uaFmDDvUqE1Eq1J/vJqBYgTDGBKdjB2D5G7D4eecqZUBDwgBB8nLII4QvInrxztEEvk1tBqlQKlRpWDWLIR3r0LZOJeKqRdKoWnlKhxX/7qI/wgqEMSZ4HN0HGz+F8Ejy5o4m5MQhkmMuJzWsOhmeEBL3p3PkRDbpWo4ZuT2oFVWLC1tH061cOM1qVaBdnSjKlLYjhMKyAuFjPXr0YPTo0Vx22WWn2l588UU2bdrEhAkTfrN99+7dee6550hISOCKK65g2rRpVKpU6VfbFDQzbH6zZs0iPj6eZs2aAfDoo49y4YUXcvHFF5+bN2aMr2WmO8XgcBKkJqIHNiJ7fz61eo9G85fsJ/hpW6NTbe3rRtGzSTVqlg7l7bpRtIypWCLHDs4VKxA+NmTIEGbMmPGrAjFjxgyeeeaZM+47Z86cM25zOrNmzaJPnz6nCsQTTzzxh5/LmCJzbL9TGA5shE9HOfc9ADLDKhDhSeegVmCs52Zia9agRovujK5dlejypakaGU658DBKlYAzi4qS/TZ97JprruGzzz4jOzsbgKSkJPbs2cP06dNJSEigefPmPPbYYwXuW69ePQ4ePAjA008/TXx8PF27dmXTpk2ntnnjjTfo0KEDrVu3ZsCAARw/fpwlS5Ywe/ZsHnzwQdq0acO2bdsYMWIEM2fOBGD+/Pm0bduWli1bctNNN5GVlXXq9R577DHatWtHy5Yt2bhxoy9/Ncb84sRh554IL7SAV9vDe8M4lp3HY+UeoX7mOzTNeJ27q03h64tm8+ToMYy963Zu6d6E8xpWIa56JJXKlrbi4AMl5whi7mjnzIZzqUZLuPyfv7tJ5cqV6dixI3PnzqVv377MmDGDgQMH8vDDD1O5cmVyc3O56KKLWLNmDa1atSrwOVauXMmMGTNYvXo1Ho+Hdu3a0b59ewD69+/PyJEjARg7diyTJk3i7rvv5qqrrqJPnz5cc801v3quzMxMRowYwfz584mPj+eGG25gwoQJjBo1CoDo6GhWrVrFa6+9xnPPPcebb775J39JxpzBwa1kThtGROpGlpfqwMLsRuzMrcIP2S2oWakOj3eNoVeLGlSLDI4rk4uTklMg/OhkN9PJAjFp0iTef/99Jk6ciMfjISUlhfXr15+2QCxevJh+/fpRtqwz9/tVV111at3atWsZO3YsR44c4dixY7/qyirIpk2bqF+/PvHx8QAMHz6c8ePHnyoQ/fv3B6B9+/Z89NFHf/atG3Nah46ks+Oz52iz5WVEw7hd/0Za1Z60ql2R/vWr8EJcdIm4GC2QlZwCcYZv+r7Ut29f7rvvPlatWsXx48epXLkyzz33HMuXLycqKooRI0aQmZn5h557xIgRzJo1i9atWzNlyhQWLlz4p7KenFbcphQ3hZaX68xblPKTcz1CdgaEV4CQUDh+CHKzoWoTPHnKwsx4Zu2tQuVtH3Ot5xPahSSxLKw9mzr+nX92bUelsoE5q2lJVXIKhB+VL1+eHj16cNNNNzFkyBDS09MpV64cFStWZN++fcydO/e094EAuPDCCxkxYgRjxozB4/HwySefcNtttwFw9OhRatasSU5ODu++++6pqcMjIyM5evTob56rcePGJCUlsXXrVho1asTbb79Nt27dfPK+TTGXdcyZ4O7z0fDz+06bhP4yn1E+YcDFQCOtST1J4UR4JZIveJWOF1xHRzvTKCBZgSgiQ4YMoV+/fsyYMYMmTZrQtm1bmjRpQu3atenSpcvv7tuuXTsGDRpE69atqVatGh06/HJP2ieffJJOnTpRtWpVOnXqdKooDB48mJEjR/Lyyy+fGpwGiIiIYPLkyVx77bV4PB46dOjA7bff7ps3bYqvzDSY2N2ZygKg0+2QcLNzNbPmknb4IOvXrWbqlnC+3ppGxVJ5XNW8MkMjvqP+ns8gbiBlLhpHbIh1IQUym+7bnDX7vZYw2RnOaacSAnvXOt1Jm+Y690lo3h+i6pHW6QF+2HmU7xMPsSElnZ92pXEiJ5fo8uGMOL8uwzrVJSpAb4pT0tl038aYP2bHEvjgRqcYnBRaGup2gUufZGdMHyYs2sbMfy4iJ1cJDwuhRUxFrm4bQ/92MbSKrUh4mF25HKysQBhjfsuT7YwrzP0bRNaAyyZBaCmyqzRhXWY0i7emsvDb/azetYCwkBAGJtTm6rZWEIqbYl8gVNUutT+HikuXpPkdB7c4t9o8uAmqNiF7yIdM25DDos0H+G5bItmerQC0iq3IXT3jGNqxDjUq2jUKxVGxLhAREREcOnSIKlWqWJE4B1SVQ4cOERFhfwyKnWP7nfslHNoGC54GzSOt4/3MC7+U1ydvJfFABvWqlGVYpzp0rFeZDvUrE10+3N+pjY8V6wIRGxtLcnIyBw4c8HeUYiMiIoLY2Fh/xzB/Rm4OhIQ59004vAOWvAyr3oZcZ8qVAzUu5GHPLXz5TRiQSvNaFZg8ogM9mlTzb25T5HxaIESkF/ASEAq8qaq/uVpNRAYC4wAFflLVoW77v4De7mZPqup7Z/v6pUqVon79+n8wvTHFzOYvnLur7Vzi3FktJBSO7HCuXWgzhPTotsxYd5y/b6tHbFRZxvauxwVxVWlcI9LfyY2f+KxAiEgoMB64BEgGlovIbFVd77VNHDAG6KKqh0WkmtveG2gHtAHCgYUiMldV032V15hia8kr8MNESNvpPK7SCKLqO2cjNe1DVsKtzNyivDx/C4eP53BPzwbcc1GcTXNhfHoE0RHYqqqJACIyA+gLrPfaZiQwXlUPA6jqfre9GfCNqnoAj4isAXoB7/swrzHFx9F9sG8trP0QVr8LpcvD+fc4P+WrAnA4I5vJS5J466UNHMvy0KxmBd4a0YHmtSr6ObwJFL4sEDHALq/HyUCnfNvEA4jIdzjdUONU9XPgJ+AxEXkeKAv04NeFxRhTkNXT4IuxzhxIACGl4Ly74OJxEFoKgP1HM3npqy18sDKZbE8elzSrzojz63F+QzuZw/yavwepw4A4oDsQC3wjIi1V9QsR6QAsAQ4A3wO/meBFRG4FbgWoU6dOUWU2JvCowpYvYfbdUK0ptB4CcZdCdDxUqAlA8uHjvDJ/K5+u2UOWJ49rE2pzw3l1aVqzgp/Dm0DlywKxG6jt9TjWbfOWDPygqjnAdhHZjFMwlqvq08DTACIyDdic/wVUdSIwEZypNs75OzAmkOXlwdLxznULBzfDzu+hcgMY/imUqXRqs7TjOby2aCtTvksiRITLW9bg7p5x1I8u57/sJij4skAsB+JEpD5OYRgMDM23zSxgCDBZRKJxupwS3QHuSqp6SERaAa2AL3yY1ZjgogrfPAML/+E8rlgHLnoM2t1wqjiknchhxrKd/OebRA4fz6ZfmxjuvzSe2Kiy/sttgorPCoSqekTkLmAezvjCW6q6TkSeAFao6mx33aUish6nC+lBtyhEAIvd/tB04Dp3wNqYkis1EdbNci5oS17u3K+5xTUw4E3nmgZXZk4uk77dzoSF2ziW5eGCuGhGX97EBp/NWSvWs7kaU2zs/AHe7gc5Gc7j+F5Q93zoMBJKO0cEWZ5cZv24m5e+2sKetEwublqdURfH0SLGCoM5PZvN1ZhgtnslTLsWQsNg+NcQ0+5XRwypGdm8s3QHU7/fwcFjWbSMqci/B7Whc4MqfgxtigMrEMYEKlVnGozFz0NoOAz/BKo1ObV61c7DzPpxN++v2EVmTh7dG1dl5AUN7HRVc85YgTAmEB07AJ/cA5vmQEQlGDLjVHHYvO8oT322gW82H6B0aAhXtq7F7d0aEFfdpsQw55YVCGMCTdK38OEtcDQFuo+BCx+CkBAysjy8PH8Lk77dTvmIMMZc3oRhnetSPtz+GRvfsE+WMYHi2AGYPsgZc6gQAyO/hpj2qCrz1qbw+CfrSUnLZFBCbf52eRMq2y08jY9ZgTDGn3I98N0LzrTb279xZleNuxSungDlotmVepxH/reWhZsO0LRmBV4d2pb2dSv7O7UpIaxAGOMvqvDfK53ptwEia8LgadCkNxlZHl7/YhOTvt1OiAiP9mnGDefVtRlWTZGyAmGMPxzaBvMedopD9RbOGUplosjIzuWjpTuYsGAre9Iy6dmkGk9e3YKYSmX8ndiUQFYgjClqabthYg/wZDqT6vV9DRXhgxXJPPvFJg4cda5leHFwWzrWt+4k4z9WIIwpSpnpMOdByDkOd36PVmnEsu2pTP4uic/X7aVdnUq8NqwdCXWj7FoG43dWIIwpKskr4f0bID0ZutzLyoxo7p+8kB2HjhMeFsJDvRpzR7eGVhhMwLACYUxRyPXAB8PBc4LsfpMYv68lr/7neyqXK82/BrSkT6talLPrGUyAsU+kMb6UlwerpsD+DZC2i4VtX+TvX1dl876tXNKsOs8MaEWUXc9gApQVCGN8IeMQzB8HB7eeOo31W9pw8/dViKshTBjWjstb1vRvRmPOwAqEMedaTibMGAq7lqJhZfgq4lJGH+lH7dg6zLyqOW1qV7JxBhMUrEAYcy6lbocJ50POcb5t8yx3rK5D1gllXL/mDOlY2wqDCSpWIIz5M1TBkwXrPoblbzjzKAFTo+/n0aUxdG5Qkaf7taRh1fJ+DmrM2bMCYcwftXsVTL7cueDNdSKiOo96bmTm7lY8fEUTRl7QwI4aTNCyAmHMH/HzTPh8tFMc4i9H2w7j+e31efWbHdSoEMHsvyTQMtZu9WmCmxUIY87GicPw6X1OlxKg59/Lorp38dL8Lfy4cwcDE2J56uqWlA6zSfVM8LMCYUxhHdsPH98GiQuh0x1sqTeEsYsy+OHr5cRUKsM/+7dkUAcbiDbFhxUIYwrj0DaY0geO7iGv9VD+dmwIH/w3mQoRYTx5dQsGJdS2owZT7FiBMOZMVk+Dz/4KqhxpdQv37r2CRTuSua1bA+7o1pBKZe1KaFM8WYEw5vfsXAqz7iCvWjM+ir6DMSujKVPKw78GtGRQhzr+TmeMT1mBMOb3rJxCbmgZeh97hI07lX5ta/HwFU2pGhnu72TG+JwVCGO85eZASBgc2ITn3UGEpSUx2XM52WXKMu2WFpzfKNrfCY0pMlYgjAGnK+n9G+DYPqhYm7z0FMLUwxTtjfYcy9wLGxMeFurvlMYUKSsQxhzYDP/7i1McqjZln6csSzx1+bTqSB4ddgl1q5Tzd0Jj/MIKhCnZso/D9EGQmc7efh/wr43V+PjH3XRtFM1r17WjQkQpfyc0xm98euK2iPQSkU0islVERp9mm4Eisl5E1onINK/2Z9y2DSLystjVR+Zc2/Il/L0mpCayuM0z9Pwwjzk/p3BH94a8OTzBioMp8Xx2BCEiocB44BIgGVguIrNVdb3XNnHAGKCLqh4WkWpu+/lAF6CVu+m3QDdgoa/ymhJk78+QvscZcwAWRw/i+q8j6FCvAi8PaUvNimX8HNCYwODLLqaOwFZVTQQQkRlAX2C91zYjgfGqehhAVfe77QpEAKUBAUoB+3yY1ZQE6SnwzbOwcjJoHkfCY+jveYSdeypwc9f6PHhZYyJK2UC0MSf5skDEALu8HicDnfJtEw8gIt8BocA4Vf1cVb8XkQVACk6BeFVVN+R/ARG5FbgVoE4du2jJnIYnG9Z+CLNuB+BI1Q68c7ARU9O70rZZHBMva0Kjana/BmPy8/cgdRgQB3QHYoFvRKQlEA00ddsAvhSRC1R1sffOqjoRmAiQkJCgRRXaBBFPNnx0C6z/HwCzYu5n1LYE4quX5+3b2tG4RqSfAxoTuHxZIHYDtb0ex7pt3pKBH1Q1B9guIpv5pWAsVdVjACIyFzgPWIwxZ7JvPRza6syhdHAzpG4js+toHt7ciI+2leH2bg2575I4u67BmDPwZYFYDsSJSH2cwjAYGJpvm1nAEGCyiETjdDklAg2AkSLyD5wupm7Aiz7MaoqLwztgwnnOclgZqNWGPc1HcsNPzdhxKIMXBrWiX9vY338OYwzgwwKhqh4RuQuYhzO+8JaqrhORJ4AVqjrbXXepiKwHcoEHVfWQiMwEegI/4wxYf66qn/gqqykm0lOcW4ACdBgJPccyPymLO95dRZlSWfz3po6c39CmyjCmsES1eHTdJyQk6IoVK/wdw/jL/Cfh2xdAc6Hb38i5cDSPzV7HtB920iKmAm+N6EC1yAh/pzQm4IjISlVNKGidvwepjflz0lNgxlDYswqaXgm1O3Gi5fXcOXUFCzYd4KYu9Xmol52+aswfYQXCBK+j++C9YU5xiLsMBkxi7b5Mbn9tJcmHT/BE3+bccF49f6c0JmhZgTDBKS8PZt4EKWvg2ilos6v5YEUyY2etpXK50kwb2cnGG4z5k85YIETkSuAzVc0rgjzGFM5Ht8COb+HKl1hdoQejX1rMxr1H6Vi/Mq8Na0d0ebuhjzF/VmEm6xsEbHEnz2vi60DGnFF6Cqz7GJpeyUy9iAETlnAoI5tnrmnFjJGdrTgYc46c8QhCVa8TkQo41ytMEREFJgPTVfWorwMa8yuZafDBCDS0NFPKDOfxmWvo2iial4e0pXK50v5OZ0yxUqjpvlU1HZgJzABqAv2AVSJytw+zGfNrSyfAK+3R3St4NOQuHl+STb+2Mbw5PMGKgzE+UJgxiKuAG4FGwFSgo6ruF5GyODOzvuLbiMYAKybD56NRQrhZHmNlTjMmj2hDjybV/J3MmGKrMGcxDQBeUNVvvBtV9biI3OybWMZ42bcePh3Frgpt6b3/TurG1OLjwW1oUNVmYDXGlwpTIMbhTLsNgIiUAaqrapKqzvdVMGNOOvjdZKIIod/+W7k8oQlPXN3cJtozpggUZgziA8D7FNdct80Y38o+zua3R1H5pzf4XC7koQEX8M8BLa04GFNECnMEEaaq2ScfqGq2iNiIoPGpbE8e305+hJ4pk/kxogMdb5tC1cpR/o5lTIlSmAJxQESucmdfRUT6Agd9G8uUZNu2J1Jx6kX01FS2RybQctQXhIUW6oQ7Y8w5VJgCcTvwroi8inNvhl3ADT5NZUoeVfSn6SxNziJz+dv0kFS2N7mN+v3HgRUHY/yiMBfKbQM6i0h59/Exn6cyJY4mLkJm3cF5AALHOtxD/d5P+juWMSVaoSbrE5HeQHMgQkQAUNUnfJjLlCAZ6z6n9AfXkaHlWBx7G727tqd8k97+jmVMiVeYC+VeB8oCPYA3gWuAZT7OZYq7E4dh90qySlUi58PbyNJwvu8yiT6XXMbJLyHGGP8qzBHE+araSkTWqOrjIvI8MNfXwUwxtmOJM1X30RTCgXBgcffp9O7Ry9/JjDFeCjP6l+n+97iI1AJycOZjMubsZR2F964nL6wsr5a/h815MSzsMIELelzh72TGmHwKcwTxiYhUAp4FVgEKvOHLUKaYyvXAnIfQ44e4W8YwN7Umcdf9hcua1/B3MmNMAX63QIhICDBfVY8AH4rIp0CEqqYVRThTjKSsgf/dCXt/Zrr0ZsHRWKbc2J4L46v6O5kx5jR+t0Coap6IjAfauo+zgKyiCGaKkbxcmD4YjyeHF8rexzsZnZhxa2daxVbydzJjzO8ozBjEfBEZIHZqiTlbeXmw7A14sRWk72Zs9gimHj+PF4e2t+JgTBAozBjEbcD9gEdEMnGuplZVreDTZCa45eXCp6Ng1VQAppcewJysdrx/+3k0rWkfHWOCQWGupI4siiCmmPn0Plg1lZzW13Hn5vZ8l1GLScM7WHEwJogU5kK5Cwtqz38DIWNOObQNVr+LJtzCvWlDmX9kL9NGdqBzgyr+TmaMOQuF6WJ60Gs5AugIrAR6+iSRCW7rZsHse6BUOWZHDmLOt3sZfXkTKw7GBKHCdDFd6f1YRGoDL/oqkAli3zwLC/4O0Y3Z2PUFHvrgEOc1qMKtFzTwdzJjzB/wR+ZRTgaanusgJsht+RK+fgqa9SVt6Cfc8vkJosuHM35YO0JC7AQ4Y4JRYcYgXsG5ehqcgtIG54rqMxKRXsBLQCjwpqr+s4BtBuLc91qBn1R1qIj0AF7w2qwJMFhVZxXmdY0ffP0UVGnE8d6vMmjiKvamZfL+7edRuZzdfNCYYFWYMYgVXsseYLqqfnemnUQkFBgPXIJz1LFcRGar6nqvbeKAMUAXVT0sItUAVHUBTiFCRCoDW4EvCvWOTNH7eSakrIYrnuP17/awce9RXhnSlnZ17BahxgSzwhSImUCmquaC84dfRMqq6vEz7NcR2Kqqie5+M4C+wHqvbUYC41X1MICq7i/gea4B5hbi9Yy/LJ8EVeJIbjiIiS9+R59WNbmydS1/pzLG/EmFupIaKOP1uAzwVSH2i8G5PelJyW6bt3ggXkS+E5GlbpdUfoOB6QW9gIjcKiIrRGTFgQMHChHJnFNHdsErCbBzCVkth3DL26sJCwlh9OVN/J3MGHMOFKZARHjfZtRdLnuOXj8MiAO6A0OAN9yZYwEQkZpAS2BeQTur6kRVTVDVhKpVbdK3Ijf/cTi0BW05kFu3nc/W/cd4bVg7YqPO1cfDGONPhSkQGSLS7uQDEWkPnCjEfruB2l6PY902b8nAbFXNUdXtwGacgnHSQOBjVc0pxOuZopSyBn7+ALrez7TYsSzaksq4q5rb7KzGFCOFKRCjgA9EZLGIfAu8B9xViP2WA3EiUl9ESuN0Fc3Ot80snKMHRCQap8sp0Wv9EE7TvWT8bP7jEFGJzXE3MW72OjrVr8zQjnX8ncoYcw4V5kK55SLSBGjsNm0qzDd6VfWIyF043UOhwFuquk5EngBWqOpsd92lIrIeyAUeVNVDACJSD+cIZNEfeF/Gl7Yvhq1foZc8ydi5yURGlOL169rb9Q7GFDOFuQ7iL8C7qrrWfRwlIkNU9bUz7auqc4A5+doe9VpWnJli7y9g3yR+O6ht/E0VvnoMKsQwp0wfliVt4B/9WxJl1zsYU+wUpotppHtHOQDcU1JH+iyRCWyrp8HulRzp9FfGzN5Cy5iKDEyofeb9jDFBpzAFItT7ZkHuBXD2dbEk2vKlc9vQqk14eFtLsnPzeHVoW0Kta8mYYqkwBeJz4D0RuUhELsIZNJ7r21gmoKjCV+Pg3WsgujGLu7zFnPUHuLtnHHWrlPN3OmOMjxTmSuq/AbcCt7uP1wA1fJbIBJ7EBfCtMzVWZv8pjHl7L42qlWekzdJqTLF2xiMIVc0DfgCScKbP6Als8G0sEzD2b4S3+0HFOjB2P/9eLSQfPsFTV7egdNgfmQzYGBMsTnsEISLxONchDAEO4lz/gKr2KJpoxu+O7IS3LnOWe4xh8g97mPhNIkM71bEbABlTAvxeF9NGYDHQR1W3AojIfUWSyvjfsf3wRk/IOQH93+D9rM48/snPXNa8Oo9f1dzf6YwxReD3+gj6AynAAhF5wx2gttNVSoJcj3Pb0Mx0uGkuSbV689js9ZzfsAqvDm1HqVDrWjKmJDjtv3RVnaWqg3Fu1rMAZ8qNaiIyQUQuLaJ8xh9+nAqb58IlT+Cp0Zb7319NqVDh+YGtrTgYU4IUZpA6Q1WnufemjgV+xDmzyRRHB7c6p7TGdiCvw608M28Tq3Ye4cmrW1CzYpkz7m6MKT7O6uugqh52p9i+yFeBjJ/NfQgkBAa8yfNfbT41KN23jc16YkxJY/0F5hcrp8C2+dD5TrbmRDPxm0T6t4vh6atb+DuZMcYPrEAYR14efPcy1GyDdr2Pxz9ZR0SpUB6+oileM60YY0oQKxDG8dM0SN0G593FvA2HWLzlIPdfEk90+XB/JzPG+IkVCONMo/G/v0DdrmTGX8mTn66ncfVIru9c19/JjDF+VJi5mExxduIILHoWYjvC0BlM+GYnu4+cYPrIzoTZKa3GlGj2F6AkS98D/+0DORnQ+3k2H4EJi7ZxZetanNfQptIwpqSzI4iSavM8mDbQOaW11z85XqUZ97y2hMjwMB7p09Tf6YwxAcAKREmUlwuf/dVZvu5DaNiT/3tvNZv3HWXKjR2pFhnh33zGmIBgXUwl0fzHIW0XDJgEDXuyYNN+Pv5xN3f3jOPC+Kr+TmeMCRBWIEqanBOw7E1o3g9aDOBwRjaPzFpLw6rluLNHQ3+nM8YEEOtiKmkSFzqD0u1uABFGf7SG/UezmD6yM+Fhof5OZ4wJIHYEUZKcOALzn4RyVaFuV75Yt5d56/Zx38XxtK8b5e90xpgAY0cQJck3z8L+dTBgEhsPZvLXD36icfVIbrmgvr+TGWMCkB1BlBS7V8HyN6HVIDLir+Yv764iolQobw5PsHs8GGMKZH8ZSoLlk2DSpVCuKtp9DI/8by2JBzN4aXAbalcu6+90xpgAZQWiuFvzAcx5AOp0hhGfMX1LKB+t2s09PeM4v2G0v9MZYwKYFYjibNPn8NEtULM1DJzK6mMVGTd7Hd3iq3LPRXH+TmeMCXA+LRAi0ktENonIVhEZfZptBorIehFZJyLTvNrriMgXIrLBXV/Pl1mLnTXvwwfDoXpLuPFzDuWV4853VlKtQjgvDW5DaIjd48EY8/t8dhaTiIQC44FLgGRguYjMVtX1XtvEAWOALqp6WESqeT3FVOBpVf1SRMoDeb7KWuwc3gEf3wY1WsI1k/GElObu6cs4mJHNR3ecT6Wypf2d0BgTBHx5BNER2KqqiaqaDcwA+ubbZiQwXlUPA6jqfgARaQaEqeqXbvsxVT3uw6zFx/FUmHy5s9zvP1ClIS/P38KSbYd46uoWtIip6N98xpig4csCEQPs8nqc7LZ5iwfiReQ7EVkqIr282o+IyEci8qOIPOsekfyKiNwqIitEZMWBAwd88iaCSq4HPhgBGQdh6AdQrSnLtqfy6oKtDGgXy8CE2v5OaIwJIv4epA4D4oDuwBDgDRGp5LZfADwAdAAaACPy76yqE1U1QVUTqla1SeZY/BxsXwR9XoC4i0k7kcN9760mNqosj/dt7u90xpgg48sCsRvw/soa67Z5SwZmq2qOqm4HNuMUjGRgtds95QFmAe18mDW4ebJg6euw+N/OJHxth6GqPDJrLXvTM3lpcBvKh9tF88aYs+PLArEciBOR+iJSGhgMzM63zSycowdEJBqnaynR3beSiJw8LOgJrMcUbOE/4PO/QflqcOnTqCrPzNvE7J/2MOqiONrWsXmWjDFnz2cFwv3mfxcwD9gAvK+q60TkCRG5yt1sHnBIRNYDC4AHVfWQqubidC/NF5GfAQHe8FXWoJZzApa/5Rw5jPoZKsbwztIdTFi4jaGd6vCXHo38ndAYE6R82u+gqnOAOfnaHvVaVuB+9yf/vl8CrXyZr1jY8AlkpUHCzSDC5n1HeXrOBrrFV+Wpvi0IsesdjDF/kL8Hqc2ftWoqRNWDul04nJHNzf9dTmREKZ69ppUVB2PMn2IFIpitng5Ji6HtdeQi3DPjR/alZTHx+vZUq2D3lTbG/Dl2akuw2vMjfHIv1LsAPe9uHvnfWhZvOcg/+re0QWljzDlhRxDBavmbEFoKrp3Ciwt3Mu2HndzerSFDOtbxdzJjTDFhBSIYpafAzx9C8368v/4EL83fwrXtY/lbr8b+TmaMKUasQASbzDR491qQEH6odT1jPv6ZC+Ki+Xv/lojYoLQx5tyxMYhg8+WjcGADSZdN4aZPDtO4eiSvDWtntw01xpxzViCCSXoKrJ7G8ZbXce1XZahUNoTJN3YgMqKUv5MZY4ohKxDBZOl4yMtlfNYVHM7I5tN7ulLdTmc1xviI9UsEi51LYekEjsZfzetrchnWqQ5NalTwdypjTDFmBSIYHE+FmTehFWvz8IkbiAgL4W67p7QxxsesQASD+U+gx/bzz/J/45PNGdzVM47o8uH+TmWMKeasQAS6fevgpxkk1ryC/2ypwF8vief2bg38ncoYUwJYgQhkxw7AjGHklK7AzTsu5oK4aO7s0ciudzDGFAkrEIFIFU4chk/uQY/s4G7PKDLLxvDioDaE2gytxpgiYqe5Bpoju+CjkbDzewCm5V7MmtKNef269lSxcQdjTBGyAhFI1s2C+Y9DaiIHKrTgX6kXsD3mKuaO6EDFMnYxnDGmaFkXU6BY9Cx8MBwFJjZ4mQ77H2ZH7FVMudGKgzHGP+wIIhDsWAKL/omnaT9uOXYbC9encnu3hvytV2MbkDbG+I0VCH/LOgozhpIXWZN70q9jUWIqf+/XkqGd7L4Oxhj/si4mf1s2EU4c5tkKDzM3MYsn+raw4mCMCQhWIPwp6xgseZXEqC5M2FKR0b2acH3nuv5OZYwxgHUx+df34+FEKvcduYxr28dy64V2hbQxJnBYgfCXzfPIW/Qv5uR2pkz9jjzVr4UNSBtjAooVCH9IXETejOvYnBfLezUeYOpNnSgdZr19xpjAYgWiqKUmotMGkZRXlbvCHmXqsK5WHIwxAckKRFHKTCfrs9GIx8PNeWN5487LqFWpjL9TGWNMgaxAFBVPFrmvX0D4kSSezbuO526+nEbVIv2dyhhjTsv6NopI9pdPEHokibs999L5+nG0rxvl70jGGPO7fFogRKSXiGwSka0iMvo02wwUkfUisk5Epnm154rIavdnti9z+lR6CplL/kPoD68xJ7cTvQfdwQVxVf2dyhhjzshnXUwiEgqMBy4BkoHlIjJbVdd7bRMHjAG6qOphEanm9RQnVLWNr/IViSO70Nc6E5F9jC0aQ9kr/0X3ljX9ncoYYwrFl0cQHYGtqpqoqtnADKBvvm1GAuNV9TCAqu73YZ6ilZ6C5+M7yM7JoU/206ztO4/uHdv6O5UxxhSaLwtEDLDL63Gy2+YtHogXke9EZKmI9PJaFyEiK9z2qwt6ARG51d1mxYEDB85p+D/seCp8fDv8uwm643sez7mekQP70a9dbX8nM8aYs+Lvs5jCgDigOxALfCMiLVX1CFBXVXeLSAPgaxH5WVW3ee+sqhOBiQAJCQlapMkLcuIwzLwJEhewMySWG7Me4KGhl3NZ8xr+TmaMMWfNlwViN+D9tTnWbfOWDPygqjnAdhHZjFMwlqvqbgBVTRSRhUBbYBuBKteDTukD+9bzXNhtTMrqzsThHbgw3gakjTHByZddTMuBOBGpLyKlgcFA/rORZuEcPSAi0ThdTokiEiUi4V7tXYD1BKrDSeRN7IHsW8s92XeyIPJK3rm5sxUHY0xQ89kRhKp6ROQuYB4QCrylqutE5AlgharOdtddKiLrgVzgQVU9JCLnA/8RkTycIvZP77OfAkrGIU68M5Qyh9YxJ7cjNbsM46XLmxISYhPvGWOCm6j6v+v+XEhISNAVK1YU6Wtq1jHSXu9FudT1PBF2DxcP+gvd7KjBGBNERGSlqiYUtM7fg9RBK+XwMfZM6EebrLX8vcJY7hp5F9UrRPg7ljHGnDNWIM6SqjL7pz2kzHqU21nG8haPMKb//YSF2qwlxpjixQrEWTh6Ipsv3/g/Qg6s5dbQ70lvMpAO1z7g71jGGOMTViAKYd/uJDYvmYVn/Wf012UQClq/OxX6v+jvaMYY4zNWIE4j7UQOC5euIGbVv2ibvpDqohwJiSKl+e3U7P8PJMS6lIwxxZsViHxycvOY83MKr32yhNdyHqFuyD7WV7mUsAvuoUnr86gUEurviMYYUySsQLg8uXl8umILh+e/SKUTO3i71GaqhRxAr5lMyxb9/R3PGGOKXIkvEHl5yjebUlg/9w2uTXuTqpLO8fI1KRNVG7r+G2l2lb8jGmOMX5T4ApGStImY6f3pHrKbg5VaoH3/TtkG3fwdyxhj/K7EF4iYug1Jrd2YnPP+QXTzq0BsigxjjAErEBBaisojP/Z3CmOMCTh2rqYxxpgCWYEwxhhTICsQxhhjCmQFwhhjTIGsQBhjjCmQFQhjjDEFsgJhjDGmQFYgjDHGFKjY3JNaRA4AO/7EU0QDB89RHF8LpqwQXHmDKSsEV95gygrBlffPZK2rqlULWlFsCsSfJSIrTnfj7kATTFkhuPIGU1YIrrzBlBWCK6+vsloXkzHGmAJZgTDGGFMgKxC/mOjvAGchmLJCcOUNpqwQXHmDKSsEV16fZLUxCGOMMQWyIwhjjDEFsgJhjDGmQCW+QIhILxHZJCJbRWS0v/MAiMhbIrJfRNZ6tVUWkS9FZIv73yi3XUTkZTf/GhFpV8RZa4vIAhFZLyLrROTeAM8bISLLROQnN+/jbnt9EfnBzfWeiJR228Pdx1vd9fWKMq+bIVREfhSRT4Mga5KI/Cwiq0VkhdsWqJ+FSiIyU0Q2isgGETkvgLM2dn+nJ3/SRWSUz/Oqaon9AUKBbUADoDTwE9AsAHJdCLQD1nq1PQOMdpdHA/9yl68A5gICdAZ+KOKsNYF27nIksBloFsB5BSjvLpcCfnBzvA8MdttfB+5wl+8EXneXBwPv+eHzcD8wDfjUfRzIWZOA6HxtgfpZ+C9wi7tcGqgUqFnz5Q4F9gJ1fZ3XL28wUH6A84B5Xo/HAGP8ncvNUi9fgdgE1HSXawKb3OX/AEMK2s5Puf8HXBIMeYGywCqgE85VqGH5PxfAPOA8dznM3U6KMGMsMB/oCXzq/oMPyKzu6xZUIALuswBUBLbn//0EYtYCsl8KfFcUeUt6F1MMsMvrcbLbFoiqq2qKu7wXqO4uB8x7cLs02uJ8Kw/YvG6XzWpgP/AlzlHkEVX1FJDpVF53fRpQpQjjvgg8BOS5j6sQuFkBFPhCRFaKyK1uWyB+FuoDB4DJbvfdmyJSLkCz5jcYmO4u+zRvSS8QQUmdrwQBdX6yiJQHPgRGqWq697pAy6uquaraBufbeUegiX8TFUxE+gD7VXWlv7Ocha6q2g64HPiLiFzovTKAPgthON24E1S1LZCB00VzSgBlPcUdb7oK+CD/Ol/kLekFYjdQ2+txrNsWiPaJSE0A97/73Xa/vwcRKYVTHN5V1Y/c5oDNe5KqHgEW4HTTVBKRsAIyncrrrq8IHCqiiF2Aq0QkCZiB0830UoBmBUBVd7v/3Q98jFOAA/GzkAwkq+oP7uOZOAUjELN6uxxYpar73Mc+zVvSC8RyIM49K6Q0zqHbbD9nOp3ZwHB3eThOX//J9hvcsxY6A2leh5w+JyICTAI2qOq/gyBvVRGp5C6XwRkv2YBTKK45Td6T7+Ma4Gv3m5rPqeoYVY1V1Xo4n82vVXVYIGYFEJFyIhJ5chmnr3wtAfhZUNW9wC4Raew2XQSsD8Ss+Qzhl+6lk7l8l9cfgyyB9IMz2r8Zpx/6//ydx800HUgBcnC+6dyM05c8H9gCfAVUdrcVYLyb/2cgoYizdsU5rF0DrHZ/rgjgvK2AH928a4FH3fYGwDJgK87he7jbHuE+3uqub+Cnz0R3fjmLKSCzurl+cn/Wnfz3FMCfhTbACvezMAuICtSsboZyOEeEFb3afJrXptowxhhToJLexWSMMeY0rEAYY4wpkBUIY4wxBbICYYwxpkBWIIwxxhTICoQxZ0FEcvPNqnnOZgAWkXriNYOvMf4WduZNjDFeTqgzTYcxxZ4dQRhzDrj3QXjGvRfCMhFp5LbXE5Gv3Tn554tIHbe9uoh8LM59KX4SkfPdpwoVkTfEuVfFF+7V3sb4hRUIY85OmXxdTIO81qWpakvgVZxZWAFeAf6rqq2Ad4GX3faXgUWq2hpnDqB1bnscMF5VmwNHgAE+fTfG/A67ktqYsyAix1S1fAHtSUBPVU10Jy/cq6pVROQgzjz8OW57iqpGi8gBIFZVs7yeox7wparGuY//BpRS1aeK4K0Z8xt2BGHMuaOnWT4bWV7Ludg4ofEjKxDGnDuDvP77vbu8BGcmVoBhwGJ3eT5wB5y6gVHFogppTGHZtxNjzk4Z9250J32uqidPdY0SkTU4RwFD3La7ce5a9iDOHcxudNvvBSaKyM04Rwp34Mzga0zAsDEIY84BdwwiQVUP+juLMeeKdTEZY4wpkB1BGGOMKZAdQRhjjCmQFQhjjDEFsgJhjDGmQFYgjDHGFMgKhDHGmAL9P6Alleshyx6OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Plot accuracy\n",
    "plt.plot(malstm_trained.history['accuracy'])\n",
    "plt.plot(malstm_trained.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.plot(malstm_trained.history['loss'])\n",
    "plt.plot(malstm_trained.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI Internship Environment",
   "language": "python",
   "name": "ai-internship-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
